{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Youtube Conversation Prediction\n",
    "## CS/INFO 4300 Language and Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import httplib2\n",
    "import os\n",
    "import sys\n",
    "sys.path.append ('/data_collection/') # so that we can import captions3\n",
    "import datetime\n",
    "import json\n",
    "from math import sqrt\n",
    "\n",
    "from apiclient.discovery import build\n",
    "from apiclient.errors import HttpError\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Function to get distribution\n",
    "import isodate\n",
    "from __future__ import division\n",
    "\n",
    "def get_speech_distr(vid_data, partition_len=5):\n",
    "    # Get toal duration of video\n",
    "    duration = isodate.parse_duration(vid_data[\"video_length\"]).seconds\n",
    "    # Go over captions\n",
    "    hist_values = [0]*(int(100/partition_len))\n",
    "    for line in vid_data[\"captions\"]:\n",
    "        dur   = float(line[\"dur\"])\n",
    "        start = float(line[\"start\"])\n",
    "        end   = dur+start\n",
    "        start_percent = start/duration\n",
    "        end_percent   = end/duration\n",
    "        end_percent = 99 if end_percent == 100 else end_percent #corner case\n",
    "        start_index = int(start_percent/partition_len)\n",
    "        end_index   = int(end_percent/partition_len)\n",
    "        for i in range(start_index, end_index+1):\n",
    "            hist_values[i] += 1\n",
    "    #Converting to values\n",
    "    freqs = []\n",
    "    for freq_idx, freq in enumerate(hist_values):\n",
    "        freq_num = (freq_idx * partition_len) + (partition_len/2)\n",
    "        freqs.append(freq_num)\n",
    "    return hist_values, freqs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load the data from the JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('data/big_data_approx.json') as json_file:   \n",
    "    video_data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "video_num_comments, video_captions = np.array([ (video_datum[\"score\"], video_datum[\"captions\"]) \n",
    "                                              for _,video_datum in video_data.iteritems() ]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Consolidate caption text for each video into one string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "combined_video_captions = []\n",
    "video_num_comments_cut  = []\n",
    "for caption_data_list,num_comments in zip(video_captions,video_num_comments):\n",
    "    text = \"\"\n",
    "    if caption_data_list is not None:\n",
    "        video_num_comments_cut.append(num_comments)\n",
    "        for caption_data in caption_data_list:\n",
    "            if caption_data is not None and \"text\" in caption_data:\n",
    "                text += (caption_data[\"text\"]+\" \")\n",
    "        combined_video_captions.append(text[:-1])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "video_captions = combined_video_captions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#2. Make a 75-25 train-test split.\n",
    "\n",
    "Use `sklearn.cross_validation.train_test_split`. Set `random_state=0`. Make sure the train and test sizes are equal (plus/minus one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2268\n",
      "2268\n"
     ]
    }
   ],
   "source": [
    "print(len(video_num_comments_cut))\n",
    "print(len(combined_video_captions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_train, Y_test, video_captions_train, video_captions_test  = train_test_split(video_num_comments_cut, combined_video_captions, \n",
    "                                                                       test_size=.25, random_state=787)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "567\n",
      "1701\n",
      "567\n",
      "1701\n"
     ]
    }
   ],
   "source": [
    "print(len(Y_test))\n",
    "print(len(Y_train))\n",
    "print(len(video_captions_test))\n",
    "print(len(video_captions_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 488.,   49.,   12.,    5.,    2.,    4.,    1.,    1.,    0.,\n",
       "           1.,    1.,    1.,    1.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    1.]),\n",
       " array([    0.        ,    59.80432935,   119.6086587 ,   179.41298805,\n",
       "          239.2173174 ,   299.02164674,   358.82597609,   418.63030544,\n",
       "          478.43463479,   538.23896414,   598.04329349,   657.84762284,\n",
       "          717.65195219,   777.45628153,   837.26061088,   897.06494023,\n",
       "          956.86926958,  1016.67359893,  1076.47792828,  1136.28225763,\n",
       "         1196.08658698,  1255.89091632,  1315.69524567,  1375.49957502,\n",
       "         1435.30390437,  1495.10823372]),\n",
       " <a list of 25 Patch objects>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEACAYAAAC08h1NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4pekxlj8ktSY/wUlBdvtJFL8FwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xb0f02d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(Y_test, bins=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  1.42100000e+03,   1.48000000e+02,   5.90000000e+01,\n",
       "          2.70000000e+01,   1.40000000e+01,   7.00000000e+00,\n",
       "          7.00000000e+00,   5.00000000e+00,   2.00000000e+00,\n",
       "          1.00000000e+00,   6.00000000e+00,   1.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n",
       "          1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          1.00000000e+00]),\n",
       " array([    0.        ,    59.60972201,   119.21944403,   178.82916604,\n",
       "          238.43888806,   298.04861007,   357.65833209,   417.2680541 ,\n",
       "          476.87777611,   536.48749813,   596.09722014,   655.70694216,\n",
       "          715.31666417,   774.92638619,   834.5361082 ,   894.14583021,\n",
       "          953.75555223,  1013.36527424,  1072.97499626,  1132.58471827,\n",
       "         1192.19444029,  1251.8041623 ,  1311.41388431,  1371.02360633,\n",
       "         1430.63332834,  1490.24305036]),\n",
       " <a list of 25 Patch objects>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEACAYAAACznAEdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xb19f550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(Y_train, bins=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build the document-term matrices\n",
    "\n",
    "Use `sklearn.feature_extraction.TfidfVectorizer`. Use unigrams only, disable idf, use `l1` normalization. \n",
    "\n",
    "Resulting matrices are `X_train` and `X_test`.\n",
    "\n",
    "**Note:** Remember to just `fit` on the training data. If a word occurs only in the test documents, our model should **not** be aware that the word exists, as we are trying to evaluate the performance on completely unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfv = TfidfVectorizer(ngram_range=(1,1), lowercase=True, strip_accents=\"unicode\", \n",
    "                      stop_words='english', use_idf=False, norm='l1', min_df=1, max_df=.1)\n",
    "tfv.fit(video_captions_train)\n",
    "X_train = tfv.transform(video_captions_train)\n",
    "X_test  = tfv.transform(video_captions_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1701, 531863)\n",
      "(567, 531863)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Predict using a random guess baseline\n",
    "\n",
    "Use a random classifier from `sklearn.dummy.DummyClassifier`.  Set `strategy=\"stratified\"`? Set `random_state=0`, to get the same result every time, since randomness is involved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dummy = DummyRegressor(strategy=\"median\")\n",
    "dummy.fit(X_train, Y_train)\n",
    "Y_pred_med = dummy.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error,mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_mse_score = mean_squared_error(Y_test, Y_pred_med)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96.4148158996\n"
     ]
    }
   ],
   "source": [
    "print(sqrt(my_mse_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Setup GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "def my_mae_scorer(estimator, X, y):\n",
    "    \"\"\"This function is just glue code for the scikit-learn scorer API.\n",
    "    See http://scikit-learn.org/stable/modules/model_evaluation.html#implementing-your-own-scoring-object\n",
    "    =Parameters=\n",
    "    estimator:\n",
    "        the model that should be evaluated (e.g., the scikit-learn classifier)\n",
    "    X: array-like, shape (n_samples, n_features)\n",
    "        the test data\n",
    "    y: array-like, shape (n_samples, n_labels)\n",
    "        the ground truth target for X.\n",
    "    =Returns:=\n",
    "    mae, float\n",
    "        the mean absolute error\"\"\"\n",
    "    y_pred = estimator.predict(X)\n",
    "    return mean_absolute_error(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Train and evaluate SVM Regression.\n",
    "\n",
    "We will use `sklearn.svm.SVR()\" as our initial classifier (Support Vector Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "svm_regression_classifier = SVR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma=0.0,\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_regression_classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_pred_svr = svm_regression_classifier.predict(X_test)\n",
    "my_mae_score_svr = mean_absolute_error(Y_test, Y_pred_svr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.3169888555\n"
     ]
    }
   ],
   "source": [
    "print(my_mae_score_svr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Train and evaluate Linear Regression.\n",
    "\n",
    "We will be using `sklearn.linear_model.LinearRegression()\" as an additional classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lreg_clf = LinearRegression(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    3.9s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   23.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "61.8461006584\n"
     ]
    }
   ],
   "source": [
    "grid = GridSearchCV(estimator=lreg_clf,\n",
    "                    param_grid=dict(normalize=[True,False]), \n",
    "                    scoring=my_mae_scorer,\n",
    "                    verbose=True)\n",
    "grid.fit(X_train, Y_train)\n",
    "best_params_lreg = grid.best_params_\n",
    "print(my_mae_scorer(grid.best_estimator_, X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61.8461006584\n"
     ]
    }
   ],
   "source": [
    "print(my_mae_scorer(grid.best_estimator_, X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 47.94762, std: 2.35685, params: {'normalize': True}\n",
      "mean: 47.94762, std: 2.35685, params: {'normalize': False}\n"
     ]
    }
   ],
   "source": [
    "for score in grid.grid_scores_:\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Train and evaluate Lasso Regression.\n",
    "\n",
    "We will be using \"sklearn.linear_model.Lasso\" as an additional classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "lasso_clf = Lasso()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grid = GridSearchCV(estimator=lasso_clf,\n",
    "                    param_grid=dict(alpha=[1,.9,.8,.7,.6,.5,.4,.3,.2,.1,.01,.001,.0001]), \n",
    "                    scoring=my_mae_scorer,\n",
    "                    verbose=True)\n",
    "grid.fit(X_train, Y_train)\n",
    "best_params_lasso = grid.best_params_\n",
    "print(my_mae_scorer(grid.best_estimator_, X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for score in grid.grid_scores_:\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.2. Train and evaluate Ridge Regression.\n",
    "\n",
    "We will be using \"sklearn.linear_model.Lasso\" as an additional classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.kernel_ridge import KernelRidge\n",
    "clf = KernelRidge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {'alpha': [1,.9,.8,.7,.6,.5,.4,.3,.2,.1,.01,.001,.0001,.000001], 'kernel': ['linear']},\n",
    "    {'alpha': [1,.9,.8,.7,.6,.5,.4,.3,.2,.1,.01,.001,.0001,.000001], 'kernel': ['rbf']},\n",
    "    {'alpha': [1,.9,.8,.7,.6,.5,.4,.3,.2,.1,.01,.001,.0001,.000001], 'kernel': ['polynomial'], 'degree' : [1,2,3,4]},\n",
    "    {'alpha': [1,.9,.8,.7,.6,.5,.4,.3,.2,.1,.01,.001,.0001,.000001], 'kernel': ['sigmoid']}\n",
    " ]\n",
    "grid = GridSearchCV(clf,\n",
    "                    param_grid,\n",
    "                    cv=3,\n",
    "                    scoring=my_mae_scorer,\n",
    "                    verbose=True)\n",
    "grid.fit(X_train, Y_train)\n",
    "best_params_kridge = grid.best_params_\n",
    "print(my_mae_scorer(grid.best_estimator_, X_test, Y_test))\n",
    "#mean: 35.91859, std: 1.46616, params: {'alpha': 0.01, 'kernel': 'linear'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for score in grid.grid_scores_:\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ElasticNet Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "en_clf = ElasticNet()\n",
    "param_grid = {'alpha': [1,.9,.8,.7,.6,.5,.4,.3,.2,.1,.01, .001, .0001], 'l1_ratio': [1,.9,.8,.7,.6,.5,.4,.3,.2,.1,.05]}\n",
    "grid = GridSearchCV(en_clf,\n",
    "                    param_grid,\n",
    "                    cv=3,\n",
    "                    scoring=my_mae_scorer,\n",
    "                    verbose=100)\n",
    "grid.fit(X_train, Y_train)\n",
    "best_params_en = grid.best_params_\n",
    "print(my_mae_scorer(grid.best_estimator_, X_test, Y_test))\n",
    "#mean: 35.91859, std: 1.46616, params: {'alpha': 0.01, 'kernel': 'linear'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for score in grid.grid_scores_:\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Create a query search\n",
    "\n",
    "Return the top ten search results for a given query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Key and version data \n",
    "DEVELOPER_KEY = \"AIzaSyBEuuLWPO0AJIIp7TVGIB1uM_mNiNkMVbw\"\n",
    "YOUTUBE_READ_WRITE_SCOPE = \"https://www.googleapis.com/auth/youtube\"\n",
    "YOUTUBE_API_SERVICE_NAME = \"youtube\"\n",
    "YOUTUBE_API_VERSION = \"v3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Authenticate \n",
    "youtube = build(YOUTUBE_API_SERVICE_NAME, YOUTUBE_API_VERSION, developerKey=DEVELOPER_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Returns the top ten search results for the query in the form \n",
    "   {video_id:{\"thumbnail\":thumbnail_url, \"title\":video title}}\"\"\"\n",
    "\n",
    "def query_search(query):\n",
    "    search_request = youtube.search().list(part=\"snippet\", q=query, maxResults=10, videoCaption=\"closedCaption\", type=\"video\")\n",
    "    \n",
    "    search_response = search_request.execute()\n",
    "    \n",
    "    search_results = {}\n",
    "    for search_result in search_response[\"items\"]:\n",
    "        video_id = search_result[\"id\"][\"videoId\"]\n",
    "        thumbnail = search_result[\"snippet\"][\"thumbnails\"][\"default\"][\"url\"]\n",
    "        title = search_result[\"snippet\"][\"title\"]\n",
    "        description = search_result[\"snippet\"][\"description\"]\n",
    "        search_results[video_id] = {\"thumbnail\":thumbnail, \"title\":title, \"description\":description}\n",
    "    \n",
    "    return search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "soup_search_results = query_search(\"soup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import nltk\n",
    "import urllib3\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def has_english(vid_id):\n",
    "    http = urllib3.PoolManager() #init urllib\n",
    "    resp = http.request('GET', 'http://video.google.com/timedtext',preload_content=False,\n",
    "                       fields={'type': 'list', 'v': vid_id})\n",
    "    sub_dir_xml = resp.read()\n",
    "    resp.close()\n",
    "    dir_soup = BeautifulSoup(sub_dir_xml)\n",
    "    eng_track = dir_soup.find(lang_code=\"en\")\n",
    "    return False if eng_track is None else True\n",
    "\n",
    "def get_transcript(vid_id):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "        vid_id: Youtube video id\n",
    "    Output:\n",
    "        transcript: Beautiful soup xml object of transcipt\n",
    "        of the format:\n",
    "        <transcript>\n",
    "            <text dur=\"DURATION_TIME\" start=\"START_TIME\">\n",
    "                SPOKEN TEXT\n",
    "            </text>\n",
    "        </transcript>\n",
    "    \"\"\"\n",
    "    http = urllib3.PoolManager() #init urllib\n",
    "    resp = http.request('GET', 'http://video.google.com/timedtext',preload_content=False,\n",
    "                       fields={'type': 'list', 'v': vid_id})\n",
    "    sub_dir_xml = resp.read()\n",
    "    resp.close()\n",
    "    dir_soup = BeautifulSoup(sub_dir_xml)\n",
    "    eng_track = dir_soup.find(lang_code=\"en\")\n",
    "    if eng_track is None:\n",
    "        return None\n",
    "    track_resp = http.request('GET', 'http://video.google.com/timedtext',preload_content=False,\n",
    "                               fields={'type': 'track',\n",
    "                                       'v':    vid_id, \n",
    "                                       'name': eng_track['name'].encode('unicode-escape'), \n",
    "                                       'lang': 'en'})\n",
    "    transcript_xml = track_resp.read()\n",
    "    track_resp.close()\n",
    "    return BeautifulSoup(transcript_xml).transcript\n",
    "\n",
    "def get_tokens(text):\n",
    "    text = re.sub(\"&#39;\", \"\\'\", text)\n",
    "    text = re.sub(\"\\n\", \" \", text)\n",
    "    text = re.sub(\"[:&%$#@!,.?]\", \"\", text)\n",
    "    return nltk.word_tokenize(text.lower())\n",
    "\n",
    "def format_transcript(transcript):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        beautifulsoup transcript\n",
    "    Outputs:\n",
    "        array/dictionary formatted transcript\n",
    "    \"\"\"\n",
    "    foramtted_transcript = []\n",
    "    for text_soup in transcript.find_all(\"text\"):\n",
    "        text = text_soup.get_text()\n",
    "        if len(text) > 0:\n",
    "            line = {\n",
    "                    'text'  : text,\n",
    "                    'dur'   : text_soup['dur'] if 'dur' in text_soup else 0,\n",
    "                    'start' : text_soup['start'] if 'start' in text_soup else 0\n",
    "                    }\n",
    "            foramtted_transcript.append(line)\n",
    "    return foramtted_transcript\n",
    "\n",
    "\n",
    "def get_flattened_transcript(vid_id):\n",
    "    transcript = get_transcript(vid_id)\n",
    "    flat_text = \"\"\n",
    "    if transcript is not None:\n",
    "        for text_soup in transcript.find_all(\"text\"):\n",
    "            text = text_soup.get_text()\n",
    "            if len(text) > 0:\n",
    "                flat_text += (text + \" \")\n",
    "    else:\n",
    "        return None # The case where we could not get the transcript\n",
    "    return flat_text[:-1]\n",
    "\n",
    "\n",
    "def get_formatted_transcript(vid_id):\n",
    "    \"\"\"\n",
    "    Convience method\n",
    "    \"\"\"\n",
    "    transcript = get_transcript(vid_id)\n",
    "    if transcript is None:\n",
    "        return None\n",
    "    return format_transcript(transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Assign conversationality scores to the videos returned and \n",
    "return a list with the video in ascending order of conversationality\n",
    "score. The final list consists tuple of the form (video_info dictionary, score).\"\"\"\n",
    "\n",
    "def rerank_search_results(model, search_results):\n",
    "    videos_with_score = [] # contain tuples of video dictionaries and their conversationality score\n",
    "    for video_id, video_info in search_results.iteritems():\n",
    "        flattened_transcript = get_flattened_transcript(video_id)\n",
    "        if flattened_transcript is not None: \n",
    "            vectorized_captions = tfv.transform([flattened_transcript]) # using previous vectorizer\n",
    "            conversationality_score = model.predict(vectorized_captions)\n",
    "            videos_with_score.append(({video_id : video_info}, conversationality_score[0]))\n",
    "        \n",
    "    return sorted(videos_with_score, key=itemgetter(1), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({u'9QiqibXv9Eo': {'description': u'All videos come with english captions. Please click the CC Button to activate english subtitles. \\u6240\\u6709\\u89c6\\u9891\\u90fd\\u5beb\\u4e0a\\u6709\\u82f1\\u6587\\u8aaa\\u660e\\u5b57\\u5e55, \\u8acb\\u6309CC \\u9215\\u63a3Please add me as ...',\n",
       "    'thumbnail': u'https://i.ytimg.com/vi/9QiqibXv9Eo/default.jpg',\n",
       "    'title': u'Chinese hot and sour soup, \\u9178\\u8fa3\\u6e6f'}},\n",
       "  16.244858248222585),\n",
       " ({u'mZyR2Ew66w8': {'description': u\"Magic Diet Soup - Lose Weight Fast - Low Gi. Well it worked for me and I have lost the weight and kept it off. So don't be scared, just try and see how I did it by ...\",\n",
       "    'thumbnail': u'https://i.ytimg.com/vi/mZyR2Ew66w8/default.jpg',\n",
       "    'title': u'Magic Diet Soup -  Lose Weight Fast - Low Gi.'}},\n",
       "  16.244858041687017),\n",
       " ({u'vZwfONmD54c': {'description': u'Sweet Corn Soup,delicate and pleasant flavour of corn makes this a popular choice. Recipe link : http://www.tarladalal.com/Sweet-Corn-Soup-(-Soup-)-37393r ...',\n",
       "    'thumbnail': u'https://i.ytimg.com/vi/vZwfONmD54c/default.jpg',\n",
       "    'title': u'Sweet Corn Soup by Tarla Dalal'}},\n",
       "  16.244858033535834),\n",
       " ({u'O9ak89FwYeI': {'description': u'Twitter: http://www.twitter.com/tweetsauce Instagram: http://www.instagram.com/electricpants ***EXTRA INFO AND SOURCES BELOW*** Vsauce2: ...',\n",
       "    'thumbnail': u'https://i.ytimg.com/vi/O9ak89FwYeI/default.jpg',\n",
       "    'title': u'Is Cereal Soup?'}},\n",
       "  16.244857525236686),\n",
       " ({u'GojmNjoTaTg': {'description': u'LIVE EVENT WITH EMERIL & LAURA: https://www.youtube.com/watch?v=lnDSYdUp1hA To get this complete recipe with instructions and measurements, check ...',\n",
       "    'thumbnail': u'https://i.ytimg.com/vi/GojmNjoTaTg/default.jpg',\n",
       "    'title': u'Loaded Potato Soup Recipe - Laura Vitale - Laura in the Kitchen Episode 863'}},\n",
       "  16.244857073823216),\n",
       " ({u'1xrhaL3WmaY': {'description': u\"If you haven't got a failsafe soup recipe in your arsenal than look no further than this tasty offering from Vegetarian cook Anna Jones. From one batch of sweet potato and ...\",\n",
       "    'thumbnail': u'https://i.ytimg.com/vi/1xrhaL3WmaY/default.jpg',\n",
       "    'title': u'Easy Vegetable Soup - Three Ways | Anna Jones'}},\n",
       "  16.244856752269577),\n",
       " ({u'L1TFnkm1TG8': {'description': u'Click here to SUBSCRIBE: http://bit.ly/1dn24vP Shop this video here: https://rdy.cr/dac6c6 Homemade Vegetable Stock: http://bit.ly/1vAte5U 3 Mac & Cheese ...',\n",
       "    'thumbnail': u'https://i.ytimg.com/vi/L1TFnkm1TG8/default.jpg',\n",
       "    'title': u'Fall Soup - 3 Delicious Ways'}},\n",
       "  16.244856654118454),\n",
       " ({u'xqFo59YveXo': {'description': u'Food Busker is hitting the streets with another incredible recipe: Ramen noodles layered with finely sliced fresh vegetables and shredded chicken in an Asian ...',\n",
       "    'thumbnail': u'https://i.ytimg.com/vi/xqFo59YveXo/default.jpg',\n",
       "    'title': u'Chicken Ramen Noodle Soup | Food Busker'}},\n",
       "  16.24485657861317)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rerank_search_results(svm_regression_classifier, soup_search_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Use grid search and cross-validation to tune the classifier\n",
    "\n",
    "The score above is pretty disappointing, but kind of expected, given how little work we did-- we are basically just using the default configuration.  A `LinearSVC` has a bunch of configuration options that should be tweaked:\n",
    "\n",
    "* `C` is the *regularization parameter*. Lower values of C constraint the model more, while higher values allows the model to fit the training data better. (Remember that fitting the training data too well can lead to overfitting.)\n",
    "\n",
    "* `class_weight` can force the classifier to emphasize positive instances more or less than negative ones. This is useful if we know for a fact that the classes aren't equally probable. Read the documentation and see what the `'auto'` setting does.\n",
    "\n",
    "However, choosing these values should also be done without looking at the test data, because they are part of the model. Use `sklearn.grid_search.GridSearchCV` to systematically try out different values for these two parameters, and choose the configuration that does best.\n",
    "\n",
    "`GridSearchCV` uses k-fold cross-validation to ensure fair evaluation and avoid overfitting. This consists of splitting the training data into *k* parts, then training the classifier *k* times, each time leaving out a different part, that is used for scoring. The average score over the *k* folds is a better estimate of how well the classifier would generalize.\n",
    "\n",
    "Because we are facing a multi-label problem, the default scoring strategy (accuracy) doesn't make sense. We have to define our own `sample_f1_scorer` strategy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sample_f1_scorer(estimator, X, y):\n",
    "    \"\"\"sample-f1 scorer metric\n",
    "    \n",
    "    This function is just glue code for the scikit-learn scorer API.\n",
    "    See http://scikit-learn.org/stable/modules/model_evaluation.html#implementing-your-own-scoring-object\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    \n",
    "    estimator:\n",
    "        the model that should be evaluated (e.g., the scikit-learn classifier)\n",
    "    X: array-like, shape (n_samples, n_features)\n",
    "        the test data\n",
    "    y: array-like, shape (n_samples, n_labels)\n",
    "        the ground truth target for X.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    \n",
    "    sample_f1_score, float\n",
    "        the sample F1 score as used in Q06 and Q07\n",
    "    \"\"\"\n",
    "    y_pred = estimator.predict(X)\n",
    "    return f1_score(y, y_pred, average='samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, run grid search over a range of regularization parameters, as below.  This takes under 1 minute on a 2014 MacBook Pro Retina. If you're not sure your code works, test it on a small number of documents first to avoid wasting time.\n",
    "\n",
    "What is the best configuration, and the best score (averaged over the 3 folds)? (there are attributes of the `GridSearchCV` object that answer this).\n",
    "\n",
    "DISCUSSION ITEM.\n",
    "What can you say about the impact of `C` and `class_weight` on the score? (look at `grid.grid_scores_` to answer this)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param_grid = dict(\n",
    "    estimator__C=[1e-3, 1e-2, 1e-1, 1, 1e1, 1e2, 1e3],  # you can also build this using np.logspace\n",
    "    estimator__class_weight=['auto', None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ovr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-9233726c6da1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m grid = GridSearchCV(ovr,\n\u001b[0m\u001b[0;32m      2\u001b[0m                     \u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                     \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                     \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_f1_scorer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                     verbose=True)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ovr' is not defined"
     ]
    }
   ],
   "source": [
    "grid = GridSearchCV(ovr,\n",
    "                    param_grid,\n",
    "                    cv=3,\n",
    "                    scoring=sample_f1_scorer,\n",
    "                    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grid.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Evaluate the chosen classifier on the test set. Inspect performance on individual categories.\n",
    "\n",
    "Use `grid.best_estimator_` to access the `ovr` object chosen as best by the grid search. Use `sample_f1_scorer` and report the **sample F1** score as in Q06 and Q07. This time, you should see a rewarding increase.\n",
    "\n",
    "DISCUSSION ITEM.\n",
    "Compare this score with the cross-validated average score over the 3 folds for the best model (Q08).  Does cross-validation give a reasonable estimate of the actual generalization performance a model can get on unseen test data? Compare with what we saw in class, when we were looking at the performance of a classifier on the data it was trained on, versus on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grid_f1_score = sample_f1_scorer(grid.best_estimator_, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(grid_f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** TODO discuss **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Then, to aggregate scores over individual categories, use `sklearn.metrics.classification_report`. Keep in mind that in the classification report, precision, recall and F1 have different meaning than the sample-based scores we used in the previous questions: they are averages over a given label, as opposed to a given document.\n",
    "\n",
    "DISCUSSION ITEM. How do you interpret this table?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_pred_test_grid = grid.predict(X_test)\n",
    "grid_report = classification_report(Y_test, Y_pred_test_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(grid_report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
