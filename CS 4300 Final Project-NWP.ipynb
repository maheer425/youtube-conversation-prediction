{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Youtube Conversation Prediction\n",
    "## CS/INFO 4300 Language and Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import httplib2\n",
    "import os\n",
    "import sys\n",
    "sys.path.append ('/data_collection/') # so that we can import captions3\n",
    "import datetime\n",
    "import json\n",
    "from math import sqrt\n",
    "\n",
    "from apiclient.discovery import build\n",
    "from apiclient.errors import HttpError\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Function to get distribution\n",
    "import isodate\n",
    "from __future__ import division\n",
    "\n",
    "def get_speech_distr(vid_data, partition_len=5):\n",
    "    # Get toal duration of video\n",
    "    duration = isodate.parse_duration(vid_data[\"video_length\"]).seconds\n",
    "    # Go over captions\n",
    "    hist_values = [0]*(int(100/partition_len))\n",
    "    for line in vid_data[\"captions\"]:\n",
    "        dur   = float(line[\"dur\"])\n",
    "        start = float(line[\"start\"])\n",
    "        end   = dur+start\n",
    "        start_percent = start/duration\n",
    "        end_percent   = end/duration\n",
    "        end_percent = 99 if end_percent == 100 else end_percent #corner case\n",
    "        start_index = int(start_percent/partition_len)\n",
    "        end_index   = int(end_percent/partition_len)\n",
    "        for i in range(start_index, end_index+1):\n",
    "            hist_values[i] += 1\n",
    "    #Converting to values\n",
    "    freqs = []\n",
    "    for freq_idx, freq in enumerate(hist_values):\n",
    "        freq_num = (freq_idx * partition_len) + (partition_len/2)\n",
    "        freqs.append(freq_num)\n",
    "    return hist_values, freqs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load the data from the JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('data/big_data_approx.json') as json_file:   \n",
    "    video_data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "video_num_comments, video_captions = np.array([ (video_datum[\"score\"], video_datum[\"captions\"]) \n",
    "                                              for _,video_datum in video_data.iteritems() ]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Consolidate caption text for each video into one string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "combined_video_captions = []\n",
    "video_num_comments_cut  = []\n",
    "for caption_data_list,num_comments in zip(video_captions,video_num_comments):\n",
    "    text = \"\"\n",
    "    if caption_data_list is not None:\n",
    "        video_num_comments_cut.append(num_comments)\n",
    "        for caption_data in caption_data_list:\n",
    "            if caption_data is not None and \"text\" in caption_data:\n",
    "                text += (caption_data[\"text\"]+\" \")\n",
    "        combined_video_captions.append(text[:-1])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "video_captions = combined_video_captions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#2. Make a 75-25 train-test split.\n",
    "\n",
    "Use `sklearn.cross_validation.train_test_split`. Set `random_state=0`. Make sure the train and test sizes are equal (plus/minus one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2268\n",
      "2268\n"
     ]
    }
   ],
   "source": [
    "print(len(video_num_comments_cut))\n",
    "print(len(combined_video_captions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_train, Y_test, video_captions_train, video_captions_test  = train_test_split(video_num_comments_cut, combined_video_captions, \n",
    "                                                                       test_size=.25, random_state=787)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "567\n",
      "1701\n",
      "567\n",
      "1701\n"
     ]
    }
   ],
   "source": [
    "print(len(Y_test))\n",
    "print(len(Y_train))\n",
    "print(len(video_captions_test))\n",
    "print(len(video_captions_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 488.,   49.,   12.,    5.,    2.,    4.,    1.,    1.,    0.,\n",
       "           1.,    1.,    1.,    1.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    1.]),\n",
       " array([    0.        ,    59.80432935,   119.6086587 ,   179.41298805,\n",
       "          239.2173174 ,   299.02164674,   358.82597609,   418.63030544,\n",
       "          478.43463479,   538.23896414,   598.04329349,   657.84762284,\n",
       "          717.65195219,   777.45628153,   837.26061088,   897.06494023,\n",
       "          956.86926958,  1016.67359893,  1076.47792828,  1136.28225763,\n",
       "         1196.08658698,  1255.89091632,  1315.69524567,  1375.49957502,\n",
       "         1435.30390437,  1495.10823372]),\n",
       " <a list of 25 Patch objects>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEACAYAAAC08h1NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4pekxlj8ktSY/wUlBdvtJFL8FwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xad3cdb0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(Y_test, bins=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  1.42100000e+03,   1.48000000e+02,   5.90000000e+01,\n",
       "          2.70000000e+01,   1.40000000e+01,   7.00000000e+00,\n",
       "          7.00000000e+00,   5.00000000e+00,   2.00000000e+00,\n",
       "          1.00000000e+00,   6.00000000e+00,   1.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n",
       "          1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          1.00000000e+00]),\n",
       " array([    0.        ,    59.60972201,   119.21944403,   178.82916604,\n",
       "          238.43888806,   298.04861007,   357.65833209,   417.2680541 ,\n",
       "          476.87777611,   536.48749813,   596.09722014,   655.70694216,\n",
       "          715.31666417,   774.92638619,   834.5361082 ,   894.14583021,\n",
       "          953.75555223,  1013.36527424,  1072.97499626,  1132.58471827,\n",
       "         1192.19444029,  1251.8041623 ,  1311.41388431,  1371.02360633,\n",
       "         1430.63332834,  1490.24305036]),\n",
       " <a list of 25 Patch objects>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEACAYAAACznAEdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xae7e0b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(Y_train, bins=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build the document-term matrices\n",
    "\n",
    "Use `sklearn.feature_extraction.TfidfVectorizer`. Use unigrams only, disable idf, use `l1` normalization. \n",
    "\n",
    "Resulting matrices are `X_train` and `X_test`.\n",
    "\n",
    "**Note:** Remember to just `fit` on the training data. If a word occurs only in the test documents, our model should **not** be aware that the word exists, as we are trying to evaluate the performance on completely unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfv = TfidfVectorizer(ngram_range=(1,2), lowercase=True, strip_accents=\"unicode\", \n",
    "                      stop_words='english', use_idf=False, norm='l1', min_df=1, max_df=.1)\n",
    "tfv.fit(video_captions_train)\n",
    "X_train = tfv.transform(video_captions_train)\n",
    "X_test  = tfv.transform(video_captions_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'00',\n",
       " u'00 00',\n",
       " u'00 01',\n",
       " u'00 02',\n",
       " u'00 03',\n",
       " u'00 04',\n",
       " u'00 07',\n",
       " u'00 10',\n",
       " u'00 12',\n",
       " u'00 13',\n",
       " u'00 15',\n",
       " u'00 17',\n",
       " u'00 20',\n",
       " u'00 23',\n",
       " u'00 25',\n",
       " u'00 26',\n",
       " u'00 27',\n",
       " u'00 31',\n",
       " u'00 333',\n",
       " u'00 35',\n",
       " u'00 36',\n",
       " u'00 38',\n",
       " u'00 39',\n",
       " u'00 42',\n",
       " u'00 43',\n",
       " u'00 46',\n",
       " u'00 49',\n",
       " u'00 51',\n",
       " u'00 52',\n",
       " u'00 59',\n",
       " u'00 abc',\n",
       " u'00 comes',\n",
       " u'00 comm',\n",
       " u'00 day',\n",
       " u'00 don',\n",
       " u'00 june',\n",
       " u'00 local',\n",
       " u'00 morning',\n",
       " u'00 nbc',\n",
       " u'00 phone',\n",
       " u'00 shelly',\n",
       " u'00 stores',\n",
       " u'00 tell',\n",
       " u'00 times',\n",
       " u'00 years',\n",
       " u'00 yuan',\n",
       " u'000 000',\n",
       " u'000 000krw',\n",
       " u'000 10',\n",
       " u'000 100',\n",
       " u'000 14',\n",
       " u'000 17',\n",
       " u'000 20',\n",
       " u'000 2010',\n",
       " u'000 23',\n",
       " u'000 350',\n",
       " u'000 361',\n",
       " u'000 375',\n",
       " u'000 39',\n",
       " u'000 45',\n",
       " u'000 50th',\n",
       " u'000 acres',\n",
       " u'000 ah',\n",
       " u'000 air',\n",
       " u'000 americans',\n",
       " u'000 aspen',\n",
       " u'000 audi',\n",
       " u'000 audiobooks',\n",
       " u'000 average',\n",
       " u'000 bce',\n",
       " u'000 births',\n",
       " u'000 bishops',\n",
       " u'000 bonus',\n",
       " u'000 burned',\n",
       " u'000 calories',\n",
       " u'000 cash',\n",
       " u'000 catholic',\n",
       " u'000 cc',\n",
       " u'000 chance',\n",
       " u'000 change',\n",
       " u'000 charity',\n",
       " u'000 cheers',\n",
       " u'000 citizens',\n",
       " u'000 cking',\n",
       " u'000 colombian',\n",
       " u'000 colonoscopies',\n",
       " u'000 councilors',\n",
       " u'000 crashes',\n",
       " u'000 create',\n",
       " u'000 cubic',\n",
       " u'000 current',\n",
       " u'000 cyclists',\n",
       " u'000 day',\n",
       " u'000 deceased',\n",
       " u'000 degrees',\n",
       " u'000 depending',\n",
       " u'000 did',\n",
       " u'000 died',\n",
       " u'000 dietary',\n",
       " u'000 different',\n",
       " u'000 digits',\n",
       " u'000 directly',\n",
       " u'000 doesn',\n",
       " u'000 dollar',\n",
       " u'000 dollars',\n",
       " u'000 electron',\n",
       " u'000 emotional',\n",
       " u'000 equals',\n",
       " u'000 ethiopia',\n",
       " u'000 euro',\n",
       " u'000 euros',\n",
       " u'000 expensive',\n",
       " u'000 fades',\n",
       " u'000 fans',\n",
       " u'000 farc',\n",
       " u'000 feet',\n",
       " u'000 flat',\n",
       " u'000 flight',\n",
       " u'000 flights',\n",
       " u'000 followers',\n",
       " u'000 foot',\n",
       " u'000 football',\n",
       " u'000 forks',\n",
       " u'000 forms',\n",
       " u'000 fraction',\n",
       " u'000 frames',\n",
       " u'000 franciscan',\n",
       " u'000 french',\n",
       " u'000 friends',\n",
       " u'000 gallons',\n",
       " u'000 generations',\n",
       " u'000 geometric',\n",
       " u'000 goal',\n",
       " u'000 goes',\n",
       " u'000 going',\n",
       " u'000 got',\n",
       " u'000 hands',\n",
       " u'000 heartbeats',\n",
       " u'000 help',\n",
       " u'000 hits',\n",
       " u'000 hiv',\n",
       " u'000 horsepower',\n",
       " u'000 hours',\n",
       " u'000 hungarian',\n",
       " u'000 hurt',\n",
       " u'000 images',\n",
       " u'000 imagine',\n",
       " u'000 incidents',\n",
       " u'000 inhabitants',\n",
       " u'000 interested',\n",
       " u'000 invest',\n",
       " u'000 isn',\n",
       " u'000 joules',\n",
       " u'000 just',\n",
       " u'000 kelvin',\n",
       " u'000 kids',\n",
       " u'000 kilometers',\n",
       " u'000 kilometres',\n",
       " u'000 kilos',\n",
       " u'000 km',\n",
       " u'000 know',\n",
       " u'000 koi',\n",
       " u'000 land',\n",
       " u'000 light',\n",
       " u'000 lightyears',\n",
       " u'000 likely',\n",
       " u'000 likes',\n",
       " u'000 liter',\n",
       " u'000 lot',\n",
       " u'000 lying',\n",
       " u'000 marker',\n",
       " u'000 men',\n",
       " u'000 meters',\n",
       " u'000 metres',\n",
       " u'000 miles',\n",
       " u'000 mistakes',\n",
       " u'000 morphemes',\n",
       " u'000 named',\n",
       " u'000 newtons',\n",
       " u'000 numbers',\n",
       " u'000 obviously',\n",
       " u'000 oh',\n",
       " u'000 okay',\n",
       " u'000 ones',\n",
       " u'000 oreos',\n",
       " u'000 pages',\n",
       " u'000 paint',\n",
       " u'000 people',\n",
       " u'000 percent',\n",
       " u'000 peruvian',\n",
       " u'000 piece',\n",
       " u'000 plane',\n",
       " u'000 players',\n",
       " u'000 plus',\n",
       " u'000 possible',\n",
       " u'000 pound',\n",
       " u'000 pounds',\n",
       " u'000 priests',\n",
       " u'000 prime',\n",
       " u'000 probability',\n",
       " u'000 probably',\n",
       " u'000 produce',\n",
       " u'000 project',\n",
       " u'000 promised',\n",
       " u'000 quot',\n",
       " u'000 race',\n",
       " u'000 reais',\n",
       " u'000 real',\n",
       " u'000 recoup',\n",
       " u'000 refugees',\n",
       " u'000 requests',\n",
       " u'000 revs',\n",
       " u'000 rhett',\n",
       " u'000 rpm',\n",
       " u'000 said',\n",
       " u'000 scoville',\n",
       " u'000 scovils',\n",
       " u'000 shooting',\n",
       " u'000 signs',\n",
       " u'000 simply',\n",
       " u'000 slaves',\n",
       " u'000 small',\n",
       " u'000 soldiers',\n",
       " u'000 sounds',\n",
       " u'000 square',\n",
       " u'000 standard',\n",
       " u'000 stars',\n",
       " u'000 start',\n",
       " u'000 starved',\n",
       " u'000 stem',\n",
       " u'000 stop',\n",
       " u'000 stress',\n",
       " u'000 subscribers',\n",
       " u'000 sum',\n",
       " u'000 test',\n",
       " u'000 tested',\n",
       " u'000 think',\n",
       " u'000 thousand',\n",
       " u'000 thumbs',\n",
       " u'000 time',\n",
       " u'000 times',\n",
       " u'000 titles',\n",
       " u'000 tonnes',\n",
       " u'000 tons',\n",
       " u'000 tosai',\n",
       " u'000 total',\n",
       " u'000 totals',\n",
       " u'000 track',\n",
       " u'000 transformed',\n",
       " u'000 trees',\n",
       " u'000 twitter',\n",
       " u'000 underwater',\n",
       " u'000 video',\n",
       " u'000 visitors',\n",
       " u'000 voted',\n",
       " u'000 votes',\n",
       " u'000 waffle',\n",
       " u'000 wanted',\n",
       " u'000 wanting',\n",
       " u'000 wheels',\n",
       " u'000 won',\n",
       " u'000 words',\n",
       " u'000 yeah',\n",
       " u'000 year',\n",
       " u'000 yearly',\n",
       " u'000 years',\n",
       " u'000 yen',\n",
       " u'000 yes',\n",
       " u'000 zeroes',\n",
       " u'0000000001',\n",
       " u'0000000001 speed',\n",
       " u'0007',\n",
       " u'0007 seconds',\n",
       " u'000cc',\n",
       " u'000cc mini',\n",
       " u'000krw',\n",
       " u'000krw winner',\n",
       " u'000of',\n",
       " u'000of ll',\n",
       " u'000rpm',\n",
       " u'000rpm 79mph',\n",
       " u'000rpm builds',\n",
       " u'000rpm feels',\n",
       " u'000th',\n",
       " u'000th okay',\n",
       " u'000th planck',\n",
       " u'000th width',\n",
       " u'002',\n",
       " u'002 percent',\n",
       " u'002 seconds',\n",
       " u'003',\n",
       " u'003 012',\n",
       " u'003 993',\n",
       " u'003 crosswise',\n",
       " u'004',\n",
       " u'004 997',\n",
       " u'004 times',\n",
       " u'005',\n",
       " u'005 reduction',\n",
       " u'007',\n",
       " u'007 super',\n",
       " u'008',\n",
       " u'008 drop',\n",
       " u'00am',\n",
       " u'00am took',\n",
       " u'01',\n",
       " u'01 00',\n",
       " u'01 03',\n",
       " u'01 04',\n",
       " u'01 07',\n",
       " u'01 10',\n",
       " u'01 102',\n",
       " u'01 11',\n",
       " u'01 13',\n",
       " u'01 17',\n",
       " u'01 18',\n",
       " u'01 21',\n",
       " u'01 26',\n",
       " u'01 30',\n",
       " u'01 31',\n",
       " u'01 32',\n",
       " u'01 35',\n",
       " u'01 37',\n",
       " u'01 39',\n",
       " u'01 40',\n",
       " u'01 41',\n",
       " u'01 43',\n",
       " u'01 46',\n",
       " u'01 48',\n",
       " u'01 49',\n",
       " u'01 52',\n",
       " u'01 53',\n",
       " u'01 55',\n",
       " u'01 56',\n",
       " u'01 57',\n",
       " u'01 96',\n",
       " u'01 97',\n",
       " u'01 aimee',\n",
       " u'01 average',\n",
       " u'01 diane',\n",
       " u'01 getting',\n",
       " u'01 got',\n",
       " u'01 jen',\n",
       " u'01 lakh',\n",
       " u'01 timmy',\n",
       " u'01 vertically',\n",
       " u'01 woman',\n",
       " u'01001110',\n",
       " u'01001110 39',\n",
       " u'0101',\n",
       " u'0101 whoo',\n",
       " u'0115',\n",
       " u'0115 39',\n",
       " u'012',\n",
       " u'012 39',\n",
       " u'012 mirror',\n",
       " u'01x00',\n",
       " u'01x00 02x01',\n",
       " u'02',\n",
       " u'02 00',\n",
       " u'02 02',\n",
       " u'02 03',\n",
       " u'02 05',\n",
       " u'02 08',\n",
       " u'02 09',\n",
       " u'02 11',\n",
       " u'02 13',\n",
       " u'02 14',\n",
       " u'02 15',\n",
       " u'02 16',\n",
       " u'02 17',\n",
       " u'02 19',\n",
       " u'02 21',\n",
       " u'02 25',\n",
       " u'02 26',\n",
       " u'02 27',\n",
       " u'02 28',\n",
       " u'02 29',\n",
       " u'02 30',\n",
       " u'02 31',\n",
       " u'02 32',\n",
       " u'02 33',\n",
       " u'02 34',\n",
       " u'02 36',\n",
       " u'02 39',\n",
       " u'02 40',\n",
       " u'02 41',\n",
       " u'02 45',\n",
       " u'02 47',\n",
       " u'02 48',\n",
       " u'02 52',\n",
       " u'02 53',\n",
       " u'02 54',\n",
       " u'02 55',\n",
       " u'02 56',\n",
       " u'02 57',\n",
       " u'02 58',\n",
       " u'02 59',\n",
       " u'02 comm',\n",
       " u'02 hi',\n",
       " u'02 timmy',\n",
       " u'021',\n",
       " u'021 molecular',\n",
       " u'026',\n",
       " u'026 gallons',\n",
       " u'02x01',\n",
       " u'02x01 say',\n",
       " u'02x01 won',\n",
       " u'03',\n",
       " u'03 00',\n",
       " u'03 01',\n",
       " u'03 04',\n",
       " u'03 05',\n",
       " u'03 08',\n",
       " u'03 10',\n",
       " u'03 12',\n",
       " u'03 13',\n",
       " u'03 15',\n",
       " u'03 17',\n",
       " u'03 18',\n",
       " u'03 21',\n",
       " u'03 22',\n",
       " u'03 23',\n",
       " u'03 24',\n",
       " u'03 25',\n",
       " u'03 26',\n",
       " u'03 29',\n",
       " u'03 31',\n",
       " u'03 32',\n",
       " u'03 36',\n",
       " u'03 37',\n",
       " u'03 38',\n",
       " u'03 39',\n",
       " u'03 40',\n",
       " u'03 42',\n",
       " u'03 44',\n",
       " u'03 45',\n",
       " u'03 50',\n",
       " u'03 51',\n",
       " u'03 53',\n",
       " u'03 54',\n",
       " u'03 57',\n",
       " u'03 59',\n",
       " u'03 aimee',\n",
       " u'03 jen',\n",
       " u'03 let',\n",
       " u'03 times',\n",
       " u'04',\n",
       " u'04 00',\n",
       " u'04 01',\n",
       " u'04 04',\n",
       " u'04 05',\n",
       " u'04 11',\n",
       " u'04 16',\n",
       " u'04 20',\n",
       " u'04 23',\n",
       " u'04 24',\n",
       " u'04 27',\n",
       " u'04 29',\n",
       " u'04 39',\n",
       " u'04 comm',\n",
       " u'04 nick',\n",
       " u'04 thank',\n",
       " u'040',\n",
       " u'040 177',\n",
       " u'0456789',\n",
       " u'0456789 run',\n",
       " u'05',\n",
       " u'05 comm',\n",
       " u'05 healthy',\n",
       " u'05 months',\n",
       " u'05 patch',\n",
       " u'05 pm',\n",
       " u'05 shelly',\n",
       " u'05 yuan',\n",
       " u'057s',\n",
       " u'057s iphone',\n",
       " u'06',\n",
       " u'06 39',\n",
       " u'06 lateral',\n",
       " u'060614',\n",
       " u'060614 didn',\n",
       " u'07',\n",
       " u'07 aged',\n",
       " u'07 comm',\n",
       " u'07 seconds',\n",
       " u'08',\n",
       " u'08 comm',\n",
       " u'08 somebody',\n",
       " u'082',\n",
       " u'082 round',\n",
       " u'085',\n",
       " u'085 volts',\n",
       " u'09',\n",
       " u'09 aug',\n",
       " u'09 nigger',\n",
       " u'09 richard',\n",
       " u'099',\n",
       " u'099 good',\n",
       " u'0l',\n",
       " u'0l 100',\n",
       " u'0l coyote',\n",
       " u'0s',\n",
       " u'0s 39',\n",
       " u'10 00',\n",
       " u'10 000',\n",
       " u'10 000th',\n",
       " u'10 10',\n",
       " u'10 100',\n",
       " u'10 11',\n",
       " u'10 116',\n",
       " u'10 12',\n",
       " u'10 13',\n",
       " u'10 14',\n",
       " u'10 15',\n",
       " u'10 15cm',\n",
       " u'10 15ft',\n",
       " u'10 18th',\n",
       " u'10 20',\n",
       " u'10 200',\n",
       " u'10 26',\n",
       " u'10 28',\n",
       " u'10 30',\n",
       " u'10 308',\n",
       " u'10 3391',\n",
       " u'10 39',\n",
       " u'10 3mkg',\n",
       " u'10 42',\n",
       " u'10 5682',\n",
       " u'10 60',\n",
       " u'10 6232',\n",
       " u'10 695',\n",
       " u'10 70',\n",
       " u'10 800',\n",
       " u'10 91',\n",
       " u'10 abhancer',\n",
       " u'10 absolute',\n",
       " u'10 aldwych',\n",
       " u'10 anti',\n",
       " u'10 backseat',\n",
       " u'10 bad',\n",
       " u'10 bangladeshi',\n",
       " u'10 bankers',\n",
       " u'10 barely',\n",
       " u'10 base',\n",
       " u'10 best',\n",
       " u'10 billion',\n",
       " u'10 bluetooth',\n",
       " u'10 brain',\n",
       " u'10 brazil',\n",
       " u'10 brazilian',\n",
       " u'10 buy',\n",
       " u'10 car',\n",
       " u'10 carry',\n",
       " u'10 cash',\n",
       " u'10 challenges',\n",
       " u'10 chance',\n",
       " u'10 characters',\n",
       " u'10 chernobyl',\n",
       " u'10 chicks',\n",
       " u'10 chinese',\n",
       " u'10 civilisations',\n",
       " u'10 classic',\n",
       " u'10 combine',\n",
       " u'10 comm',\n",
       " u'10 comma',\n",
       " u'10 commandments',\n",
       " u'10 counting',\n",
       " u'10 covered',\n",
       " u'10 craziest',\n",
       " u'10 daniel',\n",
       " u'10 days',\n",
       " u'10 decided',\n",
       " u'10 designs',\n",
       " u'10 different',\n",
       " u'10 digits',\n",
       " u'10 disastrous',\n",
       " u'10 dix',\n",
       " u'10 does',\n",
       " u'10 dollars',\n",
       " u'10 don',\n",
       " u'10 dots',\n",
       " u'10 dover',\n",
       " u'10 electronic',\n",
       " u'10 ending',\n",
       " u'10 ends',\n",
       " u'10 enrolled',\n",
       " u'10 episodes',\n",
       " u'10 equals',\n",
       " u'10 example',\n",
       " u'10 expect',\n",
       " u'10 faced',\n",
       " u'10 factorial',\n",
       " u'10 faster',\n",
       " u'10 feet',\n",
       " u'10 fewer',\n",
       " u'10 finally',\n",
       " u'10 flying',\n",
       " u'10 foil',\n",
       " u'10 fort',\n",
       " u'10 forth',\n",
       " u'10 friends',\n",
       " u'10 fucking',\n",
       " u'10 g3ps',\n",
       " u'10 game',\n",
       " u'10 gauge',\n",
       " u'10 gears',\n",
       " u'10 gin',\n",
       " u'10 good',\n",
       " u'10 google',\n",
       " u'10 got',\n",
       " u'10 gun',\n",
       " u'10 guys',\n",
       " u'10 hold',\n",
       " u'10 hope',\n",
       " u'10 hopefully',\n",
       " u'10 horsepower',\n",
       " u'10 hotdogs',\n",
       " u'10 hour',\n",
       " u'10 hours',\n",
       " u'10 iconic',\n",
       " u'10 idea',\n",
       " u'10 inaudible',\n",
       " u'10 inch',\n",
       " u'10 inches',\n",
       " u'10 jack',\n",
       " u'10 james',\n",
       " u'10 juizhaigou',\n",
       " u'10 juliane',\n",
       " u'10 jumping',\n",
       " u'10 kilos',\n",
       " u'10 km',\n",
       " u'10 know',\n",
       " u'10 lady',\n",
       " u'10 laughing',\n",
       " u'10 laughter',\n",
       " u'10 legion',\n",
       " u'10 levels',\n",
       " u'10 lie',\n",
       " u'10 life',\n",
       " u'10 like',\n",
       " u'10 likes',\n",
       " u'10 linda',\n",
       " u'10 list',\n",
       " u'10 little',\n",
       " u'10 logarithm',\n",
       " u'10 maceio',\n",
       " u'10 male',\n",
       " u'10 man',\n",
       " u'10 management',\n",
       " u'10 marbled',\n",
       " u'10 mark',\n",
       " u'10 maybe',\n",
       " u'10 means',\n",
       " u'10 megabytes',\n",
       " u'10 meters',\n",
       " u'10 metre',\n",
       " u'10 metres',\n",
       " u'10 midnight',\n",
       " u'10 mile',\n",
       " u'10 miles',\n",
       " u'10 millennia',\n",
       " u'10 million',\n",
       " u'10 millionth',\n",
       " u'10 minus',\n",
       " u'10 minute',\n",
       " u'10 minutes',\n",
       " u'10 mister',\n",
       " u'10 mkg',\n",
       " u'10 ml',\n",
       " u'10 mo',\n",
       " u'10 mph',\n",
       " u'10 nanometers',\n",
       " u'10 nature',\n",
       " u'10 new',\n",
       " u'10 number',\n",
       " u'10 ocean',\n",
       " u'10 offscreen',\n",
       " u'10 oh',\n",
       " u'10 ok',\n",
       " u'10 okapi',\n",
       " u'10 ordered',\n",
       " u'10 ounce',\n",
       " u'10 ounces',\n",
       " u'10 pacific',\n",
       " u'10 pairs',\n",
       " u'10 pants',\n",
       " u'10 participants',\n",
       " u'10 people',\n",
       " u'10 person',\n",
       " u'10 plus',\n",
       " u'10 pm',\n",
       " u'10 point',\n",
       " u'10 points',\n",
       " u'10 policemen',\n",
       " u'10 pounds',\n",
       " u'10 power',\n",
       " u'10 printer',\n",
       " u'10 questions',\n",
       " u'10 quot',\n",
       " u'10 races',\n",
       " u'10 rays',\n",
       " u'10 reais',\n",
       " u'10 respectively',\n",
       " u'10 ro',\n",
       " u'10 roll',\n",
       " u'10 ropes',\n",
       " u'10 rr',\n",
       " u'10 saber',\n",
       " u'10 sagittarius',\n",
       " u'10 savage',\n",
       " u'10 say',\n",
       " u'10 scenes',\n",
       " u'10 sec',\n",
       " u'10 second',\n",
       " u'10 seconds',\n",
       " u'10 secret',\n",
       " u'10 setup',\n",
       " u'10 sewer',\n",
       " u'10 shades',\n",
       " u'10 skunk',\n",
       " u'10 song',\n",
       " u'10 songs',\n",
       " u'10 sounded',\n",
       " u'10 spanish',\n",
       " u'10 speedy',\n",
       " u'10 spider',\n",
       " u'10 squared',\n",
       " u'10 stars',\n",
       " u'10 starts',\n",
       " u'10 stop',\n",
       " u'10 subscribers',\n",
       " u'10 sylvester',\n",
       " u'10 tea',\n",
       " u'10 teutonic',\n",
       " u'10 things',\n",
       " u'10 time',\n",
       " u'10 times',\n",
       " u'10 travelled',\n",
       " u'10 trillion',\n",
       " u'10 twin',\n",
       " u'10 types',\n",
       " u'10 unsportsmanlike',\n",
       " u'10 vingt',\n",
       " u'10 virgule',\n",
       " u'10 warheads',\n",
       " u'10 ways',\n",
       " u'10 weirdest',\n",
       " u'10 winners',\n",
       " u'10 wires',\n",
       " u'10 woody',\n",
       " u'10 wouldn',\n",
       " u'10 yeah',\n",
       " u'10 year',\n",
       " u'10 years',\n",
       " u'100',\n",
       " u'100 00',\n",
       " u'100 000',\n",
       " u'100 000th',\n",
       " u'100 100',\n",
       " u'100 102',\n",
       " u'100 105',\n",
       " u'100 15',\n",
       " u'100 150',\n",
       " u'100 16',\n",
       " u'100 1989',\n",
       " u'100 39',\n",
       " u'100 77',\n",
       " u'100 887',\n",
       " u'100 97',\n",
       " u'100 als',\n",
       " u'100 america',\n",
       " u'100 americans',\n",
       " u'100 amps',\n",
       " u'100 awesome',\n",
       " u'100 base',\n",
       " u'100 beards',\n",
       " u'100 believes',\n",
       " u'100 better',\n",
       " u'100 billion',\n",
       " u'100 brooms',\n",
       " u'100 bucks',\n",
       " u'100 carnivorous',\n",
       " u'100 cars',\n",
       " u'100 cent',\n",
       " u'100 charity',\n",
       " u'100 collars',\n",
       " u'100 concluded',\n",
       " u'100 controlled',\n",
       " u'100 countries',\n",
       " u'100 day',\n",
       " u'100 days',\n",
       " u'100 degrees',\n",
       " u'100 didn',\n",
       " u'100 different',\n",
       " u'100 dollars',\n",
       " u'100 duck',\n",
       " u'100 effort',\n",
       " u'100 electors',\n",
       " u'100 episodes',\n",
       " u'100 fahrenheit',\n",
       " u'100 fat',\n",
       " u'100 feet',\n",
       " u'100 fiesta',\n",
       " u'100 friends',\n",
       " u'100 fucked',\n",
       " u'100 game',\n",
       " u'100 good',\n",
       " u'100 gram',\n",
       " u'100 grit',\n",
       " u'100 height',\n",
       " u'100 hours',\n",
       " u'100 humans',\n",
       " u'100 international',\n",
       " u'100 invented',\n",
       " u'100 just',\n",
       " u'100 kilometers',\n",
       " u'100 kisses',\n",
       " u'100 km',\n",
       " u'100 left',\n",
       " u'100 living',\n",
       " u'100 look',\n",
       " u'100 lye',\n",
       " u'100 marketed',\n",
       " u'100 means',\n",
       " u'100 mentally',\n",
       " u'100 meter',\n",
       " u'100 meters',\n",
       " u'100 miles',\n",
       " u'100 million',\n",
       " u'100 millionths',\n",
       " u'100 mind',\n",
       " u'100 mistake',\n",
       " u'100 money',\n",
       " u'100 month',\n",
       " u'100 mortality',\n",
       " u'100 mother',\n",
       " u'100 names',\n",
       " u'100 nanometers',\n",
       " u'100 need',\n",
       " u'100 network',\n",
       " u'100 neuroscientists',\n",
       " u'100 new',\n",
       " u'100 numbers',\n",
       " u'100 pages',\n",
       " u'100 people',\n",
       " u'100 percent',\n",
       " u'100 perfect',\n",
       " u'100 pieces',\n",
       " u'100 pound',\n",
       " u'100 primary',\n",
       " u'100 prohibited',\n",
       " u'100 putting',\n",
       " u'100 quite',\n",
       " u'100 ready',\n",
       " u'100 reais',\n",
       " u'100 remaining',\n",
       " u'100 right',\n",
       " u'100 rooorrrww',\n",
       " u'100 rpm',\n",
       " u'100 safe',\n",
       " u'100 score',\n",
       " u'100 secure',\n",
       " u'100 seed',\n",
       " u'100 shounen',\n",
       " u'100 specific',\n",
       " u'100 starts',\n",
       " u'100 stranges',\n",
       " u'100 subscriptions',\n",
       " u'100 sure',\n",
       " u'100 taxes',\n",
       " u'100 things',\n",
       " u'100 think',\n",
       " u'100 times',\n",
       " u'100 tons',\n",
       " u'100 total',\n",
       " u'100 touch',\n",
       " u'100 trillion',\n",
       " u'100 unlockable',\n",
       " u'100 usda',\n",
       " u'100 used',\n",
       " u'100 ve',\n",
       " u'100 video',\n",
       " u'100 views',\n",
       " u'100 want',\n",
       " u'100 watt',\n",
       " u'100 watts',\n",
       " u'100 way',\n",
       " u'100 weeks',\n",
       " u'100 wombats',\n",
       " u'100 write',\n",
       " u'100 yard',\n",
       " u'100 yeah',\n",
       " u'100 years',\n",
       " u'100 yen',\n",
       " u'100 yes',\n",
       " u'1000',\n",
       " u'1000 birds',\n",
       " u'1000 calipers',\n",
       " u'1000 commonly',\n",
       " u'1000 different',\n",
       " u'1000 dollars',\n",
       " u'1000 levels',\n",
       " u'1000 liked',\n",
       " u'1000 mama',\n",
       " u'1000 members',\n",
       " u'1000 month',\n",
       " u'1000 names',\n",
       " u'1000 pages',\n",
       " u'1000 people',\n",
       " u'1000 psi',\n",
       " u'1000 state',\n",
       " u'1000 strom',\n",
       " u'1000 times',\n",
       " u'1000 year',\n",
       " u'1000 years',\n",
       " u'1000s',\n",
       " u'1000s years',\n",
       " u'1005',\n",
       " u'1005 pages',\n",
       " u'100g',\n",
       " u'100g candy',\n",
       " u'100g km',\n",
       " u'100gs',\n",
       " u'100gs test',\n",
       " u'100hp',\n",
       " u'100hp 39',\n",
       " u'100hp sharp',\n",
       " u'100k',\n",
       " u'100k dollars',\n",
       " u'100km',\n",
       " u'100km bad',\n",
       " u'100km hr',\n",
       " u'100ml',\n",
       " u'100ml 39',\n",
       " u'100mln',\n",
       " u'100mln korean',\n",
       " u'100mph',\n",
       " u'100mph just',\n",
       " u'100s',\n",
       " u'100s 200s',\n",
       " u'100s billions',\n",
       " u'100s cycles',\n",
       " u'100s used',\n",
       " u'100th',\n",
       " u'100th anniversary',\n",
       " u'100th cap',\n",
       " u'100th day',\n",
       " u'100th death',\n",
       " u'100th episode',\n",
       " u'101',\n",
       " u'101 39',\n",
       " u'101 big',\n",
       " u'101 bikes',\n",
       " u'101 cat',\n",
       " u'101 cats',\n",
       " u'101 dalmations',\n",
       " u'101 elephant',\n",
       " u'101 feet',\n",
       " u'101 homework',\n",
       " u'101 let',\n",
       " u'101 little',\n",
       " u'101 ok',\n",
       " u'101 plus',\n",
       " u'101 things',\n",
       " u'101 time',\n",
       " u'101 ultimate',\n",
       " u'101 using',\n",
       " u'101 visit',\n",
       " u'101 world',\n",
       " u'101 yeah',\n",
       " u'101 year',\n",
       " u'102',\n",
       " u'102 10404',\n",
       " u'102 39',\n",
       " u'102 bc',\n",
       " u'102 like',\n",
       " u'102 miles',\n",
       " u'102 seconds',\n",
       " u'102 squared',\n",
       " u'1020',\n",
       " u'1020 7212',\n",
       " u'1024',\n",
       " u'1024 threaded',\n",
       " u'102nd',\n",
       " u'102nd floor',\n",
       " u'103',\n",
       " u'103 104',\n",
       " u'104',\n",
       " u'104 completion',\n",
       " u'104 forestar',\n",
       " u'104 isn',\n",
       " u'104 squared',\n",
       " u'10404',\n",
       " u'10404 ok',\n",
       " u'105',\n",
       " u'105 110',\n",
       " u'105 completion',\n",
       " u'105 open',\n",
       " u'105 squared',\n",
       " ...]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1701, 531478)\n",
      "(567, 531478)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Predict using a random guess baseline\n",
    "\n",
    "Use a random classifier from `sklearn.dummy.DummyClassifier`.  Set `strategy=\"stratified\"`? Set `random_state=0`, to get the same result every time, since randomness is involved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dummy = DummyRegressor(strategy=\"median\")\n",
    "dummy.fit(X_train, Y_train)\n",
    "Y_pred_med = dummy.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error,mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_mse_score = mean_squared_error(Y_test, Y_pred_med)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96.4148158996\n"
     ]
    }
   ],
   "source": [
    "print(sqrt(my_mse_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Setup GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "def my_mae_scorer(estimator, X, y):\n",
    "    \"\"\"This function is just glue code for the scikit-learn scorer API.\n",
    "    See http://scikit-learn.org/stable/modules/model_evaluation.html#implementing-your-own-scoring-object\n",
    "    =Parameters=\n",
    "    estimator:\n",
    "        the model that should be evaluated (e.g., the scikit-learn classifier)\n",
    "    X: array-like, shape (n_samples, n_features)\n",
    "        the test data\n",
    "    y: array-like, shape (n_samples, n_labels)\n",
    "        the ground truth target for X.\n",
    "    =Returns:=\n",
    "    mae, float\n",
    "        the mean absolute error\"\"\"\n",
    "    y_pred = estimator.predict(X)\n",
    "    return mean_absolute_error(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Train and evaluate SVM Regression.\n",
    "\n",
    "We will use `sklearn.svm.SVR()\" as our initial classifier (Support Vector Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "svm_regression_classifier = SVR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma=0.0,\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_regression_classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_pred_svr = svm_regression_classifier.predict(X_test)\n",
    "my_mae_score_svr = mean_absolute_error(Y_test, Y_pred_svr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.3169876021\n"
     ]
    }
   ],
   "source": [
    "print(my_mae_score_svr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Train and evaluate Linear Regression.\n",
    "\n",
    "We will be using `sklearn.linear_model.LinearRegression()\" as an additional classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lreg_clf = LinearRegression(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    1.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "50.5050950168\n"
     ]
    }
   ],
   "source": [
    "grid = GridSearchCV(estimator=lreg_clf,\n",
    "                    param_grid=dict(normalize=[True,False]), \n",
    "                    scoring=my_mae_scorer,\n",
    "                    verbose=True)\n",
    "grid.fit(X_train, Y_train)\n",
    "best_params_lreg = grid.best_params_\n",
    "print(my_mae_scorer(grid.best_estimator_, X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.5050950168\n"
     ]
    }
   ],
   "source": [
    "print(my_mae_scorer(grid.best_estimator_, X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 51.12673, std: 2.20485, params: {'normalize': True}\n",
      "mean: 51.12673, std: 2.20485, params: {'normalize': False}\n"
     ]
    }
   ],
   "source": [
    "for score in grid.grid_scores_:\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Train and evaluate Lasso Regression.\n",
    "\n",
    "We will be using \"sklearn.linear_model.Lasso\" as an additional classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "lasso_clf = Lasso()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    0.0s\n",
      "C:\\Python27\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:444: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "grid = GridSearchCV(estimator=lasso_clf,\n",
    "                    param_grid=dict(alpha=[1,.9,.8,.7,.6,.5,.4,.3,.2,.1,.01,.001,.0001]), \n",
    "                    scoring=my_mae_scorer,\n",
    "                    verbose=True)\n",
    "grid.fit(X_train, Y_train)\n",
    "best_params_lasso = grid.best_params_\n",
    "print(my_mae_scorer(grid.best_estimator_, X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for score in grid.grid_scores_:\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.2. Train and evaluate Ridge Regression.\n",
    "\n",
    "We will be using \"sklearn.linear_model.Lasso\" as an additional classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.kernel_ridge import KernelRidge\n",
    "clf = KernelRidge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {'alpha': [1,.9,.8,.7,.6,.5,.4,.3,.2,.1,.01,.001,.0001,.000001], 'kernel': ['linear']},\n",
    "    {'alpha': [1,.9,.8,.7,.6,.5,.4,.3,.2,.1,.01,.001,.0001,.000001], 'kernel': ['rbf']},\n",
    "    {'alpha': [1,.9,.8,.7,.6,.5,.4,.3,.2,.1,.01,.001,.0001,.000001], 'kernel': ['polynomial'], 'degree' : [1,2,3,4]},\n",
    "    {'alpha': [1,.9,.8,.7,.6,.5,.4,.3,.2,.1,.01,.001,.0001,.000001], 'kernel': ['sigmoid']}\n",
    " ]\n",
    "grid = GridSearchCV(clf,\n",
    "                    param_grid,\n",
    "                    cv=3,\n",
    "                    scoring=my_mae_scorer,\n",
    "                    verbose=True)\n",
    "grid.fit(X_train, Y_train)\n",
    "best_params_kridge = grid.best_params_\n",
    "print(my_mae_scorer(grid.best_estimator_, X_test, Y_test))\n",
    "#mean: 35.91859, std: 1.46616, params: {'alpha': 0.01, 'kernel': 'linear'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for score in grid.grid_scores_:\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ElasticNet Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "en_clf = ElasticNet()\n",
    "param_grid = {'alpha': [1,.9,.8,.7,.6,.5,.4,.3,.2,.1,.01, .001, .0001], 'l1_ratio': [1,.9,.8,.7,.6,.5,.4,.3,.2,.1,.05]}\n",
    "grid = GridSearchCV(en_clf,\n",
    "                    param_grid,\n",
    "                    cv=3,\n",
    "                    scoring=my_mae_scorer,\n",
    "                    verbose=100)\n",
    "grid.fit(X_train, Y_train)\n",
    "best_params_en = grid.best_params_\n",
    "print(my_mae_scorer(grid.best_estimator_, X_test, Y_test))\n",
    "#mean: 35.91859, std: 1.46616, params: {'alpha': 0.01, 'kernel': 'linear'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for score in grid.grid_scores_:\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Create a query search\n",
    "\n",
    "Return the top ten search results for a given query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Key and version data \n",
    "DEVELOPER_KEY = \"AIzaSyBEuuLWPO0AJIIp7TVGIB1uM_mNiNkMVbw\"\n",
    "YOUTUBE_READ_WRITE_SCOPE = \"https://www.googleapis.com/auth/youtube\"\n",
    "YOUTUBE_API_SERVICE_NAME = \"youtube\"\n",
    "YOUTUBE_API_VERSION = \"v3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Authenticate \n",
    "youtube = build(YOUTUBE_API_SERVICE_NAME, YOUTUBE_API_VERSION, developerKey=DEVELOPER_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Returns the top ten search results for the query in the form \n",
    "   {video_id:{\"thumbnail\":thumbnail_url, \"title\":video title}}\"\"\"\n",
    "\n",
    "def query_search(query):\n",
    "    search_request = youtube.search().list(part=\"snippet\", q=query, maxResults=10, videoCaption=\"closedCaption\", type=\"video\")\n",
    "    \n",
    "    search_response = search_request.execute()\n",
    "    \n",
    "    search_results = {}\n",
    "    for search_result in search_response[\"items\"]:\n",
    "        video_id = search_result[\"id\"][\"videoId\"]\n",
    "        thumbnail = search_result[\"snippet\"][\"thumbnails\"][\"default\"][\"url\"]\n",
    "        title = search_result[\"snippet\"][\"title\"]\n",
    "        description = search_result[\"snippet\"][\"description\"]\n",
    "        search_results[video_id] = {\"thumbnail\":thumbnail, \"title\":title, \"description\":description}\n",
    "    \n",
    "    return search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "soup_search_results = query_search(\"soup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import nltk\n",
    "import urllib3\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def has_english(vid_id):\n",
    "    http = urllib3.PoolManager() #init urllib\n",
    "    resp = http.request('GET', 'http://video.google.com/timedtext',preload_content=False,\n",
    "                       fields={'type': 'list', 'v': vid_id})\n",
    "    sub_dir_xml = resp.read()\n",
    "    resp.close()\n",
    "    dir_soup = BeautifulSoup(sub_dir_xml)\n",
    "    eng_track = dir_soup.find(lang_code=\"en\")\n",
    "    return False if eng_track is None else True\n",
    "\n",
    "def get_transcript(vid_id):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "        vid_id: Youtube video id\n",
    "    Output:\n",
    "        transcript: Beautiful soup xml object of transcipt\n",
    "        of the format:\n",
    "        <transcript>\n",
    "            <text dur=\"DURATION_TIME\" start=\"START_TIME\">\n",
    "                SPOKEN TEXT\n",
    "            </text>\n",
    "        </transcript>\n",
    "    \"\"\"\n",
    "    http = urllib3.PoolManager() #init urllib\n",
    "    resp = http.request('GET', 'http://video.google.com/timedtext',preload_content=False,\n",
    "                       fields={'type': 'list', 'v': vid_id})\n",
    "    sub_dir_xml = resp.read()\n",
    "    resp.close()\n",
    "    dir_soup = BeautifulSoup(sub_dir_xml)\n",
    "    eng_track = dir_soup.find(lang_code=\"en\")\n",
    "    if eng_track is None:\n",
    "        return None\n",
    "    track_resp = http.request('GET', 'http://video.google.com/timedtext',preload_content=False,\n",
    "                               fields={'type': 'track',\n",
    "                                       'v':    vid_id, \n",
    "                                       'name': eng_track['name'].encode('unicode-escape'), \n",
    "                                       'lang': 'en'})\n",
    "    transcript_xml = track_resp.read()\n",
    "    track_resp.close()\n",
    "    return BeautifulSoup(transcript_xml).transcript\n",
    "\n",
    "def get_tokens(text):\n",
    "    text = re.sub(\"&#39;\", \"\\'\", text)\n",
    "    text = re.sub(\"\\n\", \" \", text)\n",
    "    text = re.sub(\"[:&%$#@!,.?]\", \"\", text)\n",
    "    return nltk.word_tokenize(text.lower())\n",
    "\n",
    "def format_transcript(transcript):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        beautifulsoup transcript\n",
    "    Outputs:\n",
    "        array/dictionary formatted transcript\n",
    "    \"\"\"\n",
    "    foramtted_transcript = []\n",
    "    for text_soup in transcript.find_all(\"text\"):\n",
    "        text = text_soup.get_text()\n",
    "        if len(text) > 0:\n",
    "            line = {\n",
    "                    'text'  : text,\n",
    "                    'dur'   : text_soup['dur'] if 'dur' in text_soup else 0,\n",
    "                    'start' : text_soup['start'] if 'start' in text_soup else 0\n",
    "                    }\n",
    "            foramtted_transcript.append(line)\n",
    "    return foramtted_transcript\n",
    "\n",
    "\n",
    "def get_flattened_transcript(vid_id):\n",
    "    transcript = get_transcript(vid_id)\n",
    "    flat_text = \"\"\n",
    "    if transcript is not None:\n",
    "        for text_soup in transcript.find_all(\"text\"):\n",
    "            text = text_soup.get_text()\n",
    "            if len(text) > 0:\n",
    "                flat_text += (text + \" \")\n",
    "    else:\n",
    "        return None # The case where we could not get the transcript\n",
    "    return flat_text[:-1]\n",
    "\n",
    "\n",
    "def get_formatted_transcript(vid_id):\n",
    "    \"\"\"\n",
    "    Convience method\n",
    "    \"\"\"\n",
    "    transcript = get_transcript(vid_id)\n",
    "    if transcript is None:\n",
    "        return None\n",
    "    return format_transcript(transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Assign conversationality scores to the videos returned and \n",
    "return a list with the video in ascending order of conversationality\n",
    "score. The final list consists tuple of the form (video_info dictionary, score).\"\"\"\n",
    "\n",
    "def rerank_search_results(model, search_results):\n",
    "    videos_with_score = [] # contain tuples of video dictionaries and their conversationality score\n",
    "    for video_id, video_info in search_results.iteritems():\n",
    "        flattened_transcript = get_flattened_transcript(video_id)\n",
    "        if flattened_transcript is not None: \n",
    "            vectorized_captions = tfv.transform([flattened_transcript]) # using previous vectorizer\n",
    "            conversationality_score = model.predict(vectorized_captions)\n",
    "            videos_with_score.append(({video_id : video_info}, conversationality_score[0]))\n",
    "        \n",
    "    return sorted(videos_with_score, key=itemgetter(1), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({u'9QiqibXv9Eo': {'description': u'All videos come with english captions. Please click the CC Button to activate english subtitles. \\u6240\\u6709\\u89c6\\u9891\\u90fd\\u5beb\\u4e0a\\u6709\\u82f1\\u6587\\u8aaa\\u660e\\u5b57\\u5e55, \\u8acb\\u6309CC \\u9215\\u63a3Please add me as ...',\n",
       "    'thumbnail': u'https://i.ytimg.com/vi/9QiqibXv9Eo/default.jpg',\n",
       "    'title': u'Chinese hot and sour soup, \\u9178\\u8fa3\\u6e6f'}},\n",
       "  16.244858248222585),\n",
       " ({u'mZyR2Ew66w8': {'description': u\"Magic Diet Soup - Lose Weight Fast - Low Gi. Well it worked for me and I have lost the weight and kept it off. So don't be scared, just try and see how I did it by ...\",\n",
       "    'thumbnail': u'https://i.ytimg.com/vi/mZyR2Ew66w8/default.jpg',\n",
       "    'title': u'Magic Diet Soup -  Lose Weight Fast - Low Gi.'}},\n",
       "  16.244858041687017),\n",
       " ({u'vZwfONmD54c': {'description': u'Sweet Corn Soup,delicate and pleasant flavour of corn makes this a popular choice. Recipe link : http://www.tarladalal.com/Sweet-Corn-Soup-(-Soup-)-37393r ...',\n",
       "    'thumbnail': u'https://i.ytimg.com/vi/vZwfONmD54c/default.jpg',\n",
       "    'title': u'Sweet Corn Soup by Tarla Dalal'}},\n",
       "  16.244858033535834),\n",
       " ({u'O9ak89FwYeI': {'description': u'Twitter: http://www.twitter.com/tweetsauce Instagram: http://www.instagram.com/electricpants ***EXTRA INFO AND SOURCES BELOW*** Vsauce2: ...',\n",
       "    'thumbnail': u'https://i.ytimg.com/vi/O9ak89FwYeI/default.jpg',\n",
       "    'title': u'Is Cereal Soup?'}},\n",
       "  16.244857525236686),\n",
       " ({u'GojmNjoTaTg': {'description': u'LIVE EVENT WITH EMERIL & LAURA: https://www.youtube.com/watch?v=lnDSYdUp1hA To get this complete recipe with instructions and measurements, check ...',\n",
       "    'thumbnail': u'https://i.ytimg.com/vi/GojmNjoTaTg/default.jpg',\n",
       "    'title': u'Loaded Potato Soup Recipe - Laura Vitale - Laura in the Kitchen Episode 863'}},\n",
       "  16.244857073823216),\n",
       " ({u'1xrhaL3WmaY': {'description': u\"If you haven't got a failsafe soup recipe in your arsenal than look no further than this tasty offering from Vegetarian cook Anna Jones. From one batch of sweet potato and ...\",\n",
       "    'thumbnail': u'https://i.ytimg.com/vi/1xrhaL3WmaY/default.jpg',\n",
       "    'title': u'Easy Vegetable Soup - Three Ways | Anna Jones'}},\n",
       "  16.244856752269577),\n",
       " ({u'L1TFnkm1TG8': {'description': u'Click here to SUBSCRIBE: http://bit.ly/1dn24vP Shop this video here: https://rdy.cr/dac6c6 Homemade Vegetable Stock: http://bit.ly/1vAte5U 3 Mac & Cheese ...',\n",
       "    'thumbnail': u'https://i.ytimg.com/vi/L1TFnkm1TG8/default.jpg',\n",
       "    'title': u'Fall Soup - 3 Delicious Ways'}},\n",
       "  16.244856654118454),\n",
       " ({u'xqFo59YveXo': {'description': u'Food Busker is hitting the streets with another incredible recipe: Ramen noodles layered with finely sliced fresh vegetables and shredded chicken in an Asian ...',\n",
       "    'thumbnail': u'https://i.ytimg.com/vi/xqFo59YveXo/default.jpg',\n",
       "    'title': u'Chicken Ramen Noodle Soup | Food Busker'}},\n",
       "  16.24485657861317)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rerank_search_results(svm_regression_classifier, soup_search_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Use grid search and cross-validation to tune the classifier\n",
    "\n",
    "The score above is pretty disappointing, but kind of expected, given how little work we did-- we are basically just using the default configuration.  A `LinearSVC` has a bunch of configuration options that should be tweaked:\n",
    "\n",
    "* `C` is the *regularization parameter*. Lower values of C constraint the model more, while higher values allows the model to fit the training data better. (Remember that fitting the training data too well can lead to overfitting.)\n",
    "\n",
    "* `class_weight` can force the classifier to emphasize positive instances more or less than negative ones. This is useful if we know for a fact that the classes aren't equally probable. Read the documentation and see what the `'auto'` setting does.\n",
    "\n",
    "However, choosing these values should also be done without looking at the test data, because they are part of the model. Use `sklearn.grid_search.GridSearchCV` to systematically try out different values for these two parameters, and choose the configuration that does best.\n",
    "\n",
    "`GridSearchCV` uses k-fold cross-validation to ensure fair evaluation and avoid overfitting. This consists of splitting the training data into *k* parts, then training the classifier *k* times, each time leaving out a different part, that is used for scoring. The average score over the *k* folds is a better estimate of how well the classifier would generalize.\n",
    "\n",
    "Because we are facing a multi-label problem, the default scoring strategy (accuracy) doesn't make sense. We have to define our own `sample_f1_scorer` strategy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sample_f1_scorer(estimator, X, y):\n",
    "    \"\"\"sample-f1 scorer metric\n",
    "    \n",
    "    This function is just glue code for the scikit-learn scorer API.\n",
    "    See http://scikit-learn.org/stable/modules/model_evaluation.html#implementing-your-own-scoring-object\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    \n",
    "    estimator:\n",
    "        the model that should be evaluated (e.g., the scikit-learn classifier)\n",
    "    X: array-like, shape (n_samples, n_features)\n",
    "        the test data\n",
    "    y: array-like, shape (n_samples, n_labels)\n",
    "        the ground truth target for X.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    \n",
    "    sample_f1_score, float\n",
    "        the sample F1 score as used in Q06 and Q07\n",
    "    \"\"\"\n",
    "    y_pred = estimator.predict(X)\n",
    "    return f1_score(y, y_pred, average='samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, run grid search over a range of regularization parameters, as below.  This takes under 1 minute on a 2014 MacBook Pro Retina. If you're not sure your code works, test it on a small number of documents first to avoid wasting time.\n",
    "\n",
    "What is the best configuration, and the best score (averaged over the 3 folds)? (there are attributes of the `GridSearchCV` object that answer this).\n",
    "\n",
    "DISCUSSION ITEM.\n",
    "What can you say about the impact of `C` and `class_weight` on the score? (look at `grid.grid_scores_` to answer this)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param_grid = dict(\n",
    "    estimator__C=[1e-3, 1e-2, 1e-1, 1, 1e1, 1e2, 1e3],  # you can also build this using np.logspace\n",
    "    estimator__class_weight=['auto', None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ovr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-9233726c6da1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m grid = GridSearchCV(ovr,\n\u001b[0m\u001b[0;32m      2\u001b[0m                     \u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                     \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                     \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_f1_scorer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                     verbose=True)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ovr' is not defined"
     ]
    }
   ],
   "source": [
    "grid = GridSearchCV(ovr,\n",
    "                    param_grid,\n",
    "                    cv=3,\n",
    "                    scoring=sample_f1_scorer,\n",
    "                    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grid.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Evaluate the chosen classifier on the test set. Inspect performance on individual categories.\n",
    "\n",
    "Use `grid.best_estimator_` to access the `ovr` object chosen as best by the grid search. Use `sample_f1_scorer` and report the **sample F1** score as in Q06 and Q07. This time, you should see a rewarding increase.\n",
    "\n",
    "DISCUSSION ITEM.\n",
    "Compare this score with the cross-validated average score over the 3 folds for the best model (Q08).  Does cross-validation give a reasonable estimate of the actual generalization performance a model can get on unseen test data? Compare with what we saw in class, when we were looking at the performance of a classifier on the data it was trained on, versus on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grid_f1_score = sample_f1_scorer(grid.best_estimator_, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(grid_f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** TODO discuss **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Then, to aggregate scores over individual categories, use `sklearn.metrics.classification_report`. Keep in mind that in the classification report, precision, recall and F1 have different meaning than the sample-based scores we used in the previous questions: they are averages over a given label, as opposed to a given document.\n",
    "\n",
    "DISCUSSION ITEM. How do you interpret this table?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_pred_test_grid = grid.predict(X_test)\n",
    "grid_report = classification_report(Y_test, Y_pred_test_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(grid_report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
