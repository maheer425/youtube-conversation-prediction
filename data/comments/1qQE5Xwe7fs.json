{
    "comment_thread": {
        "z134etchntjdzl5xv04cfbioaojwilrwiww0k": {
            "top_comment": {
                "date": "2014-07-14T19:42:13.779Z", 
                "text": "*Moore\u2019s Law and the secret world of ones and zeros*\nhttp://adafru.it/b121610\n\n*SciShow explains how SciShow exists \u2014 and everything else that\u2019s ever been \nmade or used on a computer \u2014 by exploring how transistors work together in \ncircuits to make all computing possible. Like all kinds of science, it has \nits limitations, but also awesome possibilities.*\n\n*Read more*: http://adafru.it/b121610\ufeff", 
                "author": "Adafruit Industries"
            }, 
            "comments": [
                {
                    "date": "2014-07-15T15:16:20.810Z", 
                    "text": "I agree completely", 
                    "author": "david moloney"
                }, 
                {
                    "date": "2014-07-15T15:04:54.222Z", 
                    "text": "+david moloney 3d stacking works remarkably well for solid state storage, \nbut I'd be concerned about doing it too much on processing chips.  Mostly \nbecause of the heat problems.  (current chips already produce a massive \namount of waste heat, stuffing even more transistors on them without doing \nsomething about all that waste will result in issues keeping it cool.)", 
                    "author": "Jonathon Wyza"
                }, 
                {
                    "date": "2014-07-15T08:51:32.770Z", 
                    "text": "Extremely dumbed down - 3d stacking means moores law (planar 2d scaling) is \nover from an economic perspective ", 
                    "author": "david moloney"
                }, 
                {
                    "date": "2014-07-15T07:00:26.316Z", 
                    "text": "+12f9264 Zooz It's a Google+ thing...", 
                    "author": "RedPirateGaming"
                }, 
                {
                    "date": "2014-07-15T01:22:45.868Z", 
                    "text": "?", 
                    "author": "Distant horizon"
                }
            ], 
            "num_replies": 5
        }, 
        "z12csf5ivxzyyxzjd04cfpj5sp2byd154z00k": {
            "top_comment": {
                "date": "2014-07-14T10:56:21.620Z", 
                "text": "The most simplistic explanation of basic electronics and computer science . \nI am convinced that this video has the capability to teach more than entire \ndegrees in many schools which will take years to attain and finally get a \npiece of paper which may or may not represent actual capabilities of the \nindividual in question .\nSimple science in simple words. Just Awesome!!!! \ufeff", 
                "author": "Adith Bhat"
            }, 
            "comments": [
                {
                    "date": "2015-03-07T13:40:43.000Z", 
                    "text": "+Matt  McGoo  Why post such a rant when it adds nothing to the topic?  When \nfacts are misrepresented, everybody loses.  If you want to be entertained, \ngo watch a movie, but when you want to be educated you don't want to have \nto second guess the source material.  Its one thing to omit details for the \nsake of concise clarity, but quite another to put forth contradicting \nmaterial.  \n\nI'll stand by what I posted, to help increase the viewers knowledge on the \ntopic.  ", 
                    "author": "Larry Serflaten"
                }, 
                {
                    "date": "2015-03-07T08:18:49.000Z", 
                    "text": "+Larry Serflaten and the others above talking about how not perfectly \naccurate to a science degree his info is, holy fuck mate this is a simple \nexplanation of a complex subject for the average person to understand. Hank \nis not making these clips to teach a degree in what ever subject he is \ntalking about. maybe you need to stop watching these clips if you find they \nare not detailed enough for you and stop being a whine bitch and make a \nclip of your own that explains science in so much detail most people don't \nunderstand and find boring and get fuck all subs then you might realize why \nhe does things the way he does", 
                    "author": "Danger Mouse"
                }, 
                {
                    "date": "2015-03-05T07:57:44.506Z", 
                    "text": "Dude, he barely explained anything about how a computer works. He didn't \neven mention logic gates. I'm not sure what you thought you got out of \nthis, but it was a world away from what actually studying computer \nengineering (or science) would convey. As you said, \"the most simplistic\" \nand conveying the least possible information while still getting across his \npoint.", 
                    "author": "NickRoman"
                }, 
                {
                    "date": "2015-02-11T06:40:47.934Z", 
                    "text": "+Rafael Silva While it's true there is a working quantum computer, it does \nvirtually nothing right now. No coding language existed for it, so it does \nVERY simple operations, it just does them absurdly fast.", 
                    "author": "OgreSamanosuke"
                }, 
                {
                    "date": "2014-09-22T18:34:02.886Z", 
                    "text": "This video is accurate up to 2003, when we already started with more chips \non the same board, also much development on quantum computers and optics \nfiber communication as been done (Google and NASA already have a quantum \ncomputer, NSA is probably breaking our banks passwords with it)", 
                    "author": "Rafael Silva"
                }, 
                {
                    "date": "2014-09-21T18:31:57.822Z", 
                    "text": "It would be nice if they were more accurate in their explanations.  3:40 - \nThe transistor has two modes, on and off.  True for digital circuitry, but \nmisleading on the whole.  Transistors also provide amplification, producing \nlarge changes in output current from small changes in input current.  They \nshould have prefaced their discussion with something like; 'When \ntransistors are used as a switch, they are either on or off'.  5:10 - The \ntransistor can only manage one byte of data at a time.  A digital switch is \neither on or off, that's 1 bit of data, not 8. It takes 8 transistors to \nhandle the 8 bits of a byte.  (as was stated previously in the video!) 7:19 \n- Electrons travel at 8.5 cm/hr.  While true, it is misleading to think the \nelectrons that were engaged at the switch are the same electrons that first \nlight the lamp.  The light switch produces a change in potential energy on \nthe wire, and that potential change travels down the wire at nearly the \nspeed of light.  So the statement; 'That's fast enough when the electrons \nonly have to travel 32 nanometers, but other stuff can move a lot faster' \ncauses a misunderstanding of the concept.  While no one can be a master of \nall knowledge, it would pay to apply due diligence when researching and \nauthoring the material especially when dealing with established facts and \nsubject matter.", 
                    "author": "Larry Serflaten"
                }, 
                {
                    "date": "2014-07-25T03:11:34.255Z", 
                    "text": "I agree. I bet you that all my friends who graduated from computer science \ndon't know this.", 
                    "author": "wbgsci"
                }, 
                {
                    "date": "2014-07-15T16:57:23.751Z", 
                    "text": "+theonlyari I would not see a doctor without a degree, agreed. As for \ncomputer science and electronics, I am of the opinion that the stuff has to \nbe inside rather than any certificate. Agreed degree has been the GOTO way \nup until now but you see with all the technology around, competition and \nthe demand to innovate being so high, may be it's time we need to rethink \nthe classroom and exam environment. \nPeace!!!! ", 
                    "author": "Adith Bhat"
                }, 
                {
                    "date": "2014-07-15T16:40:09.015Z", 
                    "text": "False...ish. Source: Real, working, electrical engineer. As for the piece \nof paper which says \"DEGREE!!\"-- i know people with degrees who dont know \ntheir elbow from their... well you know... And there are a number of people \nout there without degrees who are much smarter than me-- but they are few \nand far between. For most everyone else out there, you need the degree. \nFormal training in any area is better than no training at all. I mean would \nyou go see a doctor without a degree?", 
                    "author": "theonlyari"
                }, 
                {
                    "date": "2014-07-15T06:48:08.088Z", 
                    "text": "+Robert Loren Ursua I have a formal computer science degree and of course, \ncurriculum included everything you have mentioned above. Never the less , I \nstill cannot make a computer all by myself as in manufacture and not just \nassembling and to be honest and I don't think anybody around me with \ndistinction grade degrees can do it either. Anyway all this is besides the \npoint. \nI have my opinion and you have yours. I don't think either of us were \ntrying to state facts because clearly your opinion that my bold statement \nis plain wrong is not a fact either because I know countless people who \nhave great degrees and still cannot do anything you mentioned above. \nPeace!!! ", 
                    "author": "Adith Bhat"
                }, 
                {
                    "date": "2014-07-15T06:19:18.217Z", 
                    "text": "+ADITH BHAT \"I am convinced that this video has the capability to teach \nmore than entire degrees\". This video doesn't enable you to do shit. You \ndon't need sources to debunk that. does this teach you about logic gates? \nDoes this teach you about How to make them? Does it teach you about ALU's? \nDigital signal processing? Does it teach you enough to know how to make a \ncomputer? Nope nope nope nope.\n\nYou made a bold statement, and I applaud you for that. But it's just wrong.", 
                    "author": "Robert Loren Ursua"
                }, 
                {
                    "date": "2014-07-15T04:48:50.000Z", 
                    "text": "+Robert Loren Ursua can you be more precise? Post the link for the source\ufeff. \nOh well, yeah people from academics will say this as false. Not really \nsurprised there. ", 
                    "author": "Adith Bhat"
                }, 
                {
                    "date": "2014-07-15T04:37:10.412Z", 
                    "text": "false. Source: Computer engineering major", 
                    "author": "Robert Loren Ursua"
                }
            ], 
            "num_replies": 13
        }, 
        "z12sgjijnt3ltnce223zwzswopq5ibcy304": {
            "top_comment": {
                "date": "2014-07-13T13:52:08.437Z", 
                "text": "Temporary solution; make the processors bigger in size. Sure we'll need to \ndevelop new motherboards that support them but so what? Processors are some \nof the smallest components in a pc- but why\ufeff", 
                "author": "cheatingthesystem21"
            }, 
            "comments": [
                {
                    "date": "2015-03-31T03:13:56.466Z", 
                    "text": "+BloodEyePact not if we use helium cooling like smartphones", 
                    "author": "the official \u201csandidge02\u201d .sandidge02"
                }, 
                {
                    "date": "2015-03-14T17:56:59.876Z", 
                    "text": "+Arturo Gutierrez It's not about the distance, but about the capacitance of \nthe input gate of the transistor... bigger transistors have bigger gates \nand a lower max. frequency... ;)", 
                    "author": "0815egal0815"
                }, 
                {
                    "date": "2014-12-21T00:58:02.847Z", 
                    "text": "+ReaLzEdits\nI think lower power consumption and higher resulation is the way of the \nfeature not just higher clock speeds on the GPU but also making ways of the \nother components to run better to produce the output resaltion required by \nthe card for the monitor. That and making them so they can handle more at \nthe same time which as seen with Server CPUs sometimes requires the \nprocessor to run slower but with more cores to get more done in the same \namount of time. Optimizeing the GPU can only go so far until they have to \nwork on more than just that one part to get a better card to the consumer \nyes i do agree. The real question is what is next? The base JEDEC spec for \nGDDR5 is DDR3 and now we have DDR4 so hopefully there will be a better kind \nof Video RAM coming soon. I also think that dual GPU configurations are \ngoing to come around again but the fad of them being on the same card as \neach other instead of SLI / Crossfire. This is because atm anyways it is \ninpossiable to achive max quailty in graphics well running at 3840x2160 or \nhigher to which there are already manufactuers working on 8k monitors 1 \neven featured it at the 2014 CES.\nSo dual GPUs are going to make a come back due to just pure power required \nto get the job done for the newer displays. Will 8k ever catch on because \n4k is haveing trouble and 4k really hasnt caught on as of yet mainly \nbecause of everyone thinking 1080p is the thing that everything that they \nwant is made for anyhow or beleiveing the myth that 4k and 1080p are the \nsame on the screen or somethign else. the thing of 4k and 1080p beign the \nsame is true to a point but with bigger screens it becomes less and less \ntrue.\nso 4k and 8k might be driveing the GPU makers to devlop for more demanding \nspecs espcially with the newer stuff haveing massive particale counts \ncompared to the older games. I am assuming this b/c of how the newer games \nlook on the newer consoles compared to their counter parts on the older \nconsoles and how they look on PC on Ultra vs low.\nSo dual GPU cards are coming till nVidia and AMD can find out how to do it \nwith a single GPU in that also liquid cooling is coming around again. I say \nagain as liquid cooling was before air cooling was a thing. as dual GPUs \nwill genetate a ton of heat but then you have a ton of ppl who are just \nadverse to liquid cooling all together and thus will opt to go with a older \nsingle GPU card compared to the newer dual GPU card.\nPower devliery to the GPUs will also change to get the right amount of \npower to the correct GPU at the right time.\nbut my rant is getting kinda long so i will end it here it is longer but \nthat is enough for now.", 
                    "author": "yumri4"
                }, 
                {
                    "date": "2014-12-21T00:31:12.814Z", 
                    "text": "+yumri4  Sorry to revive a dead thread but....\nSome gpu chips might be faster than nvidia's but nvidia is keeping up the \nsame pace as amd while having much smaller and less power hungry chips..... \nSo when enough time passes amd will lose control of the market to \nnvidia..... Like it has now because you cant simply keep throwing more \npower and clock speeds and hopefully it beats whatever your competitors \nhave.", 
                    "author": "ReaLzEdits"
                }, 
                {
                    "date": "2014-12-15T18:16:03.866Z", 
                    "text": "+Ratchet\nNo, proccesors are small because the silicon they are built on is a large \npart of the cost, and the amount of errors in the actual building increases \nas you increase die size. So,  bigger CPU would simply be a lot higher in \ncost. This is the reason everything gets cheaper: it's not cheaper to \nbuild, it just needs less silicon and silicon is your major cost.", 
                    "author": "Vaes Joren"
                }, 
                {
                    "date": "2014-12-09T01:50:11.000Z", 
                    "text": "Clearly is needed other approach, the classic Von Newman architecture don't \nwork anymore, that's why most of computer companies are scanning the human \nbrain to build chips that work in the same way, the race for smaller sizes \nis not the solution, the new neuromorphic processors are 176000 time more \nefficient than their classic counterpart. In those systems the motherboard \ndisappears and is completely absorbed by the neural chip. the 100% of the \ncomputer is the neurosynaptic chip, it represent a Huge increase in \ncapacity which is scalable adding more chips and the best part... if one \nzone is damaged the chip keeps working with no problems. So 3D computing \ncan be finally implemented because clocks, heatsinks and fans are not \nneeded with these chips so no more problems with heat. With Graphene and \nhigh temp Quantum computing the power of computers will explode again. The \nMoore's Law is just the beginning. \nAnd a silicon wafer for microprocessors of the latest generation is gram \nfor gram the most expensive piece of metal on the planet, more than gold or \ndiamond. People basically pay for a small slice of technology in the form \nof an Intel i7 or Qualcomm Snapdragon for its smartphones.", 
                    "author": "Carlos Herrera"
                }, 
                {
                    "date": "2014-07-29T10:49:37.145Z", 
                    "text": "+Lewis Rainwater no, processors are small because there's a demand for \nsmall processors, what would you rather have a computer that needs a large \nroom to fit or a computer the size of your phone. Electron drift speed has \nabsolutely no impact in this.", 
                    "author": "Ratchet"
                }, 
                {
                    "date": "2014-07-28T23:06:09.938Z", 
                    "text": "The reason the processor is so small is because the electrons move slow. \nThat is what give the processor it's GHz i believe. It's subtly mentioned \nin t\ne video.", 
                    "author": "Lewis Rainwater"
                }, 
                {
                    "date": "2014-07-28T16:47:59.189Z", 
                    "text": "yes i do to most likely graphene when and if we can ever find out how to \nsynthetically replicate it on a mass scale of course ", 
                    "author": "yumri4"
                }, 
                {
                    "date": "2014-07-28T16:23:57.871Z", 
                    "text": "+yumri4 one does not simply change the size of an atom, without spliting it \n(unless you mean changing the element used see: carbon - graphene)", 
                    "author": "lily dee"
                }, 
                {
                    "date": "2014-07-26T15:18:27.008Z", 
                    "text": "yes but what i was getting at was making those atoms smaller instead of \nmakeing them less atoms ", 
                    "author": "yumri4"
                }, 
                {
                    "date": "2014-07-26T15:10:08.675Z", 
                    "text": "+yumri4 changing material will not world physics. Once transistors become \nless than 5 atoms thick Heisenberg uncertainty principle kicks in. ", 
                    "author": "Ratchet"
                }, 
                {
                    "date": "2014-07-26T14:29:37.523Z", 
                    "text": "+RealRatchet1 where ever did i say we would be going to quantum based \ncomputers? just a material change to get smaller is all. In that yes i do \nregonize that quantum computers would be slower for working on Word, Excel \nand Internet browsing.", 
                    "author": "yumri4"
                }, 
                {
                    "date": "2014-07-26T08:47:15.838Z", 
                    "text": "+yumri4 quantum computers cannot replace regular gate logic computers, \nbecause ironically for every day tasks quantum computers would be slower.", 
                    "author": "Ratchet"
                }, 
                {
                    "date": "2014-07-26T04:33:14.535Z", 
                    "text": "+XMcEvilson\nin short what i ment was that the newer gens of CPUs and probably Graphics \nprocessors, network processors and sound processors will be based on a \ndiffenret material to get more speed and/or more done at a lower speed \nwhich ever works better in the design teams mind.\nsilicon is on the way out on the newer generations but silicon is here to \nstay for a long long time on the already exsisting devices as they are so \nmany of silicon based chips in computers already.", 
                    "author": "yumri4"
                }, 
                {
                    "date": "2014-07-26T02:29:13.929Z", 
                    "text": "+yumri4 billions of them are in use, so they're not going to be around much \nlonger. nice logic", 
                    "author": "XMcEvilson"
                }, 
                {
                    "date": "2014-07-26T00:13:18.796Z", 
                    "text": "+RealRatchet1 at the moment i do not think silicon based chips are going to \nbe around to much longer but another material instead which can be used on \na even smaller scale. But i do foresee a materal change before moveing onto \nquantum computers or even optical computers in the main stream. optical \ncomputers are stupid expenive atm anyways.", 
                    "author": "yumri4"
                }, 
                {
                    "date": "2014-07-25T19:32:07.000Z", 
                    "text": "+yumri4 I did mean stacking cores. Making the circuit 3D itself wouldn't \nreally solve anything in the long run and most likely create even more \nproblems. Either way it's interesting to see how these things will be \ntackled in the future, considering silicon based chips are here to stay \neven when quantum computers become available.", 
                    "author": "Ratchet"
                }, 
                {
                    "date": "2014-07-25T18:05:04.274Z", 
                    "text": "+RealRatchet1 though even then wouldnt they only do that for the processor \ncores and nothing else as it only makes sense to do stacking for more cores \nand/or a bigger GPU side of the chip. Otherwise i cannot see why to make a \n3D lay out chip compared to a 2D lay out chip design ... unless it is \nrequire by the material used to go even smaller of course", 
                    "author": "yumri4"
                }, 
                {
                    "date": "2014-07-25T17:00:30.839Z", 
                    "text": "+Arturo Gutierrez it would have no noticeable impact on speed, not on this \nscale. Only thing that slows down a chip is the logic gates itself, due to \ntime it takes to switch states, not the travel through the wire, which is \nconsidered instantaneous. The real problem is cooling and and defect \nprobability. It's much easier just to stack processors, but even then 2 \nprocessors don't mean 2 times the speed, the relationship between \ncalculation speed and amount of processors is logarithmic even in simplest \nmultiprocessor programs.", 
                    "author": "Ratchet"
                }
            ], 
            "num_replies": 33
        }, 
        "z12mc12rzmzdeffdc23dvrw45n2kgj30y": {
            "top_comment": {
                "date": "2014-07-13T10:05:55.560Z", 
                "text": "Is it not possible to just make the area we use for a chip larger? I mean \nit's cool that we've been able to use the standard size for so long, but \nwouldn't just having a bigger chip allow for one processor that is faster?\ufeff", 
                "author": "Useless Noise"
            }, 
            "comments": [
                {
                    "date": "2014-07-13T17:22:13.737Z", 
                    "text": "As a follow up to my previous statement, Moore's Law also doesn't say \nanything about CPU speed increasing.\nOnce you can reduce the size (and therefore cost) of transistors you can do \nseveral different things:\n1. Increase CPU speeds economically because you can now fit more CPUs on a \nsingle wafer and test them to find the good ones.\n2. Keep CPU speed the same but improve performance by adding more on-die \nmemory cache (something that takes up a huge area of silicon) or more CPU \ncores.\n3. Improve reliability for a given CPU speed by adding redundancy.\n4. Do nothing with CPU speed and simply improve profit margin by increasing \nthe number of CPUs on a wafer.\n5. Numerous other things like reducing voltage and heat.\n\nOutside of high-end desktop CPUs, the focus on Moore's Law is mainly to do \nwith option 4. Many industry profit forecasts are based on whether it is \nprofitable to do a \"die-shrink\" in order to cram more ICs on a single wafer.\n\nAlso, wafer costs come down over time as manufacturing processes improve. \nSo there is a cost/benefit analysis to be done for increasing the size of \nthe wafer. You can fit more dies on a larger wafer (and more efficiently \nsince you can't normally put square dies on the edge of around wafer), but \na larger wafer is harder to manufacture and will be more expensive.\nThis, I think, is an important part of Moore's Law that often gets \noverlooked as the focus is normally on the sexy headlines related to \nreducing the size of the transistor (see Intel's oft-publicized \nannouncements of their new xx nm process).", 
                    "author": "Chris Baker"
                }, 
                {
                    "date": "2014-07-13T17:06:38.407Z", 
                    "text": "I think this is a common misconception about Moore's Law. The original \nstatement by Gordon Moore related the cost of putting transistors onto a \nwafer, not the number of transistors total. The reason it often gets \nconflated with transistor count is because one of the biggest costs in \nmanufacturing ICs is the cost of the raw silicon wafer itself.\nSo, the end result is that we are really concerned with increasing the \nnumber of transistors in a given area of silicon. Thus increasing the size \nof a chip would allow more transistors but would not have any bearing on \nthe trend since transistors/cm^2 would remain the same.\nAnd, in fact, there is no standard size for a CPU die. They are made as \nsmall as possible in order to cram as many onto a single silicon wafer as \npossible. More dies = more CPUs you can sell. (And, as TheDesius said, at \nsome size the propagation delay across the chip becomes an important factor \nthat complicates the design.)", 
                    "author": "Chris Baker"
                }, 
                {
                    "date": "2014-07-13T12:02:55.038Z", 
                    "text": "more travel time between the 2 furthest transistors, so the chip would get \nslower instead of faster.", 
                    "author": "TheDesius"
                }
            ], 
            "num_replies": 3
        }, 
        "z13zwfhjnrvdvbgq204cd3oylyjvg5aakto0k": {
            "top_comment": {
                "date": "2014-07-13T16:49:38.360Z", 
                "text": "Quantum computers are the future.\ufeff", 
                "author": "gladwin tirkey"
            }, 
            "comments": [
                {
                    "date": "2014-07-17T10:58:25.213Z", 
                    "text": "+Toasted Lego That's exactly what I said.", 
                    "author": "gerry7man555"
                }, 
                {
                    "date": "2014-07-17T05:47:19.851Z", 
                    "text": "+NoxSicarius1 yeh but just due to the way quantum computers work, they will \nnever be as good as ordinary computers for doing normal every day stuff. \neven in the future.", 
                    "author": "Gayle bertrude"
                }, 
                {
                    "date": "2014-07-16T22:40:14.523Z", 
                    "text": "Classic computers can do better than any other computer type right now. My \nTI 89 does better than any other computer type right now. This is about the \nfuture though, not the present.", 
                    "author": "NoxSicarius1"
                }, 
                {
                    "date": "2014-07-16T02:03:49.257Z", 
                    "text": "Nah, classical computers can still do most ordinary operations better than \na quantum computer.(Games, rendering etc) Perhaps for hackers or Unix \nusers. ^^", 
                    "author": "gerry7man555"
                }, 
                {
                    "date": "2014-07-14T04:18:50.638Z", 
                    "text": "They are the ultimate foreseeable end, but they are most likely not the \nnext computational type to come. ", 
                    "author": "NoxSicarius1"
                }
            ], 
            "num_replies": 5
        }, 
        "z13iybj4zk3fwvqfq234s3445oamhf54004": {
            "top_comment": {
                "date": "2014-07-13T12:15:22.450Z", 
                "text": "Dumb question:\n8.5CM/ Hr ... Can someone explain please? Why if you turn a light on does \nit not take hours for it to travel down the wire to the light? \nI understand I've probably got the very wrong end of the stick here xD\ufeff", 
                "author": "guitarslf132"
            }, 
            "comments": [
                {
                    "date": "2014-07-15T22:58:39.969Z", 
                    "text": "+guitarslf132 It's a helpful visualization, it's just not what electricity \nreally is xD ", 
                    "author": "IceMetalPunk"
                }, 
                {
                    "date": "2014-07-15T16:48:51.526Z", 
                    "text": "+IceMetalPunk I need to imagine it as electrons physically moving down a \nwire. It helps :) ", 
                    "author": "guitarslf132"
                }, 
                {
                    "date": "2014-07-14T22:50:22.933Z", 
                    "text": "+guitarslf132 Maybe. I don't know what your ideas of them are :P DC \njust has the electromagnetic signal always moving the same direction, while \nAC has the signal switching direction frequently at regular intervals. ", 
                    "author": "IceMetalPunk"
                }, 
                {
                    "date": "2014-07-14T15:16:45.645Z", 
                    "text": "+IceMetalPunk Brilliant thank you! :) That is the misconception I had in my \nhead. Does this mean my idea of how AC and DC current flows is also wrong?", 
                    "author": "guitarslf132"
                }, 
                {
                    "date": "2014-07-13T23:19:02.218Z", 
                    "text": "+IceMetalPunk wonderfully said :)", 
                    "author": "Jnan Mckenzie"
                }, 
                {
                    "date": "2014-07-13T23:14:43.181Z", 
                    "text": " There's a common misconception that an electrical signal is a bunch of \nelectrons moving. That's not the case. When an electron gets excited, it \njumps to a higher energy state; as it relaxes back down to a lower state, \nit releases that extra energy as photons of light. Some of that light bumps \ninto nearby electrons, giving them energy to jump up, and the process \nstarts all over again.\n\nSo while the electrons themselves move very slowly, the signal is actually \ncarried by the light, and it moves very fast. Not at light speed, because \nit's delayed every time a photon is absorbed and re-emitted, but much \nfaster than the electrons themselves. Using optical computers would remove \nthat delay along the wire and allow truly light speed transmission from \ncomponent to component", 
                    "author": "IceMetalPunk"
                }
            ], 
            "num_replies": 6
        }, 
        "z12chpsaoqm1xjllu230j5zjbyzij3iyd04": {
            "top_comment": {
                "date": "2014-07-13T16:30:38.256Z", 
                "text": "Anyone else skeptical about that 8.5 cm/hr?  That's approximately 0.00005 \nmph, which is about 100,000 times slower than a human can walk...yeah, I \ndon't think so...\ufeff", 
                "author": "sockmaster2718"
            }, 
            "comments": [
                {
                    "date": "2014-07-30T04:04:18.196Z", 
                    "text": "+jaredloveless Basically", 
                    "author": "Jesus S."
                }, 
                {
                    "date": "2014-07-30T00:06:29.687Z", 
                    "text": "So, the electrical currents that transmit our electrical signals are \nconveyed by a chain of electron hops? The combined effect of the hops is \nsignals that travel at very high rate?", 
                    "author": "jaredloveless"
                }, 
                {
                    "date": "2014-07-14T01:08:45.350Z", 
                    "text": "Do you have any idea though, how big a centimeter is to an electron? A \ncentimeter is 10^13 times the size of an electron. Imagine trying to walk \n10^13 paces every hour.\n\nThe reason this seems strange to you is because you're thinking of \nelectricity, which is very fast and not electrons which are very slow (on a \nmacro scale).\n\nIf you want to see the difference, get a length of pipe and fill it with \ntennis balls until its completely full. Then push another tennis ball into \none end. The push (electricity) moves almost instantly through the pipe and \nanother ball will get pushed out the end of it. However each individual \nball (electrons) only moves maybe 5cm, much slower than the signal that the \npush just sent.\n\nInside a wire, the electrons move slowly but the signal travels very \nquickly allowing it to convey a signal between the transistors at something \nlike 1/40th the speed of light. However that tiny nanometer gap Hank was \ntalking about isn't full of electrons, so it has to slow down to the speed \nof the individual electron to handle switching. That speed isn't so bad on \nthe nanometer scale, but it's still a definite physical limit.", 
                    "author": "Michael Kenner"
                }, 
                {
                    "date": "2014-07-14T00:46:53.612Z", 
                    "text": "The average drift velocity of electrons in a circuit are very slow, they \nmight have very high speeds but the directions are randomized, and so the \naverage displacement in a unit of time is pretty small. ", 
                    "author": "Jesus S."
                }
            ], 
            "num_replies": 4
        }, 
        "z13qylph0y22c1ghx04cirhogzyhuvwp2bw": {
            "top_comment": {
                "date": "2014-08-16T21:21:27.635Z", 
                "text": "If you have a binary code, for example 0100101, how does it know when to \nstop if you send more information, like 67 and 68 in binary code? How does \nthe computer know when the sequence of 1 information stops?\ufeff", 
                "author": "Vittamar \u201cFasuth\u201d Akbin"
            }, 
            "comments": [
                {
                    "date": "2014-11-13T07:26:09.690Z", 
                    "text": "+Vittamar Akbin The computer only process data as is specified by the \nprogram code (again, just numbers but they are hardwired into the CPU to be \nunderstood as instructions that do useful operations). The program can tell \nit to stop processing a particular string of data and do something else. \nNote that the CPU never actually stops working, it's always fetching the \nnext instruction from memory to be told what to do. In order to \"stop\" a \nCPU, you have to turn the power off.", 
                    "author": "redjr242"
                }, 
                {
                    "date": "2014-11-03T06:45:09.458Z", 
                    "text": "+highks\n\nhm, so the computer just guesses when to stop? :-(", 
                    "author": "Vittamar \u201cFasuth\u201d Akbin"
                }, 
                {
                    "date": "2014-11-02T22:33:25.000Z", 
                    "text": "That is why your computer first needs a BIOS (or UEFI today) to be able to \nunderstand anything at all. It's the first layer of programming that makes \nit possible to \"speak\" with a computer. This first level of programming is \ndone in assembly language, which is not really easy to understand. I never \nfully understood how this is done neither - I guess you have to have very \nspecial skills in mathematics to really understand what's going on at this \nlevel.", 
                    "author": "highks"
                }
            ], 
            "num_replies": 3
        }, 
        "z12yjjzp1mvastgk423pcdohbnj5fnvtb": {
            "top_comment": {
                "date": "2014-07-13T14:58:55.466Z", 
                "text": "Electrons are not slow. Depending on the medium they are traveling in, thry \ngo between 97 and 98% of the speed of light. The 8.5 cm/hour was poorly \nexplained and misguided lots of people. It's the flow of AC that is \ntravelling at 8.5cm/hour, not the electrons themselves.\ufeff", 
                "author": "Yan Leduc-Chun"
            }, 
            "comments": [
                {
                    "date": "2014-07-14T13:14:36.716Z", 
                    "text": "It's actually exactly the opposite of what you said.  Electric current (or \nmore properly, the *electromagnetic wave*) travels at nearly the speed of \nlight down a wire, but the electrons themselves move slower than a snail.", 
                    "author": "mcool13thebass"
                }, 
                {
                    "date": "2014-07-14T09:39:20.252Z", 
                    "text": "+Yan Leduc-Chun\nThat isn't the case. Electrons go \"pretty fast\" as lightning because \nthey're being accelerated in a direction by the rather strong electric \nfield present. But they still don't go anywhere near the speed of light *in \nthe given direction*, and it's simply wrong that \"the slightest input of \nmomentum\" will accelerate electrons at such speeds as they would achieve \nsignificant relativistic mass. It isn't as if electrons are somehow \nnormally super slow and then applying some few volts accelerates them to \nnear light speed, either.\n\nThe free electrons in the medium do bounce around *much faster*, at the \nFermi velocity (still not close to the speed of light at all; on the order \nof 1%). The electrons in a conductor are accelerated *in a direction* when \nDC voltage is applied, again proportional to the strength of the electric \nfield. The average velocity of the electrons in the direction applied by \nthe field is called the drift velocity and this is what we're talking about \nwhen describing the velocity of electrons when an electric field is applied.\n\nAnd with AC the electrons might as well not be going much of anywhere \nbecause the applied current alternates and they barely have any net \nmovement.", 
                    "author": "Vulcapyro"
                }, 
                {
                    "date": "2014-07-14T03:35:55.277Z", 
                    "text": "+Michael Kenner When lightning strikes, do you see it go down at 8cm/hour? \nElectrons have almost no mass. Therefore the slightest input of momentum \nand they're almost travelling at C.", 
                    "author": "Yan Leduc-Chun"
                }, 
                {
                    "date": "2014-07-14T01:16:29.748Z", 
                    "text": "You actually have that backwards. The flow of electricity travels at close \nto the speed of light, individual electrons flow at 8.5cm/hour. Unless \nwe're talking particle accelerators and similar high-energy astronomical \nphenomena, individual electrons never move near the speed of light.", 
                    "author": "Michael Kenner"
                }, 
                {
                    "date": "2014-07-14T00:49:23.014Z", 
                    "text": "Here is the explanation to why you are wrong (with math). \n\nTLDR: Electrons don't need to move that fast because there are just so many \nof them in wire. What moves so fast is the propagation of the \nelectromagnetic fields since one electron moving causes a ripple effect.\n\n\"Electric current is essentially a measure of how many charge carriers you \ncan move through a given cross-section of conductor in a given amount of \ntime. This will depend on the size of the cross section, the number of \ncharge carriers, and their velocity. A current of 1 A corresponds to a \ntransfer of 1 Coulomb of charge per second. An electron carries 1.6*10-19C \nso you need to move 6.3*10^18 electrons/sec. Divide by the density of \nelectrons in a copper wire (about 8.45*10^22 electrons/cm^3) and the cross \nsection of the wire (for AWG 18 this is pi*(1.02mm/2)^2 or 0.008 cm^2) and \nyou get 0.0093 cm/s.\"", 
                    "author": "chaos101011"
                }
            ], 
            "num_replies": 5
        }, 
        "z13oi53hstaaf514a04cfz5astayyhsqzgo": {
            "top_comment": {
                "date": "2015-02-03T01:57:49.669Z", 
                "text": "Why don't we just make the chips slightly bigger?\ufeff", 
                "author": "Space Marine"
            }, 
            "comments": [
                {
                    "date": "2015-04-30T05:06:11.266Z", 
                    "text": "+Jessica Dineen Err, try using the reply button, and note the key phrase \n\"electromagnetic waves\" in the sentence \"the signals or energy travel as \nelectromagnetic waves typically on the order of 50% to 99% of the speed of \nlight, while the electrons themselves move (drift) much more slowly.\"\n\n\n\"A quick search says the speed of an electron in motion is 2200 km/s, or \nless than 1% the speed of light. Pretty sure that in order to slow a photon \nto that degree, you would need specially constructed materials, and even \nthen...\"\n\nAnd the EMF is not an electron, or any collection of electrons, but a field \naccelerating said collection of electrons.", 
                    "author": "Tim Tian"
                }, 
                {
                    "date": "2015-04-30T04:19:54.143Z", 
                    "text": "Then there is this http://en.wikipedia.org/wiki/Speed_of_electricity", 
                    "author": "Jessica Dineen"
                }, 
                {
                    "date": "2015-04-30T04:17:45.075Z", 
                    "text": "A quick search says the speed of an electron in motion is 2200 km/s, or \nless than 1% the speed of light. Pretty sure that in order to slow a photon \nto that degree, you would need specially constructed materials, and even \nthen...", 
                    "author": "Jessica Dineen"
                }, 
                {
                    "date": "2015-04-30T03:15:21.259Z", 
                    "text": "+magicstix0r My original statement, afaik, and I suspect that to be more \nthan you (on the subject, probably not about everything), remains true. \nJust, the velocity of light (virtual photons) in that medium (which are the \nforce carriers, which determine the speed of the charge carrier (usually \nelectrons or the lack thereof) which is basically the \"wave\" you speak of), \nwhich may or may not be a few orders of magnitude slower than light in a \nvacuum, is the velocity, but the *speed* due to a large distance per meter \nof displacement, which is caused by dense areas of charged particles and \nsaid virtual photons interacting with them. ", 
                    "author": "Tim Tian"
                }, 
                {
                    "date": "2015-04-29T23:58:03.334Z", 
                    "text": "+Tim Tian In any case, the electromotive force doesn't move across the chip \nat the speed of light, so your original statement remains false. ", 
                    "author": "magicstix0r"
                }, 
                {
                    "date": "2015-04-29T06:37:05.820Z", 
                    "text": "+magicstix0r No that is for the speed of 8,5 cm per hour.\n\nThis video says that CPU clocks are limited by this speed of electron \npassing threw transistor. ", 
                    "author": "Ond\u0159ej Dujka"
                }, 
                {
                    "date": "2015-04-29T05:20:54.000Z", 
                    "text": "+magicstix0r EMF, in this case (and usually in all cases concerning \nelectronics, or anything else, for that matter), stands for the electro \n*motive* force.\n\nIn fact, I've never actually heard anyone call electromagnetic interactions \nEMF before (usually they're mentioned separately too), and a quick google \nfor EMF (personal results off) indicated the Wikipedia article for \nElectromotive force as the first result (and the third, in a different \nformat), which would indicate that it was the more common usage.", 
                    "author": "Tim Tian"
                }, 
                {
                    "date": "2015-04-29T04:05:51.579Z", 
                    "text": "+Tim Tian *Sigh* no, the flow of electrons and electric charge is not, in \nfact, the same thing as the electromagnetic force. ", 
                    "author": "magicstix0r"
                }, 
                {
                    "date": "2015-04-29T03:23:23.846Z", 
                    "text": "Except electrons are physical matter that move at a much slower speed than \nphotons, photons are the particle that EMF is. It just so happens that you \ncan use convert electrical signals to RF and magnetic resonance, and vice \nverse. Being closely related is not the same as being the same thing, you \nand your mother are not the same person, even if you are in the same family.", 
                    "author": "Jessica Dineen"
                }, 
                {
                    "date": "2015-04-29T02:43:31.545Z", 
                    "text": "+magicstix0r Which is what the EMF is...", 
                    "author": "Tim Tian"
                }, 
                {
                    "date": "2015-04-29T00:40:23.840Z", 
                    "text": "+Ond\u0159ej Dujka are their ways in which we can perhaps improve the way we \nmake chips?", 
                    "author": "Space Marine"
                }, 
                {
                    "date": "2015-04-29T00:28:51.277Z", 
                    "text": "+Ond\u0159ej Dujka That would only be the case if the charge moved through the \nchip at the speed of light, which it doesn't.", 
                    "author": "magicstix0r"
                }, 
                {
                    "date": "2015-04-29T00:29:11.000Z", 
                    "text": "+Tim Tian What travels across the chip is not the electromagnetic force; \nit's a charge, which is dependent on the force carrier particles (in this \ncase, electrons and holes). Even so, it is not the electrons that move but \na \"virtual\" wave (for lack of a better word) of charge made up of electrons \nand holes. The wave moves through the lattice by the recombination of \nelectrons filling open holes. You can think of it just like \"the wave\" in a \nstadium, or a bucket brigade. This wave moves far, far slower than the \nspeed of light, and depends on the excitation/relaxation times of the \nsemiconductor substrate. For example, in GaAs semiconductors, the wave of \ncharge moves much faster than silicon, and so you can get higher clock \nspeeds with GaAs.", 
                    "author": "magicstix0r"
                }, 
                {
                    "date": "2015-04-28T07:13:49.096Z", 
                    "text": "Here is how i see it:\n\n85 000 000 nm / 3600 = 23611.1 nm/s\n23611.1 nm/s / 32nm = 0.737 MHz\n\nSo 737 kHz should be upper limit for 32 nm chip.\n\n:-)", 
                    "author": "Ond\u0159ej Dujka"
                }, 
                {
                    "date": "2015-04-28T02:41:58.276Z", 
                    "text": "+magicstix0r Oh? Please elaborate.", 
                    "author": "Tim Tian"
                }, 
                {
                    "date": "2015-04-28T02:28:04.876Z", 
                    "text": "+Tim Tian False.", 
                    "author": "magicstix0r"
                }, 
                {
                    "date": "2015-04-27T03:59:56.848Z", 
                    "text": "+Peter Bayley Well, technically, the thing that has to travel across the \nchip is the EMF, not a physical object and traveling at the speed of light.", 
                    "author": "Tim Tian"
                }, 
                {
                    "date": "2015-04-26T22:06:31.549Z", 
                    "text": "+Space Marine Electrons are physical objects that have to cover physical \ndistance. If the chip was bigger it would become slower, as the electrons \nwould have to move over a greater distance.", 
                    "author": "Peter Bayley"
                }, 
                {
                    "date": "2015-04-12T07:26:20.730Z", 
                    "text": "+Cherno Alpha To add to Schwarzer's comment, some flawed chips are sold. A \ngood example are AMD tri core processors, which are actually quad cores \nwith a disabled defective core (or at least this was the case for specific \nmodels). They are sold simply because the rest of the chip works fine, and \nit cuts down on costs by recouping some of what would otherwise simply be \nwaste.", 
                    "author": "Jessica Dineen"
                }, 
                {
                    "date": "2015-04-10T12:46:19.403Z", 
                    "text": "+Cherno Alpha Costs more.", 
                    "author": "Tim Tian"
                }
            ], 
            "num_replies": 23
        }, 
        "z13twhcykmbetfut223ggfxzutfpudajq04": {
            "top_comment": {
                "date": "2014-07-14T05:57:40.903Z", 
                "text": "So who made the binary dictionary???\n\nHow do we know what all these different binary sequences mean?\ufeff", 
                "author": "XxXVideoVeiwerXxX"
            }, 
            "comments": [
                {
                    "date": "2014-08-21T08:45:27.076Z", 
                    "text": "Really good explanations!", 
                    "author": "hg0"
                }, 
                {
                    "date": "2014-07-19T21:23:49.484Z", 
                    "text": "There's nothing sacred about the \"binary dictionary\". Some guy just sat \ndown and said \"I need to map all the numbers and letters to binary \nstrings\", so he counted all the numbers and letters (and some other stuff \nhe needed too) and he had maybe 200 symbols. So then he went \"Ok, so the \nnext highest power of 2 is 256, so that's 8 bits to represent all 200 \nsymbols\".\n\nThen he had to decide what symbol would be what letter. So he was smart and \ndecided \"I'll make all the numbers have the last 4 bits be the actual \nbinary representation of the number. So\n\n0 = xxxx 0000\n1 = xxxx 0001\n2 = xxxx 0010\n...\n9 = xxxx 1001\n\nThen he decided that he'd make it so capital letters were always separated \nfrom their corresponding lower case letter by the same amount. So people \ncould just write code to capitalize a letter by going (just some pseudocode \nfor you):\n\n\"capitalize(char lowercase){\nchar uppercase;\nuppercase = lowercase + 32;\nreturn uppercase;\n}\n\n---\n\nAnd there's no reason that the current dictionary, or the ascii table, is \nthe best one possible. Maybe there's a better way to organize all the \ncharacters. We just need some sort of standard to go by so we all stick to \nthe current ascii table.", 
                    "author": "Nifty Fingers"
                }, 
                {
                    "date": "2014-07-19T11:28:09.236Z", 
                    "text": "-+Darkfeyttt hey this guy has gud answer 0_0", 
                    "author": "eterpe1"
                }, 
                {
                    "date": "2014-07-19T09:10:57.768Z", 
                    "text": "+XxXVideoVeiwerXxX\nI'll try to answer your question, but I don't know much about quantum \ncomputers (like most software engineer, because as for now quantum \ncomputers are not industry-ready), so I might be wrong in my explanation :\n\nAFAIK, quantum computers works with qubits, so what's the difference \nbetween a qubit and a bit ?\n\nA bit can be either 0 or 1.\nA qubit can be either 0 or 1 or a superposition of both.\n\nBut when you look at the value of a qubit it will be either 0 or 1.\n\n\"So, isn't it a bit like a trit ? (trit = 0 or 1 or 2)\"\\\nNot at all, the third 'value' of a qubit isn't a value but a very special \nstate, that will disappear once you observe the value.\n\n\"So what is it useful for ?\"\nAFAIK (again), quantum computer should be very good at looking for a \noptimal combination, in a simpler way it means \"trying a lot of value and \ngiving you the best value\", because quantum computer can try 'all' \ncombination at once.\n\n\"How it does try 'all' combination at once ?\"\nA quantum computer become really useful when you use more than 1 qubits at \nonce, like for 4 qubits/bits, there's 16 combination :\n0000\n0001\n0010\n0011\n0100\n0101\n0110\n0111\n1000\n1001\n1010\n1011\n1100\n1101\n1110\n1111\n\nA quantum-computer computation with a 4 qubits processor will put his value \nin the 'superposition' state, and at the end of the computation, the result \nwill be the best matching combination.\n\nMaybe an example might help :\n\nLet's take a 4 bits computer and try to crack a 4-bit password with it, the \nprogram would look like :\n\nSet i to 0\nSet result to 'not found'\n\nWhile result is 'not found'\nRepeat {\n     If (Try password 'i') is successful\n     Then set result to i\n     Else add 1 to i\n   }\n\nPrint \"password is \" + 'result' on screen\n\nAs you can see, we try every combination one by one.\nNow let's do the same with a 4 qubits computer :\n\nSet result = 'superposition'\nTry password with result qubits\nPrint \"password is \" + 'result' on screen\n\nWe tried all combination at once.\n\nSo, 4 bits combination computation is not a big computation, but let's look \nat a more concrete example of 'password' :\n\nYouTube encrypt data (for your privacy) with a 128 bits security, that's \nlike 2^128 possibilities = 340 282 366 920 938 463 463 374 607 431 768 211 \n456 possibilities, even if you try 1 million of million of possibilities \nper second, it would still take you 258 966 793 699 344 340 535 years to \ncompute.\n\nNow that's a big computation, if we could have a 128 qubits computer, this \nproblem wouldn't be exponential but linear, meaning that it would takes \nsomething like few seconds instead of a lot of years.\n\nQuantum computers are good at combination, but it require them to have a \nlot of qubits as the processor size.\n\nTo conclude, I hope that I don't say a lot of wrong things, that I would \nnot make mad a \"quantum computer scientist\", nor a grammar nazi (English is \nnot my native language), and hope that my explanation was easy to \nunderstand.", 
                    "author": "Darkfeyttt"
                }, 
                {
                    "date": "2014-07-19T06:45:53.379Z", 
                    "text": "+XxXVideoVeiwerXxX Quantum computers aren't directly analogous to classical \ncomputers. A qubit exists in a superposition of states, and colapses into a \ndefinite state when it's read. A quantum computer would not be very good \nfor, say, looking up entries in a database. However, it may be very good at \nfinding the optimal combinations of the entries in that database.\n\nQuantum computers won't replace classical ones, they'll just make certain \nthings a lot faster.\n\nVeritasium has a few good videos on the subject.", 
                    "author": "JoeJoeTater"
                }, 
                {
                    "date": "2014-07-19T01:56:16.785Z", 
                    "text": "+Darkfeyttt So uh *eats a chip* what uh, happens, when you know, we get \nquantum computers?\n\nWill there be 0123 values? What will be so amazing about them considering \nbinary is doing the job as is? Will we just get double (or quadruple) the \nprocess power?", 
                    "author": "XxXVideoVeiwerXxX"
                }, 
                {
                    "date": "2014-07-16T06:19:53.794Z", 
                    "text": "+gerry7man555\nYes exactly.That's why an 8 bit number can hold 256 different values. 2^8", 
                    "author": "Fleegsta"
                }, 
                {
                    "date": "2014-07-16T02:01:38.000Z", 
                    "text": "+DragonMoth34 So it's basically, for each digit, 2^n?(76554321)", 
                    "author": "gerry7man555"
                }, 
                {
                    "date": "2014-07-15T23:32:52.106Z", 
                    "text": "+ciph3ro It's very easy to understand actually. \n\n00000000 = 0\n00000001 = 1\n00000010 = 2\n00000011 = 3\n00000100 = 4\n00000101 = 5\n00000110 = 6\n00000111 = 7\n00001000 = 8\n00001001 = 9\n00001010 = 10\n00001011 = 11\n00001100 = 12\n00001101 = 13\n00001110 = 14\n00001111 = 15\n\nand so on. i think you see the pattern here. all the way up to 256 with \nthose 8 bits. 64 bit computers go much much higher.", 
                    "author": "DragonMoth34"
                }, 
                {
                    "date": "2014-07-15T19:44:02.000Z", 
                    "text": "When you make your hardware you make it in such a way that it knows what to \ndo with the bits. This goes both for instruction sets and for data being \ninterpreted from the binary values you input into a chip.\n\nI'm an systems and computing engineer and have made and worked on hardware \nand related software development.\n\nThere are also a few levels of abstraction of both hardware and software \nthat just have a common language between them but are unaware of what \nhappens inside each other. On top of the hardware and then all those levels \nof abstraction (which essentially each have inputs and outputs) you find \nsomething like a compiler, operating system or smartphone app.", 
                    "author": "Ovi Wan Kenobi"
                }, 
                {
                    "date": "2014-07-15T19:33:45.723Z", 
                    "text": "+XxXVideoVeiwerXxX 20. You can calculate it. Just google it.", 
                    "author": "Lizard771"
                }, 
                {
                    "date": "2014-07-14T20:13:54.925Z", 
                    "text": "But the \"dictionary\" can vary depending on the context. They mention it in \nthe video, the same string of binary digits can represent different things \ndepending on where it's sent in the computer (gpu, sound card, an app for \nwriting english letters). There's a bunch of standards, but there's no \n\"fixed\" list anywhere. Binary digits are just numbers in base 2 (instead of \nbase 10, like we use). Programmers can make new representations for what \nthose numbers represent based on whatever the software calls for (maybe \nit's a color, maybe it's a letter, maybe it's the ID to a reserved chunk of \nmemory in the computers ram, etc).", 
                    "author": "Fleegsta"
                }, 
                {
                    "date": "2014-07-15T17:06:15.000Z", 
                    "text": "The Numberphile (EDIT: Computerphile has stuff about this, but Numberphile \nis awesome too.) channel has a lot of good videos about this. Basically, \nthere are a lot of different ways to interpret what a number means, based \non the context in which it's used. The meanings are decided by various \ngroups and those standards either get adopted or they don't.", 
                    "author": "JoeJoeTater"
                }, 
                {
                    "date": "2014-07-14T15:53:38.039Z", 
                    "text": "+Darkfeyttt Thanks for the in-depth explanation! I've been trying to learn \nthe basics of this stuff and haven't found anything I really understand. \nThis helps a lot.", 
                    "author": "Calkor13"
                }, 
                {
                    "date": "2014-07-14T13:00:02.035Z", 
                    "text": "+Darkfeyttt Awesome explanation!", 
                    "author": "vladslick"
                }, 
                {
                    "date": "2014-07-14T12:05:03.879Z", 
                    "text": "Basically programmers and hardware manufacturers decide which binary value \ncorresponds to which 'logic value'.\n\nFor example, a simple character convention is ASCII (look for it on \ninternet), the character 'a' in ASCII is represented by the binary value \n01100001.\n\nBut what makes it 'a' (why 01100001 represent 'a'), it's because there's a \nsmall piece of software/hardware that when it sees 01100001 it says \"turn \non these pixels\" and you see a 'a' on your screen. (it's actually a bit \nmore complex in true life, but that's the basic of why 01100001 can \nrepresent 'a')\n\nHow do we (programmers and/or hardware manufacturers) decide which value \nrepresent what ? We decide it using our need.\n\nFor example, let's say I need to represent a forecast state, I'm lazy so \nforecast is represented by only four state :\nnot sunny and not raining\nnot sunny and raining\nsunny and not raining\nsunny and raining\n\nThere's four state I can decide to represent it on 2 bits, with one bit \nrepresenting the \"sunny\" information, and another bit representing the \nraining information, that would make the list look like that :\n00 not sunny and not raining\n01 not sunny and raining\n10 sunny and not raining\n11 sunny and raining\n\nThe first bit representing the sunny information, the second one the \nraining information.\n\nSo my program displaying the weather information would look like that :\n\nIf the first bit is activated\nThen print \"sunny\" on screen\nElse print \"not sunny\" on screen\n\nprint \" and \" on screen\n\nIf the second bit is activated\nThen print \"raining\" on the screen\nElse print \"not raining\" on the screen\n\nSo if we input '01', the program will print \"not sunny and raining\" on the \nscreen.\n\nWe created a new convention of forecast encoding !\n\nIf you're interested in learning computer stuff, the computerphile channel \nmight interest you.", 
                    "author": "Darkfeyttt"
                }, 
                {
                    "date": "2014-07-14T09:55:49.986Z", 
                    "text": "+XxXVideoVeiwerXxX There are many standards detailing which binary sequence \nmeans what, depending on the purpose. In a processor, it's the processor \nmanufacturer that decides which binary sequence corresponds to which \noperation, which is called the instruction set. Years ago, Intel invented \nthe x86 instruction set, and it has become the standard in desktop \ncomputing. Your phone, on the other hand, probably has a chip designed by \nARM, which uses a different instruction set (actually several, slightly \ndifferent instruction sets, but that's not the point). For text, for \nexample, there is unicode, managed by the unicode consortium, which is a \ndictionary between binary sequences and characters.", 
                    "author": "Daan Wilmer"
                }, 
                {
                    "date": "2014-07-14T08:43:12.815Z", 
                    "text": "+XxXVideoVeiwerXxX I'm sure there's a list somewhere.", 
                    "author": "Fortstorm"
                }, 
                {
                    "date": "2014-07-14T08:41:56.241Z", 
                    "text": "so is there like a list or compilation that says 10100 means this for that", 
                    "author": "XxXVideoVeiwerXxX"
                }, 
                {
                    "date": "2014-07-14T08:00:08.682Z", 
                    "text": "We invented them.", 
                    "author": "Fortstorm"
                }
            ], 
            "num_replies": 20
        }, 
        "z122hbaiulvufrrb404cg3norsvnsjfa1ro0k": {
            "top_comment": {
                "date": "2014-07-13T13:28:07.981Z", 
                "text": "Hasn't quantum entanglement shown us that things actually can go faster \nthan the speed of light?\ufeff", 
                "author": "Xaeravoq"
            }, 
            "comments": [
                {
                    "date": "2014-07-14T15:02:49.414Z", 
                    "text": "Not exactly.  Strictly, the effect of measurement on entangled entities \nhappens instantaneously, regardless of the distance between the entities. \n However, it isn't possible to transmit classical information via this \neffect at speeds faster than light.  It only transmits quantum information. \n The only thing that entanglement lets you do is have two observers at \ndistant points see the same system simultaneously.  It doesn't let you \ncontrol what either observer sees.", 
                    "author": "Matthew Prorok"
                }, 
                {
                    "date": "2014-07-14T04:46:44.398Z", 
                    "text": "No, entanglement does not go faster than the speed of light. The \nexplanation behind it is long and complicated, but the short answer is no. \nIt is also very important to note that Physics does not necessarily apply \nto Quantum Physics. They abide by different laws and these laws do not \napply to both. This problem is what has birthed the attempt to make a \ntheory of everything, a theory of the small + a theory of the big combined.", 
                    "author": "NoxSicarius1"
                }, 
                {
                    "date": "2014-07-14T01:25:26.281Z", 
                    "text": "Nothing physical but info does travel faster", 
                    "author": "Peyton Hanel"
                }, 
                {
                    "date": "2014-07-14T01:24:50.237Z", 
                    "text": "Sort of. People argue a lot about this one and most of the science involved \ngoes a little over my head. The effect of measuring one particle does seem \nto apply to the other particle faster than the speed of light. However \nthere's arguments about whether actual information is being conveyed faster \nthan light or not.", 
                    "author": "Michael Kenner"
                }
            ], 
            "num_replies": 4
        }, 
        "z13tutrgcpmbgv4a004cgniooxjjz1rppp00k": {
            "top_comment": {
                "date": "2014-07-13T18:34:19.083Z", 
                "text": "Why don't we use liquid nitrogen as a cooling method\ufeff", 
                "author": "Mazen Sami"
            }, 
            "comments": [
                {
                    "date": "2014-08-09T23:47:00.432Z", 
                    "text": "+Jacob Shepley\n\nThink on this brother:\nAll that has ever been has allready become. We might not have found certain \n'things'. But rest assured - thought creates.", 
                    "author": "sp00nman88"
                }, 
                {
                    "date": "2014-08-09T22:30:10.323Z", 
                    "text": "+sp00nman88 \"all we need to do\"", 
                    "author": "Jacob Shepley"
                }, 
                {
                    "date": "2014-07-15T19:58:49.783Z", 
                    "text": "Water cooling actually works much better than air cooling, which is what we \nuse now.", 
                    "author": "Ovi Wan Kenobi"
                }, 
                {
                    "date": "2014-07-14T12:52:01.436Z", 
                    "text": "If I'm walking around my house and I trip and the computer breaks in half \nand then there's liquid nitrogen all over the floor I think my mommy will \nspank me.\nThat's why we don't use liquid nitrogen.", 
                    "author": "Thomas Moulden"
                }, 
                {
                    "date": "2014-07-14T00:48:51.503Z", 
                    "text": "All we need to do is to find a room temperature super conductor. We \nwouldn't need much cooling if we could find ways to keep our electronics \nfrom heating up.", 
                    "author": "sp00nman88"
                }, 
                {
                    "date": "2014-07-13T23:16:58.334Z", 
                    "text": "Supercomputers do. But it's expensive and dangerous for your average \ncomputer user.", 
                    "author": "IceMetalPunk"
                }
            ], 
            "num_replies": 6
        }, 
        "z130cze50zybsxmz204cgdaawoy5tr2pqto0k": {
            "top_comment": {
                "date": "2015-04-08T02:09:08.952Z", 
                "text": "here's a weird thought. Why don't they make the chips bigger?\n(I'm sure there's some reason this isn't doable, because if no one has \nthought of this then I am giving up on humanity RIGHT NOW)\ufeff", 
                "author": "Allison Willner"
            }, 
            "comments": [
                {
                    "date": "2015-04-09T05:12:52.093Z", 
                    "text": "Thank you!", 
                    "author": "Allison Willner"
                }, 
                {
                    "date": "2015-04-08T18:39:40.327Z", 
                    "text": "Two main problems:\n1. Larger means more expensive. Additionaly, with increasing size the \nchance of a production error increases, resulting in lower yields and \ntherefore - you guess it - higher prices.\n2. The size of a chip can not be increased without limitations. Well, you \ncould increase the size as big as your production facilities can handle, \nbut you would have to decrease the clock speed of a chip, resulting in less \ncalculations per timeframe. This is due to the speed of electrons: If those \nguys are still travelling through the chip for one operation and you start \nthe next, your calculation will get messed up. There are some ways to \nprevent such errors, like more cores for calculation. But as mentioned in \nthe video are there limitations as well, especially concidering the \nincreasing complexity of software.", 
                    "author": "moepediblupp"
                }
            ], 
            "num_replies": 2
        }, 
        "z12mcblwrlrfcd43v22viheijrifc1kro04": {
            "top_comment": {
                "date": "2014-07-13T10:26:06.377Z", 
                "text": "For starters, transistors do not hold ones and zeros.  One and zero are \njust two different voltage levels; wires hold them. Transistors just allow \nor deny a one or zero to be transferred from one wire to another - and the \ncool thing is that they allow or deny based on the voltage in a third \nwire.  So you can have ones and zeros moving around wires based on other \nones and zeros in other wires.  Your characterizing transistors' on/off \nstates as one/zero is wrong - on means the two wires are connected (both \none or both zero), and off means the two wires are disconnected (and might \nbe different).  The bit about a byte being in eight transistors is wrong - \na byte is in eight wires, which may be connected to transistors. \n\nAnd as for the storage of bits in a computer, well, storing a bit takes (at \nleast) eight transistors wired together in a configuration generally known \nas a \"flip flop\" (there are several kinds), so the bit about a byte being \nin eight transistors is still wrong.\n\nFor as well as you covered the operation of semiconductor devices, you \nmight as well have said \"they're magic.\"  All you did was explain how \ninsulating silicon can become partially conductive if you dope it.  Well, \nwe already have conductive things, we call them wires.  Why are these \nparticular types of silicon useful?  What's the point of talking about \ndoping and stuff without even mentioning p- and n-type semiconductors, or \nthe way they are mashed together to make transistors?   Honestly, it's fine \nif you don't want to explain that stuff - it's complicated and difficult to \nexplain to laypeople who don't have any quantum mechanics and electronics \nbackground.  But then why talk about doping?  Why not simply talk about \nwhat transistors do (control the connection between two wires based on the \nvoltage in a third wire) without trying (and failing) to get into the \ntechnical details?\n\nAlso, talking about all those materials, but no love for gallium arsenide? \n\nThe bit about optical computing made me cringe - the advantage has *nothing* \nto do with the speed of the constituent particles, it has to do with \nbandwidth.  The speed that electrons drift in a wire is irrelevant to the \nspeed that electrical signals flow, in the same way that the time that it \ntakes the water to get from the water tower to your faucet is irrelevant to \nhow fast the water starts flowing when you turn the knob.  There was \nalready water there; a wave of water pressure is pushing it out the \nfaucet.  There were already electrons there; a wave of electric field is \npushing it.  And because it depends on electric fields, electricity travels \nat the speed of light.  Remember that light actually *is* electric fields, \nso there's really not a lot of conceptual difference between an optical \ncomputer and an electronic computer except the frequencies involved are \nmuch higher in an optical computer (and the devices and materials you use \nare different to deal with this).  And that's the advantage, too; higher \nfrequency means more bandwidth. \n\nFortunately you did not talk about quantum computing in enough detail for \nme to get mad at you. \ufeff", 
                "author": "DontMockMySmock"
            }, 
            "comments": [
                {
                    "date": "2014-07-13T20:33:56.454Z", 
                    "text": "+Allan Rempel\nI am a layman in this field and I think I understand most of these remars \nand I surely do appreciate it.", 
                    "author": "Miroslav Stejskal"
                }, 
                {
                    "date": "2014-07-13T19:16:01.620Z", 
                    "text": "yeah the bit about doping was kind of useless. I almost thought he was \ngoing to go into structure for a bit there, but nope.\notherwise I thought his explanations were ok (excluding the drift velocity \nthing). He got people thinking of the transistor as a kind of switch, which \nis basically the core idea of digital hardware, and he sketched out some \nways you can use binary data. Good enough for a non-technical approach.", 
                    "author": "seriousbees"
                }, 
                {
                    "date": "2014-07-13T17:49:57.569Z", 
                    "text": "I appreciate your pedantry. I was just about to write a similar rant, until \nI saw that you had already covered everything here. I'm not sure if any \nlaypeople will understand or care about these corrections, but at least \ntechnical people like us will be satisfied.", 
                    "author": "Allan Rempel"
                }
            ], 
            "num_replies": 3
        }, 
        "z12psxpaku2jsho2a23ft1jhmqjww3dqu04": {
            "top_comment": {
                "date": "2014-07-13T12:45:00.613Z", 
                "text": "What's so important about the 1 and the 0? With a little genius couldn't \nyou make a computer that expands outside of this? Like a single bit that \nhad a dozen or more different states? Imagine a single bit with a megabyte \nof possibilities.\ufeff", 
                "author": "Michael Davaz"
            }, 
            "comments": [
                {
                    "date": "2014-07-15T07:18:17.474Z", 
                    "text": "+BattousaiHBr\nI perfectly realize that quantum computers only allow to speed up the \nFourier transformation (and it's applications) and to lesser degree solving \nof some search problems. I didn't mention it because it was completely \nirrelevant to the topic.", 
                    "author": "Suiseiseki Desu"
                }, 
                {
                    "date": "2014-07-15T02:37:01.644Z", 
                    "text": "+Suiseiseki Desu emphasis on \"some problems\".\nif you just plan to use your computer for facebook and youtube, it would \nliterally be as fast as a conventional computer (or maybe even slower).\nquantum computing shines in very large and very complex computations.", 
                    "author": "BattousaiHBr"
                }, 
                {
                    "date": "2014-07-14T16:06:13.078Z", 
                    "text": "+Suiseiseki Desu\nI just read up on ternary computation, and it's applications towards AI (by \nadding in the Maybe or Unknown option) is fascinating. I'm sorry to change \nthe topic, but I feel that the key to \"true AI\" lies in combining aspects \nfrom hundreds of ideas all over the world. Optimism striking me again, but \nit almost seems like we'd be there right now if we just used the right \n\"combination\" of all the research that's going on.", 
                    "author": "Michael Davaz"
                }, 
                {
                    "date": "2014-07-14T15:10:35.743Z", 
                    "text": "+Michael Davaz Well quantum computers isn't a very good analogy since they \nwork in a fundamentally different way and because of that they happen to be \nmuch better at solving some problems than conventional computers.\nJust changing the base however won't make a fundamental difference for the \ncomputational power of your machine. Maybe you could build a ternary \ncomputer (but probably not one with a higher base) that would be a bit \nfaster than the binary ones but I doubt that the result would be worth the \neffort. \nThe idea of a ternary computer isn't unthinkable indeed and there was some \nresearch in this area and at least one working ternary computer in the \nearly days of computers.  ", 
                    "author": "Suiseiseki Desu"
                }, 
                {
                    "date": "2014-07-14T14:33:16.020Z", 
                    "text": "+IceMetalPunk\nBase 4 computers? That sounds fascinating! I'm going to go look up stuff on \nthat. Research is fun!", 
                    "author": "Michael Davaz"
                }, 
                {
                    "date": "2014-07-14T14:30:26.937Z", 
                    "text": "+NoxSicarius1\nI'd suppose redefining *anything* on such a rudimentary level would mean \nstarting over from scratch. You'd have to redevelop every tiny part of \nevery component in a computer -- probably resorting back to room sized \ncomputers (and who wants those days back again!). It'd take a nauseating \namount of money to develop, and then would function as a beautiful \npaperweight because who'd want a computer that can't use current software, \nhardware, or the internet? A fine fantasy of an idea -- but nothing more.", 
                    "author": "Michael Davaz"
                }, 
                {
                    "date": "2014-07-14T14:19:32.748Z", 
                    "text": "+Cameron Porter\nI guess these kind of revolutions take time, but were living in an age of \nexponential technological growth. I guess an optimist would say that its \nonly a matter of time before someone comes up with an new crazy/brilliant \nidea -- or we can just wait around for quantum computing to become more \noptimized and hope that's even cooler than we had hoped!", 
                    "author": "Michael Davaz"
                }, 
                {
                    "date": "2014-07-14T14:10:50.420Z", 
                    "text": "+Suiseiseki Desu\nIt makes a lot of sense that a binary system would be favored for \nsimplicity and reliability: remember the engineering adage about complex \nthings only being easier to break. However, computers are extremely \ncomplicated things in themselves, and the idea doesn't seem unthinkable. It \nwould seem there'd be *somebody* out there working on a way to make this \nsort of thing feasible. I mean: look at quantum computing. Somebody had to \ncome up with, and that's insanely complex!", 
                    "author": "Michael Davaz"
                }, 
                {
                    "date": "2014-07-14T11:06:51.419Z", 
                    "text": "You can totally do it, but it probably won't make computers any faster. \nBinary system was chosen because it is the simplest one. Using higher base \nwill make circuits much more complex (and hence less reliable) and \ndesigning logical elements for them much more difficult.\n+NoxSicarius1 Once again, saying that 0's and 1's are states of single \nswitches is not accurate in most cases. In most modern chips digits are \nrepresented by voltages that lie in certain ranges (normally two but you \ncould use more). For example: voltage level between 0V and 1.5V can be \ninterpreted as 0. These voltages are controlled by transistor circuits (not \nsingle transistors). To build a flip-flop storing one bit you need several \ntransistors, some of which would be \"on\" and some \"off\" at a given time.", 
                    "author": "Suiseiseki Desu"
                }, 
                {
                    "date": "2014-07-14T06:58:52.436Z", 
                    "text": "You would need some way of creating these states. At the moment we have a \ntransistor, which gives on and off for whether or not current is flowing or \nnot. To have multiple states you would need a completely new technology. It \nall comes down to converting some physical action into data. That action is \nelectrical current at the moment.", 
                    "author": "Cameron Porter"
                }, 
                {
                    "date": "2014-07-14T04:33:26.239Z", 
                    "text": "Yes and no. You see the 1 and 0 is simply on and off. This means there is \npower to the switch or this is not. This 1 or 0 IS the bit. There is no \nchanging that. All computer types will still have a bit system no matter \nwhat it uses or how it functions. A quantum computer is faster for a huge \nnumber of reasons, but it would work through considering the spin of the \nelectron rather than if there is an electron or not. This gives more bit \npossibilities, but does not redefine what a bit is. The reason quantum is \nso hard is because the computer would operate on superposition. Quantum \nsuperposition is the fundamental principle that something can be in every \npossible state until observed. This means if the electron is not measured, \nit is spinning in every possible direction (electrons have a spin to them). \nThe real problem is measuring this spin literally defines the spin. If you \nmeasure it, the state changes to one spin, if you don't measure it the spin \nis in every possible direction. So how do you use something you can't \ndirectly measure? By indirectly measuring it through probabilistic \nequations.", 
                    "author": "NoxSicarius1"
                }, 
                {
                    "date": "2014-07-13T23:36:37.864Z", 
                    "text": "It's important because it's easy to represent physically (on/off, high/low, \nnorth/south, etc.) A single bit that actually could hold millions of \npossibilities would be wonderful, but how would you make anything that had \nthat many states which could all be read and written precisely? We don't \nknow how to do that yet.\n\nThere have been other systems than binary, going up to I think quaternary \n(base 4). But the complications they add in hardware basically negate any \nbenefits they'd give over binary.", 
                    "author": "IceMetalPunk"
                }
            ], 
            "num_replies": 12
        }, 
        "z12wwnqzzsatyzdfs23dgfkqmqqhwvpy304": {
            "top_comment": {
                "date": "2015-02-11T04:18:16.191Z", 
                "text": "This was probably one of the most inaccurate episodes ever.. It was painful \nto watch. :/\ufeff", 
                "author": "magicstix0r"
            }, 
            "comments": [
                {
                    "date": "2015-04-24T10:18:50.714Z", 
                    "text": "+magicstix0r Like most things on this channel, it gives a gross \noversimplification of the topic at hand, to give ordinary people a basic \nidea. \n\nIn layman's terms a sound card does work pretty close to that. Calling it a \nnote wasn't accurate, but data is indeed interpreted as an audio sample by \nthe sound card. But to describe what an audio sample is - would just add an \nextra level of confusion, on top of what might find an already confusing \ntopic. \n\nWe all know that everything we hear can be represented by a sound wave - \nand audio data is nothing more than a digital representation of that wave. \n\nTo better describe such data - picture a wave representation of 1 second of \naudio, with the vertical axis representing amplitude, and the horizontal \naxis representing time. Each piece of data being sent to the sound card \nrepresents the amplitude of the wave at a particular point in time. The \nlarger that piece is, the more closely it will match the actual wave, in \nterms of amplitude. The more samples per second (sample rate), the closer \nit will match any changes in the wave along the horizontal axis. So, if \nyou're trying to play a 16-bit, 44,100hz wav file, it will have 2 bytes to \ndescribe the amplitude of the sample (between -1 and 1), and will have \n44,100 unique samples every second \n\nVideo card was a bit closer, but it's probably been at least 25 years since \na video card only used 256 colors. A typical modern display will use \n24-bits (3 bytes) to display color, with 256 levels of blue, red and green \n- for a total of close to 17 *million* colors. While not as common, there \nare also 30, 32, and even 48 bit color as well. But, the basic concept \nstill stands \n\nBut as I said, it's not supposed to be compsci 101 here - nearly every \nvideo generalizes and simplifies the topic at hand - the only reason you've \nnoticed this particular video, is because it covers a topic that you *are* \nknowledgeable about.", 
                    "author": "Digital_Utopia"
                }, 
                {
                    "date": "2015-04-15T23:53:42.721Z", 
                    "text": "+Ben David U sound mad bro. Y u mad?", 
                    "author": "magicstix0r"
                }, 
                {
                    "date": "2015-04-15T20:57:21.591Z", 
                    "text": "+magicstix0r Hmm, you wrote all that shit yet no one gives a fuck. Which is \na shame, since you could have complemented the video with a nice \ninformative post. Instead, your autistic, high-horsed masturbatory demeanor \nmakes you sound like an angry nerd behind a computer screen.\n\nThis video is already one of the most informative from the series. Maybe \nthey don't need to go to boring, esoteric details to prove themselves to \nwhiny nerds in order to teach people.", 
                    "author": "Ben David"
                }, 
                {
                    "date": "2015-04-13T04:45:49.808Z", 
                    "text": "+magicstix0r Welp, he got told! Lol. Thank you for all of those \nclarifications. That's why I take these \"educational\" channels as \nentertainment and not much else. With that many wrong facts I feel like its \nnot even worth watching now...", 
                    "author": "Ryan L"
                }, 
                {
                    "date": "2015-04-10T02:44:36.621Z", 
                    "text": "+Xextreem \nFirst of all, transistors aren't just \"switches.\" MOSFETS (the type of \ntransistor he's talking about here yet neglects to mention), have rather \nnonlinear I-V curves, and only behave as \"all on\" or \"all off\" when they're \nbiased properly in saturated or cut-off modes of operation.\n\nSecond, the \"limitations on how fast and smart our computers can get\" is \ngrossly over-simplified. Simply throwing more transistors on a chip doesn't \nmake it \"faster.\" The maximum clockable speed of a circuit, which for most \nof the past 4 decades was a measure of how \"fast\" it was, is limited by the \npropagation delay needed across the circuit for it to reach steady state. \nSimply adding more transistors to a highly-delayed circuit wouldn't make it \nfaster, and in fact would be quite the opposite. This is why RISC \narchitectures and superscalar (pipelined) architectures became very popular \nfor increasing clockspeeds, and thus performance, in the 90s. \n\nThird, Moore's Law states that the number of transistors per area doubles \nevery 18 months, not every two years.\n\n[Oh wow, we're only through the first two minutes of the video, this \ndoesn't bode well does it... ]\n\nFourth, his description of a transistor is inaccurate. The \"two channels\" \nhe speaks of are two channels of *doped* silicon, not pure silicon, which \nis used as the substrate for the circuit. In addition to this, the \"gap\" \nthat he's talking about is also not pure, but more doped with the opposite \ntype as the two channels. \n\nFifth, pure silicon isn't an insulator; as he just said, it's a \nsemiconductor. He just contradicted himself in his own explanation.\n\nSixth, you're not applying a \"positive electrical charge to the \ntransistor.\" The type of charge you're applying depends on the type of \ntransistor and its properties. Another misleading oversimplification.\n\nSeventh, the electrons aren't drawn out of the \"strips of silicon,\" they're \ndrawn from the bulk material in between the two strips and essentially \ncreate a \"bridge\" between the two strips.\n\nEighth, the \"gathered electrons\" don't \"turn into a current,\" they instead \nallow a current to flow between the two strips of silicon. His explanation \nmakes it seem like if you apply a charge to the gate on the transistor, \nthat you'll magically see current flow between the source and drain, which \nis patently false.\n\nNinth, there's no such thing as a transistor that can store a single bit of \ninformation. Even the closest thing, a DRAM cell, requires a large refresh \ncircuit.\n\nTenth, minus 20 points for his laughable explanation of how a sound card \nworks. \"Mapped to each spot on a sound wave...That spot has its own \nsound...\" ? Lols. There is not a single sound card in existence that works \nthe way he described.\n\nEleventh, quantum tunneling causes more heat issues than data corruption \nissues, and has actually been the source of the heat issues in modern \nprocessors for roughly the past 10 years. \n\nTwelfth, just adding four times as many processors doesn't automagically \nmake things four times faster. Cache synchronization, memory bus access \ncoordination, context switching, etc. all eat into the ideal performance \nefficiency. \n\nThirteenth, \"It's hard to design software that makes use of multiple \nprocessors\" is a gross generalization that is subjective and seldom true.\n\nFourteenth, \"...we like our flows of data to be linear...\" Tell that to CPU \ndesigners who have relied on non-linear out of order processing to make \nimprovements in modern CPUs for over a decade.\n\nMaybe you should get out there and do some research on your own, maybe read \na book, instead of fanboy-worshipping someone on YouTube that spoonfeeds \nyou half-baked facts.\n\nIn short, get rekt, fucking idiot.", 
                    "author": "magicstix0r"
                }, 
                {
                    "date": "2015-04-10T01:57:18.441Z", 
                    "text": "+magicstix0r How so? trolling and nothing to proof is stfu/kid", 
                    "author": "Xextreem"
                }
            ], 
            "num_replies": 6
        }, 
        "z13ixtf5pnjsf1wgg04cfjiofzntx3lbvgw": {
            "top_comment": {
                "date": "2015-01-06T18:29:24.629Z", 
                "text": "Suggestion: The hunt for dark matter using the LHC\ufeff", 
                "author": "chemistryguy"
            }, 
            "comments": [
                {
                    "date": "2015-03-21T20:31:55.432Z", 
                    "text": "+IamGrimalkin Yeah I suppose so, but we would have to be pretty lucky \ndepending on what the dark matter is like.", 
                    "author": "Kyler Lumpkin"
                }, 
                {
                    "date": "2015-03-21T20:14:33.867Z", 
                    "text": "+Kyler Lumpkin Both could work depending on the nature of dark matter. The \nLHC could detect a dark matter particle as soon as they boot up again \n(although they would still need to analyse and confirm it).", 
                    "author": "IamGrimalkin"
                }, 
                {
                    "date": "2015-03-21T19:21:26.491Z", 
                    "text": "+IamGrimalkin Yeah that would work, but still wouldn't be as good as making \na specialized detector. Plus, the aim of current dark matter research isn't \nto find HOW it's made, but if it even exists. Maybe later when we pin down \nmore of dark matter's characteristics we can use the LHC.", 
                    "author": "Kyler Lumpkin"
                }, 
                {
                    "date": "2015-03-20T13:46:53.918Z", 
                    "text": "+Kyler Lumpkin The detector isn't, but they could detect a lack of energy \nand momentum in results, which implies a particle their detector can't \ndetect just flew out of the collision.", 
                    "author": "IamGrimalkin"
                }, 
                {
                    "date": "2015-02-19T04:56:18.006Z", 
                    "text": "That's not how these things work, the detector at the LHC isn't NEARLY \nsensitive enough to be able to detect even the more friendly theoretical \ndark matter particles.", 
                    "author": "Kyler Lumpkin"
                }
            ], 
            "num_replies": 5
        }, 
        "z13fs3zyarriwc4ckzeouvgqtlabju0c": {
            "top_comment": {
                "date": "2014-07-14T09:50:02.145Z", 
                "text": "If current gaps are ~30nm, having a photon computer would greatly reduce \nthe number of \"transistors\" or whatever the fundamental component of a \nlight computer would be, because visible light is in the 100-1000 nm range. \nBut perhaps more could be accomplished with a smaller number of components. \nI don't quite understand how the speed of the actual electrons matters \nhere, because the electric field propagates at light speed. Any change in \nelectrical current and voltage will be \"felt\" down the line however fast \none electron's motion can affect adjacent electrons, and then how fast \nthose electrons affect the ones behind them, etc. I must be missing \nsomething, because some very smart people are convinced that this would be \nbetter. Best of luck to them. Let me know when there's a compiler for it.\ufeff", 
                "author": "DFPercush"
            }, 
            "comments": [
                {
                    "date": "2014-07-25T06:56:23.439Z", 
                    "text": "Optics (terahertz region of the EM spectrum) is fussy and sensitive. But \nthere are some profs at my school who are working on making this kind of \ntechnology possible. Maybe in 20 years photonic computers will be a thing, \nor maybe not, but photonics is some pretty cool and weird shit.\n\nAlso, the electric field only propogates at the speed of light in a vacuum. \nIn a conductor it will be slower - an electric field passing through \nmaterials of different conductivity will bend according to Snell's Law \n(optics)", 
                    "author": "KD0SKH"
                }, 
                {
                    "date": "2014-07-20T15:17:32.154Z", 
                    "text": "You are talking about the wave period of light. The light quantum itself is \nmuch smaller.", 
                    "author": "blazebluebass"
                }, 
                {
                    "date": "2014-07-18T14:14:45.122Z", 
                    "text": "+DFPercush By the way I also hold no computer engineering degree nor am I \nstudying to attain one :)", 
                    "author": "Bryan Lee"
                }, 
                {
                    "date": "2014-07-18T14:13:56.092Z", 
                    "text": "+DFPercush Where do you study? xD There's a preview of an introductory to \nsolid state physics here if you're interested:\nhttp://books.google.com.sg/books?hl=en&lr=&id=sM55AgAAQBAJ&oi=fnd&pg=PP1&dq=solid+state+physics+learn&ots=PofhguCV4t&sig=UwMdLpkhXlmWAaZBOvbElXsS-aw#v=onepage&q&f=false", 
                    "author": "Bryan Lee"
                }, 
                {
                    "date": "2014-07-17T23:03:49.202Z", 
                    "text": "+Bryan Lee  \nThat's why I don't have a degree in computer engineering right now. Can you \nrecommend any online resources that would be good to learn about solid \nstate physics? Listening to a professor who could barely speak english \ndidn't do it for me.", 
                    "author": "DFPercush"
                }, 
                {
                    "date": "2014-07-17T13:58:45.172Z", 
                    "text": "+DFPercush Remember that light acts as a wave AND a particle, so not \nnecessarily. Also, the problem with electron's movement speed is that it is \nnot the current we are measuring but rather the literal and physical time \nit takes for the electron to move into the gap. Try not to think of the \nelectrons as a current but as an entity that has to move into and out of a \ngap :)", 
                    "author": "Bryan Lee"
                }, 
                {
                    "date": "2014-07-17T10:00:28.297Z", 
                    "text": "+DFPercush But why does it need to be visible light?", 
                    "author": "DarkYogurt"
                }, 
                {
                    "date": "2014-07-16T10:56:49.657Z", 
                    "text": "Right, current solid state electronics are not restricted by EM wavelengths \nuntil you start talking about interference, but I was speaking of a \nhypothetical light-based computer. Light can't pass through something \nsmaller than its wavelength, can it?", 
                    "author": "DFPercush"
                }, 
                {
                    "date": "2014-07-16T07:57:26.962Z", 
                    "text": "The current processors in the market are 22nm. That is the channel length. \nIt is not related to the wavelength of light. The channel length is in \nsimple terms is the distance between where electrons are and where they \nwant to go to change a 1 to a 0. This requires a minimum amount of voltage \nto trigger the transfer.\n\nThe electricity in transistors does not flow in a \"line\". It is more \ncomplex than that which is why you can't directly apply the electric field \npropagation theory to it.", 
                    "author": "Priyanka Gupta"
                }
            ], 
            "num_replies": 9
        }, 
        "z12hgbtwrtuxv3f0m220cvorkse5xhnjk04": {
            "top_comment": {
                "date": "2015-02-10T17:44:48.588Z", 
                "text": "i still don't understand how the number of transistors affect performance. \ncould somebody explain?\ufeff", 
                "author": "theabdu500"
            }, 
            "comments": [
                {
                    "date": "2015-02-19T04:51:19.000Z", 
                    "text": " Imagine there's a slave doing a lot of work, like maybe mining. This slave \nhas to go through an entire mountain alone, and he would do it twice as \nfast if he had a friend right? And twice as fast yet again if there were \nfour people, and on and on again. ", 
                    "author": "Kyler Lumpkin"
                }, 
                {
                    "date": "2015-02-14T11:22:02.809Z", 
                    "text": "That would be appreciated", 
                    "author": "theabdu500"
                }
            ], 
            "num_replies": 2
        }, 
        "z13dgpjppsajuxdpc04cizi4kvbdffg4wuc0k": {
            "top_comment": {
                "date": "2014-07-14T12:20:07.140Z", 
                "text": "Or we could just sit our asses down and be satisfied and appreciate what we \ngot instead of fliping the whole world to get faster tech.\ufeff", 
                "author": "Andrew Markus"
            }, 
            "comments": [
                {
                    "date": "2014-07-25T16:28:39.000Z", 
                    "text": "+7CellarDoors And I have the right to post whatever I want, wherever I \nwant, and nobody needs jackasses like you spreading hate, got it disphit?", 
                    "author": "Andrew Markus"
                }, 
                {
                    "date": "2014-07-25T15:20:21.660Z", 
                    "text": "+Andrew Markus Public forum, I literally have the only right required to \njudge and comment on you and your words. Don't like it? Tough, don't post \nyour thoughts on the internet then.\n\nNo one is obligated to ignore your comments just because they're yours, \nprincess.", 
                    "author": "A Duck"
                }, 
                {
                    "date": "2014-07-25T13:56:15.734Z", 
                    "text": "+7CellarDoors I appreciate your input, but please, fuck off!\nYou have no right to judge me based on a comment. You don't know me and you \nand therefore you have the right to shut your mouth off.\nThanks.", 
                    "author": "Andrew Markus"
                }, 
                {
                    "date": "2014-07-25T10:22:12.847Z", 
                    "text": "What a sad state the world would be in if scientists and engineers were as \nlazy, content, and lacking in ambition as you. Im glad you're not in any \nposition of authority over technology or industry, as your miserably \nmediocre attitude would hold us back for decades.\n\nGo join a church group, become a bishop or something. You have no right to \ncomment on your progressive betters.", 
                    "author": "A Duck"
                }, 
                {
                    "date": "2014-07-17T09:58:48.460Z", 
                    "text": "+Brandon Phillips Another scenario that may be possible in the future is \nweapons of mass destruction becoming way to easy to produce, leading us to \nhaving to make a system where everyone in the world is always being \nmonitored in order for us not to destroy our selves which would require an \nextrem amount of computational energy", 
                    "author": "DarkYogurt"
                }, 
                {
                    "date": "2014-07-17T11:10:32.000Z", 
                    "text": "+Brandon Phillips Actually... We aren't that far from that technology.\nThere are a couple of problems, though.\n1.) People don't really like to drive in an automated car. (Loss of control)\n2.) Money, money and money!\n3.) We would need to get rid of all the older cars and prohibit driving \nthose on public roads. (So that only integrated vehicles are allowed to do \nso.)\n\nThe development of automated vehicles already is at a point, that there are \nonly a couple of years left, until we actually have some properly \nfunctioning prototypes.\nAnd even there one of the biggest problems is, that the cars on the streets \nAREN'T interconnected and automated.\nOne of the most difficult challenges in getting a fully automated vehicle \nworking right now is, that the other cars in the traffic are controlled by \nhumans (who tend to do mistakes and act impulsively) and you can only use \nsensory data from your own car (instead of having data from all the cars \naround you).\nIf you would interconnect them and take away the steering wheel from the \nhumans, it would be way easier. (And the current prototypes of Google, for \nexample, would already work without any problem in that scenario already, \nas the current prototypes are basically street-ready already. The challenge \nis, to get them to respond perfectly in abnormal situations. [car crashes, \nsomebody driving extremely close behind you, sudden bullshit from the \ndriver in front of you and other stuff like this])", 
                    "author": "Celrador"
                }, 
                {
                    "date": "2014-07-17T03:49:09.000Z", 
                    "text": "A good scenario to think about that can allow people to appreciate and yet \nbe humbled by technology and how far we have yet to go is this:\n\nImagine a system were every vehicle on every road in the world was fully \nautomated, linked and centrally controlled for safety, optimal route, drive \ntime and speed. Every time a new vehicle route is added, every vehicle on \nthe road is adjusted to maximize efficiency of all vehicles. We are so mind \nboggling far from this level of technology it is hard to believe we could \never reach this.", 
                    "author": "Brandon Phillips"
                }, 
                {
                    "date": "2014-07-15T19:45:25.752Z", 
                    "text": "+Celrador Like how the hell are we going to find the fastest route for that \nstupid salesman.", 
                    "author": "Cade Kachelmeier"
                }, 
                {
                    "date": "2014-07-15T11:49:51.094Z", 
                    "text": "Until the day the Terminator movies become reality....", 
                    "author": "Andrew Markus"
                }, 
                {
                    "date": "2014-07-15T11:45:07.517Z", 
                    "text": "It's human nature to try and understand and create. We always want to make \nthings better. Yes, our current technology is extraordinary, but we can do \nbetter.  ", 
                    "author": "cooperwey"
                }, 
                {
                    "date": "2014-07-15T09:02:05.735Z", 
                    "text": "Development is good. Development is, literally, life.", 
                    "author": "TheCaliger"
                }, 
                {
                    "date": "2014-07-15T07:09:53.000Z", 
                    "text": "+Andrew Markus There are too many problems that need to be solved, where \nour current computation power simply isn't good enough for, yet.\n\nSo many theorems to proof, so many simulations to do and so many piles of \ndata to process...\nIt's the curiosity of humankind to figure out the universe, that drives \nthis development more than anything.", 
                    "author": "Celrador"
                }
            ], 
            "num_replies": 12
        }, 
        "z134yr4zwzbwtfgum23nizp4nripfv43u": {
            "top_comment": {
                "date": "2015-03-25T20:53:27.035Z", 
                "text": "Actually having four chips doesn't mean a 4x increase in speed. Check \nout Amdahl's law\ufeff", 
                "author": "Thomas Nehring"
            }, 
            "comments": [
                {
                    "date": "2015-04-09T14:42:51.039Z", 
                    "text": "+bensemus x Wow, Cool stuff! There's a reason I am a software developer and \nnot a computer architect. ", 
                    "author": "Thomas Nehring"
                }, 
                {
                    "date": "2015-04-09T06:12:31.402Z", 
                    "text": "+Thomas Nehring If programs scaled properly then yes it would be a 4x \nincrease in speed. like he said we aren't the best at making parallel \nprograms that can fully utilize our current 4-8 core cpus except in \nrendering as that is a very predictable operation. That law has a clause \nwere there is a set amount of work that cannot be run in parallel. We have \ncomputers with custom os's like the Tianhe-2 with its 32,00 Xeons, each \nwith 16 threads and 48,000 Xeon pi co-processors, each with 57 cores. \nThat's 560,000 threads running at once.\n\nIronically it outputs 34 PFLOPS while its theorized that we need a computer \ncapable of an exaFLOP or more to simulate the human brain. The K \nsupercomputer that outputs 10.5 PFLOPS simulated 1% of the human brain for \n1 second of activity and it took it ~40 minutes to complete the \ncalculations.", 
                    "author": "bensemus x"
                }
            ], 
            "num_replies": 2
        }, 
        "z13zizf50tqsuhsqh04ccn3g0mvjuzbzfug0k": {
            "top_comment": {
                "date": "2015-03-04T00:08:17.096Z", 
                "text": "Just saying, most applications you can buy/download are multi threaded if \nit is of a certain size\nImagine a motherboard with the space for 4-8 processor sockets\nI'd love to use that for gaming\ufeff", 
                "author": "Peter Taylor"
            }, 
            "comments": [
                {
                    "date": "2015-04-06T20:00:51.587Z", 
                    "text": "\"Just saying, most applications you can buy/download are multi threaded if \nit is of a certain size\"\n\nThat's just wrong. The size of the app doesn't ensure multi-cpu support. \nJust look at gaming. We have 30 gb PC games that don't properly support the \nextra hardware. Hell, 90% of them don't even offer 64 bit support. It is \nnot dependent on size, it's dependent on the developer.", 
                    "author": "Sonic Blast Man"
                }, 
                {
                    "date": "2015-03-04T21:01:43.205Z", 
                    "text": "Most games have terrible multi-processor support. Many problems in gaming \nare simple hard to make parallel. Unless a problem can be completely \nparallelized, as in there is absolutely no sequential requirements, then \nthere will be a limit to the speedup that can be achieved. For example if \n90% of a problem can be parallelized then we can achieve at most a 10x \nspeedup. That is no matter how many processors you add a problem with 10% \nsequential execution will never be more then 10x as fast. Games however are \nno where near that level of parallelism and while certain aspects of the \nmath of games can be easily parallelized there are many aspects of a game \nstep which must be done in order.\n\nOf course the debate between a faster dual core versus a slower quad core \nis going to be game dependant, it is becoming more and more in favor of a \nquad core. Eventually 6 and 8 cores will probably become the best bet. \nSimply doubling the amount of processors probably won't get you a very \nlarge performance increase, quadrupling versus doubling a current gen quad \ncore would probably be indistinguishable from each other.\n\nBasically adding more cores is diminishing returns unless you have achieved \n100% parallelization.", 
                    "author": "BoredDan"
                }
            ], 
            "num_replies": 2
        }, 
        "z130gtrrboqlwbgaf04ccbsoiqykentwguo0k": {
            "top_comment": {
                "date": "2014-07-14T00:30:21.414Z", 
                "text": "Ok, so...someone please answer this for me. I have a much better \nunderstanding of computers than the average person. I'm no computer science \nmajor, but I can hold a conversation on just about everything a computer \ncan do.\n\nWhy don't we just make bigger processors? I mean really. It's going to get \nto the point, as stated in the video, that we simply can't go any smaller. \nBeyond the heat issues, and the \"bleeding\" issue, transistors are \"X\" size, \nand you can only put them so close together. Physical space is the omega \nissue. I know that this day in age, us spoiled humans want everything to be \nfaster and smaller, but that age is about to come to an end. Doubling the \ndimensions of a processor would quadruple the available space, and would \nquadruple the computing power. So why not just make bigger processors?\n\nSo...our smart phones are about as smart as they're going to get. So what? \nI'm talking our desktops, which will never go away despite people thinking \nthey will. We will always need powerhouses to run major programs and let's \nface it, you're never going to be photoshopping on your smart phone anyway. \nLaptops have even started to get bigger in the last few years, coming from \na late-90's to mid-00's where there was a race to see how small you can \nget. Mostly it's because we want bigger screens, but for whatever the \nreason, we ARE getting more space to use. Even our smartphones are getting \nbigger again...have you seen the size of some of the newest phones? It's \nlike talking into a DVD case.\n\nBigger processors would be extremely handy in supercomputers, where entire \nbuildings are used by banks of hardware basically wired in series. Imagine \nthe corner of the room with a stack of processors the size of a sheet of \npaper. I can't even imagine the processing power of a chip that big. Stack \nTHOSE in series and a computer could read the entire Library of Congress in \na matter of milliseconds. Heat wouldn't be an issue because the density \nhasn't really changed. Surface area to transistor proximity is still the \nsame, so cooling wouldn't be a problem.\n\nSo really what am I missing? Is cost exponential to the size of the chip? A \n1-inch chip costs $100, a 2-inch chip costs $400? I really don't understand \nwhy this isn't even being considered. Hank mentioned more processors, why \nnot just bigger ones? I said I'm no computer science major, so I admit \nthere may be a factor I'm missing...so someone please enlighten me.\ufeff", 
                "author": "Gunner3789"
            }, 
            "comments": [
                {
                    "date": "2014-09-08T20:38:33.842Z", 
                    "text": "+Radu Murzea Actually, a bigger processor helps in the heat issue. The \nlarger the surface the easier it is to cool, although the real problem with \nheat is a problem of heat density, not absolute heat dissipation (i.e.: we \nhave a few really really really small spots which get really really really \nhot). The main concern, besides the one you mention (signal propagation \ntime) is reliability. The bigger the chip the more impurities it has. And \nno, it's not an easy-to-fix problem (can't be really solved, just sort of \ncircumvented by making chips smaller or integration scale bigger).", 
                    "author": "Javier Setoain"
                }, 
                {
                    "date": "2014-09-08T18:51:32.479Z", 
                    "text": "I'm no computer scientist myself, but I know that a lot of the reason why \nwe can't make a processor physically much bigger is because of its clock \nspeed.\n\nProcessors these days run at GHz frequencies, which means that data has to \nbe really really REALLY (!!!) close physically in order to feed the \nprocessing unit with data that it has to process. If a processor would be \n20cm in length, then there's no way to get data to the processing unit fast \nenough over that distance. In that case you would waste clock cycles: the \nprocessor can handle the data, but there no way to get to it without \nwasting time. This exactly why the L1, L2, L3 etc. caches that you \nsometimes see in a CPU's technical description are packed within the same \nphysical chip as the processing unit and as close as possible to it.\n\nAnother issue that I know would be a problem if you make a physically large \nchip is heat: it would get really hot really fast. Don't know why off the \ntop of my head now, unfortunately...", 
                    "author": "Radu Murzea"
                }, 
                {
                    "date": "2014-07-16T19:28:37.249Z", 
                    "text": "+Javier Setoain \"Because a bigger die implies more impurities by in^2\"\n\nI have to think that would be something we could overcome much easier than \nsimply running out of available space, yeah? Not that it would be easy, at \nall, but it's gonna leave us no choice eventually.\n\nWhat you said about transistor count makes sense tho. There just seems to \nbe no real solution to our computing problem. Quantum computers aren't the \nsolution everyone thinks they are. They won't be any faster per \napplication, they'll just be able to handle many more times the amount of \napplications at the same time. Like a 10000-core processor. Problem being, \nthe entire computer industry will need to change to accomodate it. We have \n8 core processors now that are basically useless because no software \nutilizes that many cores. And now Intel is already talking about 1000 core \n\"conventional\" processors. That's neat and all, good for them, but until \nthe software is there to utilize it, it's useless.\n\nOn the other hand if there was a solution regarding single, dual, and \nquad-cores, there would be no abrupt restructuring of the industry.", 
                    "author": "Gunner3789"
                }, 
                {
                    "date": "2014-07-15T15:40:57.058Z", 
                    "text": "+Gunner3789 \n\"Why don't we just make bigger processors?\"\n\nBecause a bigger die implies more impurities by in^2 and thus a higher \nreject rate during testing. Also, a bigger die implies longer paths so a \nsignal takes more time to go from one part of the processor to another. \nAlso, clock distribution along the chip would become way more complicated \n(things like clock skew is a very real issue in GHz processors). To sum up: \nit wouldn't fix anything. In fact, it would make things worse.\n\n\"Doubling the dimensions of a processor would quadruple the available \nspace, and would quadruple the computing power.\"\n\nYes and a big big big NO. Double the number of transistors doesn't imply \ndouble the computer power, we wish! It's not like you put transistors one \non top of another and everything goes faster all of a sudden... you have to \nmake something with those transistors, and the things we can do with the \nnumber of available transistors don't give us that kind of performance \nboost. In fact, we could put 5 times as many transistors in processors as \nwe're currently putting (GPUs do have that kind of transistor count).", 
                    "author": "Javier Setoain"
                }
            ], 
            "num_replies": 4
        }, 
        "z12cuxfygmzjvbzjq04cgxpropafurmjr3c": {
            "top_comment": {
                "date": "2014-07-13T13:39:03.637Z", 
                "text": "this might be a dumb question but cant they use natural things like potato \nchips and maybe it will become faster AND better for the environment.\ufeff", 
                "author": "Super Hans"
            }, 
            "comments": [
                {
                    "date": "2014-07-15T12:50:13.753Z", 
                    "text": "+JusticeRetroHunter Micro-Chip / Potato-Chip I see what you did there =)", 
                    "author": "TomlinsTE"
                }, 
                {
                    "date": "2014-07-13T19:38:48.800Z", 
                    "text": "Just realized i am an idiot.\n\n\"potato chips\" well done, well done.", 
                    "author": "JusticeRetroHunter"
                }, 
                {
                    "date": "2014-07-13T19:02:24.001Z", 
                    "text": "10/10 super hans comment", 
                    "author": "seriousbees"
                }, 
                {
                    "date": "2014-07-13T16:35:29.333Z", 
                    "text": "silicon is natural. Potato chips are not natural, but potatoes themselves \nare, and are made of carbon.graphite is carbon, which is what graphine is \nmade from.", 
                    "author": "JusticeRetroHunter"
                }, 
                {
                    "date": "2014-07-13T13:43:14.351Z", 
                    "text": "Bacteria would eat it", 
                    "author": "HireDeLune"
                }
            ], 
            "num_replies": 5
        }, 
        "z12gdhvrgynqs3yq004chlkxpwyfdfqbntk0k": {
            "top_comment": {
                "date": "2014-07-14T02:15:44.185Z", 
                "text": "A great explanation of (the limits of) Moore\u2019s Law & how computers process \ninformation: \ufeff", 
                "author": "Ben Parr"
            }, 
            "comments": [
                {
                    "date": "2014-09-03T07:02:38.737Z", 
                    "text": "nice video", 
                    "author": "sai ayyagari"
                }, 
                {
                    "date": "2014-08-31T09:16:54.775Z", 
                    "text": "Uyt\nthigh\n", 
                    "author": "Hamed Hamed"
                }, 
                {
                    "date": "2014-08-20T14:42:29.566Z", 
                    "text": "+Mahesh Madusanka ", 
                    "author": "HUSAIN BOHRA"
                }, 
                {
                    "date": "2014-08-20T14:41:56.057Z", 
                    "text": "X", 
                    "author": "HUSAIN BOHRA"
                }, 
                {
                    "date": "2014-08-09T12:55:52.380Z", 
                    "text": "Hi my name is zenaida and nice too met you all I first time to come here in \ngoogle+", 
                    "author": "Zenaida Delez"
                }, 
                {
                    "date": "2014-07-21T05:10:08.509Z", 
                    "text": "YES VERY INFORMATIVE", 
                    "author": "sai ayyagari"
                }, 
                {
                    "date": "2014-07-20T09:21:01.482Z", 
                    "text": "Very educative and informative", 
                    "author": "Musediq Salisu"
                }, 
                {
                    "date": "2014-07-18T01:43:54.609Z", 
                    "text": "insightful", 
                    "author": "Celine Mrouwe"
                }, 
                {
                    "date": "2014-07-17T07:14:34.514Z", 
                    "text": "Good morning .", 
                    "author": "Balbhadra Jhariya"
                }, 
                {
                    "date": "2014-07-16T11:10:22.158Z", 
                    "text": "drole", 
                    "author": "Cedric Guede"
                }, 
                {
                    "date": "2014-07-15T23:44:34.234Z", 
                    "text": "Hi guys", 
                    "author": "Zaki Zaki"
                }, 
                {
                    "date": "2014-07-15T15:23:05.065Z", 
                    "text": "+Zion Shore +Mikael Morrell-Stinson ", 
                    "author": "Christy Morrell-Stinson"
                }, 
                {
                    "date": "2014-07-15T15:19:44.811Z", 
                    "text": "+diov Steve ", 
                    "author": "Mobile World"
                }, 
                {
                    "date": "2014-07-15T10:13:43.545Z", 
                    "text": "+Tyler Bules lol", 
                    "author": "Note Warner"
                }, 
                {
                    "date": "2014-07-14T22:46:21.532Z", 
                    "text": "This pretty much sums up what I have spent the last 4 years of college \nlearning... ", 
                    "author": "Tyler Bules"
                }, 
                {
                    "date": "2014-07-14T15:14:38.125Z", 
                    "text": "Really well done. Making my kids watch this. ", 
                    "author": "Clinton Reed"
                }, 
                {
                    "date": "2014-07-14T15:08:03.063Z", 
                    "text": "Hii im new member", 
                    "author": "Asif Mahar"
                }, 
                {
                    "date": "2014-07-14T15:03:43.967Z", 
                    "text": "nic", 
                    "author": "anokha rajpot"
                }, 
                {
                    "date": "2014-07-14T14:54:36.258Z", 
                    "text": "hor", 
                    "author": "MUNEESWARAN SELVA"
                }, 
                {
                    "date": "2014-07-14T14:51:59.828Z", 
                    "text": "+solomon kwabena gyimah ", 
                    "author": "Kumar mallikarjun"
                }
            ], 
            "num_replies": 52
        }, 
        "z13oy5ly1vzlu5atl22lhzj4lwyld5mn2": {
            "top_comment": {
                "date": "2014-07-13T23:18:57.400Z", 
                "text": "But still every expert predicts that in 2030-s-50-s we will have \nhuman-level AI? Even though we have so many problems with making computers \nsmarter? How so?\ufeff", 
                "author": "Kate Senatskaya"
            }, 
            "comments": [
                {
                    "date": "2014-08-13T19:20:31.805Z", 
                    "text": "We are actually waiting for a breakthrough on science to keep evolving \nthings. I believe we have already done what we could possibly do until now.", 
                    "author": "L\u00e1zaro Carvalhaes"
                }, 
                {
                    "date": "2014-08-03T22:31:30.260Z", 
                    "text": "I can't see it, either ......", 
                    "author": "David Andrews"
                }
            ], 
            "num_replies": 2
        }, 
        "z122j3lanmiqfle3323tyzia1x31frvrb04": {
            "top_comment": {
                "date": "2014-07-13T13:17:45.923Z", 
                "text": "But what tells the thing that directs the current where to direct it?\ufeff", 
                "author": "Nemo Fil (\u202b\u05e0\u05d9\u05de\u05e8\u05d5\u05d3 \u05e4\u05d9\u05dc\u05d9\u05d1\u05d4\u202c\u200e)"
            }, 
            "comments": [
                {
                    "date": "2014-07-15T00:10:03.038Z", 
                    "text": "+Danny Ovox\nYES Me too. I initially started as a programmer just to make games when I \nwas 12, been 8 years now.. I've always had an interest in all kinds of \nscience, but now I've started to get into electrical engineering and \nrobotics as well.\nBtw you might already know about this but a pretty cool cheap way to test \nout concepts and prototypes for robotics or any electrical machinery is to \nplay the game Garry's Mod. There's a mod for it called wiremod that has \ntools for basically anything would you need to program robots and stuff. \nSince the game is built on the Source physics engine, you can watch your \ncreations physically interact with it's surroundings (although the physics \nare obviously not entirely accurate to real life). People make some pretty \ninsane stuff in that game, from robots with AI to video games within the \nvideo game to entire computers and operating systems. It's nuts.", 
                    "author": "Fleegsta"
                }, 
                {
                    "date": "2014-07-14T23:51:36.783Z", 
                    "text": "+Fleegsta yes my friend, I love computer science, electrical engineering, \nand mechanical engineering. Shocker! That is why I would love to go into \nrobotics :) it combines the three wonderful sciences.", 
                    "author": "Danny Sturridge"
                }, 
                {
                    "date": "2014-07-14T20:17:43.308Z", 
                    "text": "Logic gates. That's more in the field of electrical engineering than it is \ncomputer science. Once you figure out logic gates, you realize all a \ncomputer is is a big series of logic gates.", 
                    "author": "Fleegsta"
                }
            ], 
            "num_replies": 3
        }, 
        "z12md3fjtzbldlwqj04cgpnqynyegzoryz00k": {
            "top_comment": {
                "date": "2014-07-15T07:51:45.117Z", 
                "text": "Neat stuff except I don't know where you were going with the 6.5cm/hr \nelectrons to a lamp analogy. we're talking data transfer, not raw power. \nData represented by electrons travels down copper at something like .6 * c \n(speed o' light). can't look up exact figure... it's like two in the \nmorning and I'm nodding off.\ufeff", 
                "author": "Scotty Catman"
            }, 
            "comments": [
                {
                    "date": "2014-09-28T14:44:13.023Z", 
                    "text": "The gaps in the chain don't exist because the electrons don't require \nelectrons behind them to propagate. The chain is an analogy for speed, not \nelectricity. Basic electricity seeks a ground, and given the cable or wire \nis within spec, it will propagate through until it reaches said ground. Its \npath might take it through many data-manipulating transistors, such is the \npurpose of the circuit.", 
                    "author": "Scotty Catman"
                }, 
                {
                    "date": "2014-09-28T08:31:39.009Z", 
                    "text": "+Scotty Catman thank you.\nbut how about this one, take a look:\nso imagine the electrons in wire is like a chain, the propagation may go so \nfast but the gap has no electrons, the electron requires to jump across the \ngap before the propagation can reach the other side. Is this theory \nacceptable?", 
                    "author": "Jay Leong"
                }, 
                {
                    "date": "2014-09-27T14:43:24.634Z", 
                    "text": "You are absolutely wrong there. You can't just convert m/s (velocity) to Hz \n(frequency). \"The electron will respond to the information\"... the presence \nof absence of electrons *is* information. The moon-laser analogy doesn't \napply here, there is no way of transmitting data across a wire from a \nperpendicular perspective.\"No matter how fast the electron can respond to \nthe information...\" like I said before, information doesn't affect \nelectrons. Information is an arbitrary thing, it doesn't magically plant \nitself on an electron. The absence or presence of electrons is the \nrepresentation of data.", 
                    "author": "Scotty Catman"
                }, 
                {
                    "date": "2014-09-27T12:18:53.952Z", 
                    "text": "+Scotty Catman the electron will respond to the information (a input)at the \nspeed of .6c but when it move across the gap it takes much slower speed. If \nyou put the gap in large scale you will understand how slow it is. And \nmaybe just like moving a laser beam across the moon surface, it may go \nfaster than light but the information's speed still follow the light speed. \nNo matter how fast the electron can respond to the information, it still \nlimit but its physical speed. If you put more than 179 875 475 input/s \n (0.6c=179 875 475 m / s) it will be unable to work because the frequency \nis too high.", 
                    "author": "Jay Leong"
                }, 
                {
                    "date": "2014-08-19T23:50:52.173Z", 
                    "text": "+Patrick Staight\nYou're correct, that's what I've been trying to say.", 
                    "author": "Scotty Catman"
                }, 
                {
                    "date": "2014-08-19T17:24:44.961Z", 
                    "text": "When one electron jumps to the next nucleus in a metallic bond it will \nincrease the probability of other electrons further down the wire jumping \nto their next nuclius. So the rate at which a single electron jumps down a \nwire may be 6.5cm/hour while the delay between pushing an electron into one \nend of a wire and having one pop out the other end is (the length of the \nwire)/0.6c. Please correct me if I'm wrong.", 
                    "author": "Patrick Staight"
                }, 
                {
                    "date": "2014-07-18T15:23:08.832Z", 
                    "text": "+Bryan Lee\n8.5cm/h isn't gap speed. No one's talking about gap speed. 8.5cm/h is the \nspeed of a single electron across copper at 120V.\nWhat I'm saying is that this speed isn't significantly low in computing. We \ndon't care about the single electron... if it moves slowly, that doesn't \nmatter. What matters is how quickly that electron can move an electron on a \ncopper atom in front of it and so on, which is an amazing .6c.", 
                    "author": "Scotty Catman"
                }, 
                {
                    "date": "2014-07-18T14:19:40.476Z", 
                    "text": "+Scotty Catman Also, as mentioned by Green, the slow 8.5cm/h speed is \nnearly negligible when we are dealing with gaps merely nanometres wide. The \ncurrent will still flow at 0.6c but the speed of the electron itself \nbridging the gap is at 8.5cm/h is it not? ", 
                    "author": "Bryan Lee"
                }, 
                {
                    "date": "2014-07-18T14:18:12.726Z", 
                    "text": "+Scotty Catman Again, correct me if I am wrong, but don't we only treat it \nas a chain of electrons when we are talking about current and signals -- \nwhere electrons are already present to propagate information? From what I \nunderstand we aren't dealing with the current but rather the physical \nentity of the electron that has to actually bridge the gap between the \nsilicon slides to enable the current to flow.", 
                    "author": "Bryan Lee"
                }, 
                {
                    "date": "2014-07-17T18:59:57.977Z", 
                    "text": "+Bryan Lee\nYou don't treat it like individual electrons though. It's treated as a \nchain of electrons... you move one end of the chain, the other moves as \nwell. Can you imagine how slow a computer would be if we were relying on a \nspeed of 8.5cm/h?\nAdditionally, he's relating copper to graphene, not silicon to graphene. \nSilicon is a semiconductor, graphene is a highly-efficient conductor.", 
                    "author": "Scotty Catman"
                }, 
                {
                    "date": "2014-07-17T14:02:33.319Z", 
                    "text": "+Scotty Catman Correct me if I'm mistaken, but this isn't a matter of \ncurrent but rather we are dealing with how fast the actual electron can \nmove into and out of the silicon gap. Try not to think of the electron as \npart of a current but instead a physical entity that has to move 8.5cm/h \ninto a gap :)", 
                    "author": "Bryan Lee"
                }, 
                {
                    "date": "2014-07-17T10:52:08.545Z", 
                    "text": "I don't think he was wrong, I think he was missing the point they were \ntrying to make in this video. English is not my mother tongue and more \noften than not I fail to explain myself clearly, but I don't think that's a \nreason to make fun of a reasonable and polite conversation, even if it's \nbeen a bit clumsy (at least on my part).", 
                    "author": "Javier Setoain"
                }, 
                {
                    "date": "2014-07-16T21:30:38.000Z", 
                    "text": "+Javier Setoain +Scotty Catman Come on guys, get back at it. You gotta find \nout who's righter.", 
                    "author": "Brandon Lisik"
                }, 
                {
                    "date": "2014-07-16T07:27:37.000Z", 
                    "text": "That's exactly what I said. The \"signal\" you detect is the electric field, \nwhich propagates at .5-.7c (depending on the wire). The electrons respond \nto that electric field and that response can be measured all along the \nwire, not because one electron (or group of them) arrive from one end to \nthe other but because they gain net velocity in the whole circuit, and that \nmovement is what we call electricity (this is what the switch/lamp example \nstates, which is the same example my professor used btw). Regarding the \nconductivity of graphene, it is due to being one single atom layer (as the \nvideo says) and having all the electrons confined in two dimensions (as the \nvideo says). Graphite, which is composed of multiple layers of graphene \nheld together by van der Waals forces), doesn't retain those wonderful \nproperties even though it's the same structure (carbon atoms in an \nhexagonal lattice). Once again, the lamp and switch example was just a way \nto say: \"hey, electrons don't move in a copper wire in one single \ndirection, in fact they move along it pretty slowly; since graphene is two \ndimensional, electrons have less degrees of freedom and they move more \nefficiently along graphene\". I think you're missing the point here, really.", 
                    "author": "Javier Setoain"
                }, 
                {
                    "date": "2014-07-15T20:53:10.670Z", 
                    "text": "Except that's wrong. The structure of copper allows for an input voltage on \none end to be detectable on the other end at a rate of roughly .65*c. This \nis taking the non-linear movement into account. Individual electrons may be \nmoving slowly, but it's a mass movement; huge magnitudes of electrons are \nmaking jumps to other copper atoms. So wave propagation is the important \nthing; it's the speed at which an input can cause an output on a length of \ncopper or graphene or what have you. The 6.5cm/s might only jump up to \n10cm/s with graphene, I don't know the numbers there. The revolutionary \nthing about graphene isn't so much its speed but rather its power \nefficiency due to extremely low resistance. Accurate interpretation of an \ninput on graphene can be done with smaller input on graphene than copper.", 
                    "author": "Scotty Catman"
                }, 
                {
                    "date": "2014-07-15T17:55:28.594Z", 
                    "text": "Wave propagation refers to the electric field. Individual electrons move \nvery fast but they do so in random directions. In the absence of an \nelectric field, their net movement is 0 and so their net velocity is 0 too. \nIn the presence of an electric field they gain some net velocity, but it's \nway slower than their specific velocity, which is closer to the speed of \nlight in the medium. In graphene, since electrons don't have so much \nfreedom of movement, it's a completely different story. The great \nelectrical and electronic properties of graphene arise from this fact, \nwhich is where this video was going with the switch and lamp analogy :-)", 
                    "author": "Javier Setoain"
                }, 
                {
                    "date": "2014-07-15T15:55:19.498Z", 
                    "text": "I re-did my research and your phrasing is a bit ambiguous. Wave propagation \n(the important speed) is what I was referring to moving at speeds of .6*c. \nI believe the video was correct about 6.5cm/hr speed of a single electron \nalong a wire, but it's a pointless figure.", 
                    "author": "Scotty Catman"
                }, 
                {
                    "date": "2014-07-15T15:27:40.292Z", 
                    "text": "Electrons might move at that speed, but they don't move ALONG a wire at \nthat speed.", 
                    "author": "Javier Setoain"
                }
            ], 
            "num_replies": 18
        }, 
        "z12cifzrlz3nftfp104cjltwmvmycboruno0k": {
            "top_comment": {
                "date": "2015-02-25T01:46:25.913Z", 
                "text": "1:36 \"How can we get more transistors onto a chip?\"\n.......make a bigger chip, duh.... XD\ufeff", 
                "author": "dc2008242"
            }, 
            "comments": [
                {
                    "date": "2015-04-09T20:30:46.126Z", 
                    "text": "+bensemus x thankyou for the info", 
                    "author": "dc2008242"
                }, 
                {
                    "date": "2015-04-09T06:19:38.843Z", 
                    "text": "+dc2008242 What he said applied to #2 and #1 is wrong as bigger transistors \nmeans less per mm2 which is the exact opposite of what we want. We do have \nbigger chips but if you look at them they are usualy clocked at about 2Ghz \nwhile consumer chips can go as high as 4.4Ghz. Xeon vs i7 4790", 
                    "author": "bensemus x"
                }, 
                {
                    "date": "2015-03-01T14:54:38.629Z", 
                    "text": "+thewiirocks the way I see it, there are two ways of making it bigger\n1.) make the transistors bigger\n2.) add more transistors\n\n.......now what you said is a bit confusing to me (which is odd because I \nusually understand complicated technologies) but I want to know, does what \nyou say apply to #1, #2, or both?", 
                    "author": "dc2008242"
                }, 
                {
                    "date": "2015-03-01T03:05:06.851Z", 
                    "text": "Sounds simple enough, doesn't it?\n\nThe problem is that Moore's Law is about how many transistors we can fit *in \nthe same area of silicon*. Increasing the number of transistors for the \nsame surface area will make the chip WAY faster due to a decrease in signal \ntime. \n\nThink of it this way: A computer operates on a digital \"clock\". The clock \nis a circuit that flips back and forth from 0 and 1 at a regular interval. \nThe rate of this clock is what gives us the GHz performance number for the \nchip. Each time the clock updates it causes a cascade of switches in the \nstate of the transistors on the chip. This isn't instantaneous. In fact, it \nlooks a LOT like a complex domino setup.\n\nIf you've ever seen densely packed dominos falling, you've probably noted \nthe wave of collapse that passes from one end to the other. The time for \nthe wave to go from one end to the other is called \"metastability\" in the \ncomputer science world. Our chips have to be clocked so that the chip's \nstate is completely stable before the next clock tick.\n\nIn practical terms this means that a bigger chip will have to be clocked \nslower. Slower clocking means fewer instructions per second which defeats \nthe goal of making the chip faster. \n\nMake sense? :-)", 
                    "author": "thewiirocks"
                }
            ], 
            "num_replies": 4
        }, 
        "z12vuxowatjnz5avw23ug32atsr3dfdmj": {
            "top_comment": {
                "date": "2015-04-22T10:11:32.000Z", 
                "text": "It's not science. It's God! Praise God for technologies!\ufeff", 
                "author": "Midnite Reveries"
            }, 
            "comments": [
                {
                    "date": "2015-04-28T01:50:36.123Z", 
                    "text": "Now I believe you", 
                    "author": "Unkown 2.0"
                }, 
                {
                    "date": "2015-04-28T01:32:38.000Z", 
                    "text": "+Unkown 2.0 \n*\"The Lord created the computing machines.\"*  - Matthew 16:1-12", 
                    "author": "Midnite Reveries"
                }, 
                {
                    "date": "2015-04-28T01:28:58.335Z", 
                    "text": "Obvious troll is obvious. Unless you're actually stupid.", 
                    "author": "Unkown 2.0"
                }
            ], 
            "num_replies": 3
        }, 
        "z121fb3zdprhsrrgv04cirxjstmptzmadso0k": {
            "top_comment": {
                "date": "2014-08-25T22:29:28.471Z", 
                "text": "Thank you sooooooo much and God bless. This was amazing and beautiful. I am \nan investment firm banker and I admire your work. Please continue to share \nwith the world of education. The greatest thing for this generation is the \nability to access quality information. From my family and friends and from \nall of your subscribers. Thank you sooooooo much! !!!\ufeff", 
                "author": "JEAN MARANELLO"
            }, 
            "comments": [
                {
                    "date": "2014-11-04T17:53:50.456Z", 
                    "text": "Yes. We need to continue to motivate our youth. An education made me a self \nmade multi millionaire. We our selves must study, practice and teach", 
                    "author": "JEAN MARANELLO"
                }, 
                {
                    "date": "2014-11-02T22:24:28.884Z", 
                    "text": "I discussed this with a friend recently - there is so much information on \nyoutube these days, it is now really easy to learn anything from soldering \nto repairing a computer or a car. Back when we were kids and teens, it was \nmuch harder to learn new things when your dad/mom/uncle/neighbour couldn't \nteach you.\nNow we have this amazing wealth of tutorials on youtube and other sites, \nbut kids and teens mostly don't seem to be interested. It seems they rather \nwatch videos of somebody else playing a game...\nOr maybe it is just me becoming a grumpy old guy who thinks kids are stupid \nthese days, I don't know! ;)", 
                    "author": "highks"
                }
            ], 
            "num_replies": 2
        }, 
        "z13xxfnpclqgj5ecz22nyny52nzhy15s1": {
            "top_comment": {
                "date": "2014-07-13T19:03:14.526Z", 
                "text": "Transistors are not only digital, that is, they are not only on-or-off, \n0-or-1. Transistors are also analog, meaning that as the current between \nthe base/gate and the collector/drain (or emitter/source, it's \ncomplicated). The point is, you did make it too simple.\ufeff", 
                "author": "PitaJ"
            }, 
            "comments": [
                {
                    "date": "2014-07-15T07:14:28.220Z", 
                    "text": "input/output", 
                    "author": "Maoh Lynx"
                }, 
                {
                    "date": "2014-07-13T22:55:55.716Z", 
                    "text": "Point is, we're not all EE majors.", 
                    "author": "Brad Harris"
                }, 
                {
                    "date": "2014-07-13T19:10:20.713Z", 
                    "text": "They oversimplified many things in the video, that one however is an \nappropriate abstraction in this context. ", 
                    "author": "Suiseiseki Desu"
                }
            ], 
            "num_replies": 3
        }, 
        "z13wvfioixufcjuup234t12gwmfqj5vr404": {
            "top_comment": {
                "date": "2014-07-13T11:11:48.825Z", 
                "text": "Why not just make the chip bigger so you can fit more transistors on it. \nSimple. \ufeff", 
                "author": "noturaveragewatcher"
            }, 
            "comments": [
                {
                    "date": "2014-07-15T14:52:17.362Z", 
                    "text": "+Suiseiseki Desu Larger SRAMs are also slower, for one. Also, if the cache \noccupies a region too big, the physical distance comes into play and you \nmight need to slow your SRAM clock, i.e.: slower memory access (in the \ncritical path, by the way). Clock skew is a problem in large chips, and not \nan easy one. You're right, defects are a problem in large chips, but they \nare not the only one (not by far).", 
                    "author": "Javier Setoain"
                }, 
                {
                    "date": "2014-07-13T19:03:12.219Z", 
                    "text": "+TheDesius\nO really? Suppose I could make my CPU a bit larger and add some extra cache \nmemory to it. How is it supposed to make it slower? Accessing cache would \nstill be much faster than reading data from the DRAM memory.", 
                    "author": "Suiseiseki Desu"
                }, 
                {
                    "date": "2014-07-13T18:54:12.416Z", 
                    "text": "The chip sizes actually have been getting larger over the years. However to \nmanufacture a larger chip you also need better technologies and higher \nquality of the crystal. Bigger chip is more likely to be defect, so after \ncertain size it's impossible to manufacture them economically.", 
                    "author": "Suiseiseki Desu"
                }, 
                {
                    "date": "2014-07-13T12:38:29.577Z", 
                    "text": "Also bigger chips are more expensive", 
                    "author": "zizipanyout"
                }, 
                {
                    "date": "2014-07-13T11:58:59.721Z", 
                    "text": "more travel time between the transistors, so the chip would get slower \ninstead of faster", 
                    "author": "TheDesius"
                }
            ], 
            "num_replies": 5
        }, 
        "z135shxj0kytfzwkt22ujvwioz23zdjjd04": {
            "top_comment": {
                "date": "2014-07-28T23:08:29.409Z", 
                "text": "Does graphene not have 0 resistance to electron flow, meaning that \nelectrons would travel at light speed like an optical computer?\ufeff", 
                "author": "Lewis Rainwater"
            }, 
            "comments": [
                {
                    "date": "2014-10-05T03:50:05.000Z", 
                    "text": "+HomeSkillenSLICE My mistake, it's actually 0.1% according papers \nsuch \"Mobility and Saturation Velocity in Graphene on SiO2\" by Dorgan et \nal. and \"Room temperature velocity saturation in intrinsic graphene\" by \nShishir et al.", 
                    "author": "MysticKenji2"
                }, 
                {
                    "date": "2014-10-05T00:19:39.255Z", 
                    "text": "+MysticKenji2 source ?", 
                    "author": "HomeSkillenSLICE"
                }, 
                {
                    "date": "2014-08-22T16:52:32.773Z", 
                    "text": "There is still some resistance, it's just incredibly low. Electrons can \ntheoretically move at about 1% of the speed of light in graphene of the \nhighest possible quality.", 
                    "author": "MysticKenji2"
                }
            ], 
            "num_replies": 3
        }, 
        "z12gw3bwlrniejtai04ccnmjdxywzrryrfw": {
            "top_comment": {
                "date": "2015-02-10T05:54:37.000Z", 
                "text": "I swear this guy knows literally everything. Also I lol'd when he called \nquantum mechanics an enchanting minx. Also when he said \"laser computer... \nah want one of those.\"\ufeff", 
                "author": "Argonaut22j"
            }, 
            "comments": [
                {
                    "date": "2015-03-22T04:49:42.680Z", 
                    "text": "he's great, but most of his videos he learns it all. It's scripted. But he \nis a smart guy", 
                    "author": "Kaleb Dodson"
                }, 
                {
                    "date": "2015-03-17T12:08:27.197Z", 
                    "text": "+Battusai1984 Do you have a link? I see the Quantum Computing videos, but I \ndon't see any videos on Optical Computing. Thanks!", 
                    "author": "thewiirocks"
                }, 
                {
                    "date": "2015-03-17T00:51:51.923Z", 
                    "text": "+foua & +OgreSamanosuke - FWIW, I work with loads which can scale linearly \nalmost infinitely. Basically, each record of data has heavy calculations \nrun against it, but these calculations are not dependent on other records. \nSo I distribute each record to a separate processor (per-core or full \nprocessor) and let them operate in complete parallel. The biggest challenge \nis keeping each processor \"fed\". Data movement itself takes time, so one \nprocessor ends up dedicated to routing incoming records to each processor's \nbuffer. The end result looks a lot like a high-performance direct-injection \nengine. The \"pressure\" of the incoming data stream has to stay high or \nunderflows (insufficient fuel) will occur. Conversely, allowing overflows \nmay mean that the buffer feeder thread isn't distributing its time \nefficiently to keep each processor fed.\n\nThere is some synchronization on the per-processor buffers, but there are a \nnumber of methods for keeping it to a minimum so that sync-locks have no \ndiscernible impact on performance. My real problem is that multi-core \nprocessors physically can't scale linearly. Which brings me to the response \nfrom +daraptor0. \n\n+daraptor0 - I don't think Hank is talking about the transistor heat \nlimits. Or if he is, he's not really making that clear. What I think he's \ntalking about is Thermal Design Power. \n\nThe inherent problem with multi-core processors is that while we can pack \nas many as 20 cores in a single chip, our ability to dissipate heat does \nnot increase linearly with the number of cores. The maximum amount of heat \nthat can be dissipated is known as the \"Maximum Thermal Design Power\".\n\nMax TDP leaves architects and software engineers with a quandry: Do we take \nthe screaming-fast single-threaded approach or do we run multiple cores \nwith each core having a lower individual performance?\n\nThis is not a trivial question! If your code is sensitive to \nsynchronization problems, the single-threaded approach may be significantly \nfaster. But if the workload is highly parallel in nature (especially if the \nworkload is long-running), choosing sustained processing over multiple \ncores may lead to the workload being completed faster.\n\nGiven that we're getting diminishing returns on continuing to clock up \nCPUs, the latter is very appealing. But that means switching to an entire \nclass of algorithms that are inherently parallel. Considering that only the \ntop 1% of qualified engineers can actually wrap their heads effectively \naround multi-threaded code, that's more difficult than it sounds! ", 
                    "author": "thewiirocks"
                }, 
                {
                    "date": "2015-03-16T13:01:41.753Z", 
                    "text": "+OgreSamanosuke You claimed that the statement \"your computer can be 4x \nfaster\" is \"outright incorrect\". Disregarding practicalities and \nsynchronization, like you said, if each core works independently it is four \ntimes faster, even if this barely happens in practice. I would not go as \nfar as saying that it's outright incorrect. I think it gets its point \nacross accurately. I mean, whatever number you use there instead of 4x \nthere will be people disagreeing.", 
                    "author": "foua"
                }, 
                {
                    "date": "2015-03-16T06:27:11.818Z", 
                    "text": "+foua \nhttp://blog.codinghorror.com/quad-core-desktops-and-diminishing-returns/ Is \na decent explaination of it. Basically because you need to use the bus to \npass info across on what each thread is doing when multi-threading you are \nlimiting how fast you can go. Multi-cores are fine when you are using each \none independently. ", 
                    "author": "OgreSamanosuke"
                }, 
                {
                    "date": "2015-03-14T13:12:15.505Z", 
                    "text": "+OgreSamanosuke What diminishing returns are there? If you compare the one \nchip to the four you can process four times as many instructions in \nparallel as the sequential in the same timespan. If you start thinking \nabout parts which can not be done in parallel, then of course you'll get \ndiminishing returns, but it's still upper-bounded by four times the speed.", 
                    "author": "foua"
                }, 
                {
                    "date": "2015-03-09T04:08:10.031Z", 
                    "text": "+magicstix0r\n+thewiirocks I believe he was referring to the way he explained how \ntransistors work. Transistors have 3 leads, the collector emitter and base. \nThere are 2 types of transistors, NPN and PNP, this of course refers to the \nleads. Transistors are turned on by applying a voltage to the base, a \npositive voltage for NPN and a negative voltage for PNP. Once the proper \nvoltage is applied to the base-emitter circuit, current will flow through \nthe emitter-colleter leads, aka the transistor is on. Depending on what \ntype of transister you have determines the direction of current flow. \nRemoving the current flow from either the base-emitter or collector-emitter \ncircuits will turn the transistor off. The base and collector or not \nattached in a circuit point of view, as in no current flows between these 2 \nleads. the Base-Emitter circuit requires a .7 volt difference in potential \nto remain on, and the Emitter-Collector requires a .2 volt difference in \nvoltage potential.\n\nAlso much of his explanations on how semiconductors function in general are \ninaccurate. The most important fact about heat regarding semiconductors is \nthat they have a negative temperature coeffecent. As current flows through \na semiconductor (any semiconductor, diodes, SCR, transistors  ect) they \nheat up, as the heat increases, resistance decreases, allowing more current \nto flow through the device. More current means more heat, this will \nincrease untill the device burns up. This can be prevented by placing \nresistave devices in the circuit.\n\nI believe many of these inaccuracies can be arbitrated to a lack in \nunderstanding how electricity works. The best way to explain fundamental \nelectrical theroy is like this. A negative charge is an excess of \nelectrons, a positive charge is a lack of electrons, the deference between \nthese 2 points is called Voltage. Voltage is a pulling force, it wants to \npull all the electrons towards it. The electrons flow from negative to \npositive, think of a vacuum in a tube and the air wants to fill it. The \nvacuum is the voltage and the air is the electrons. This flow is called \ncurrent, or amps. Current flows in the opposite direction of applied \nvoltage. Watts is an expression of volts times amps, ie 12 volts with 6 \namps is 72 Watts. This is of-course only the most rudimentary explanation \nof electricity, but it's all you need to know to understand the operation \nof semiconductors.", 
                    "author": "daraptor0"
                }, 
                {
                    "date": "2015-03-07T10:59:17.265Z", 
                    "text": "+thewiirocks\nThere is a really nice video on optic computing on veritasium's channel you \nmight like,", 
                    "author": "Battusai1984"
                }, 
                {
                    "date": "2015-03-07T08:02:26.015Z", 
                    "text": "you guys need to get over yourselves and realise Hank is making youtube \nclips that explain the subject so people who are not scientists can get an \nidear of the subject. if you want perfect info GO TO COLLEGE aand get a \nscience degree and then find a way to explain things so people who have not \ngone to college that have an interest in science can understand it. jeez \nstop nit picking", 
                    "author": "Danger Mouse"
                }, 
                {
                    "date": "2015-03-01T02:49:08.873Z", 
                    "text": "+magicstix0r Stating that Hank's video is essentially wrong is a rather odd \nstatement. As a computer science professional I found his explanations \nsimplistic but generally correct. For example, he is correct that a \"shared \nnothing\" problem can achieve n times the performance. However, most \nproblems have at least some shared components which are subject to \nscalability issues like those identified by Amdahl's Law. This is the \n\"diminishing returns\" you refer to.\n\nHank's explanation of \"we're bad at writing parallel software\" greatly \nsimplifies the matter, but is essentially correct. He is also correct in \nstating that most of the research is currently focused on increasing \nparallelism and that heat dissipation is a significant hurdle to increasing \nsaid parallelism. (Research the Max TDP of modern microprocessors. If you \npoke around enough you should find a good explanation of why TDP suddenly \nmatters in a world of multi-core chips.) \n\nI found his explanation of electron slowness to be possibly the most \noffensive statement, but again it's not really worth arguing over. \nExplaining the difference between an energy wave and electrons is kind of \nbeyond what he's trying to get across. For better or worse, the energy wave *is \nslowed* by passing through a medium of electrons which makes his point \nstill valid. Optical computing would not be subject to this limitation and \n*may* be faster under the right circumstances. (Those circumstances being \nthat the computer operates in a vacuum and has fewer optical switch points \nthan the number of electron interactions required by today's computers.)", 
                    "author": "thewiirocks"
                }, 
                {
                    "date": "2015-02-22T10:05:54.412Z", 
                    "text": "While I agree that Hank appears to know everything, researching science is \ndifficult you know? Especially that science itself is a really broad \nsubject. We should take into account that Hank is a science educator \nmeaning he covers physics, biology and chemistry. These fields may have \ncorrelation to each other but all in all they are different fields \naltogether. In order to be good at one you need to devote time and effort \nto one of these fields. I am doing biology in college and when I did \nresearch on electrochemistry for a group project (long story I won't tell \nwhy I was doing it) I was absolutely wrecked and my mind  was blown apart! \nIt was very little to do with biology. I also researched the mechanism of \nhard drives and my mind was also blown apart.\n\nSo yeah, if Hank got few facts wrong then it is because he is covering \nreally broad topics in a short amount of time. Most scientists work in \ngroup with others from a different field and work together for years. Let's \nnot forget too that Hank has a degree in biochemistry and this video is to \ndo more with physics and maybe little bit of chemistry. I'm not saying we \nlet go of Hank's mistaken facts but I'm just putting up a signpost saying \nthe topic of his video is not his field of expertise.", 
                    "author": "impalabeeper"
                }, 
                {
                    "date": "2015-03-08T08:32:45.000Z", 
                    "text": "+OgreSamanosuke its not fallacy when the quality of the video is relative \nto what other people can make", 
                    "author": "Argonaut22j"
                }, 
                {
                    "date": "2015-02-14T19:55:35.000Z", 
                    "text": "You can protest his hyperbole and defend the video, but using \"you can't do \nbetter\" is a fallacy, no matter how you look at it.", 
                    "author": "OgreSamanosuke"
                }, 
                {
                    "date": "2015-02-13T16:20:40.803Z", 
                    "text": "+OgreSamanosuke Actually, the logic that I shut down that argument with was \ntotally and completely valid. The reason for that is his argument was more \nthan what yours was. It was more than just \"hey here's an error, maybe try \nto correct it\" That's a reasonable response.\n\nHis arugment was \"here's a million errors, let me just mention one though \nspecifically, then let me say that this whole video is worthless because \nhe's not doing his job right.\"\n\nOkay so do you see the dffference between those two arguments. That's why \nhis argument deserved to be shut down with the reminder that he can't do \nany better.  Unless he can, in which case I look forward to his video \nchannel on science.", 
                    "author": "Argonaut22j"
                }, 
                {
                    "date": "2015-02-13T08:23:00.302Z", 
                    "text": "+Argonaut22j I'm not debating the difficulty of making these videos, I'm \ndefending the capacity to make criticism. Especially in the case of it \nbeing very valid here. You tried to shut down the criticism with the \nterrible logic that if someone can't make a better video, their opinion \ndoesn't matter.\n\nSecondly, yes, most of the information in this video is either incorrect or \nmassively behind the times. That doesn't make some of it not useful or \ninteresting, even when not accurate, but it does still make it wrong.", 
                    "author": "OgreSamanosuke"
                }, 
                {
                    "date": "2015-02-12T04:40:43.000Z", 
                    "text": "He didn' tmiss jack by a wide margin. The only thing that's missing are the \npeople who care what you have to say.\n\nThis guy has hundreds of thousands of views and he does it by providing \nentertaining, informative videos. His \"job\" is more than just providing \nfacts its also being entertaining.\n\nAnd sure you can point out facts, but anyone can point to a building and go \n\"I could do that better.\" It takes a lot of work to make something and to \nactually make it better. So the only thing worthless are your trolling, \nwhiny, comments. ", 
                    "author": "Argonaut22j"
                }, 
                {
                    "date": "2015-02-12T04:13:25.087Z", 
                    "text": "+Argonaut22j  Ignoring the idiocy of your comment that seems more like the \nelementary school playground equivalent of \"I know you are but what am I,\" \nsimply put, it isn't my job to create YouTube videos on scientific topics. \nQuite literally, it *is* Hank's job; it's how he buys his food and pays his \nmortgage. The fact that this video has not one or two minor details wrong, \nbut instead is full of glaring mistakes shows a complete lack of research \non the part of him and his team. In short, it was sloppy, and if his goal \nis for \"...everyone to become smarter with him and his subbable \nsubscribers...\" then he has missed the mark by a wide margin. \n\nI can only hope that, instead of taking your childish approach to \ncriticism, the SciShow team keeps in mind that accuracy in what is \npresumably an educational video series is *its one fucking requirement* and \nwill ensure the veracity of the information they publish.  \n\nIn short, regardless of whether or not \"someone else can do better,\" which \nis *always* the case, if you're not going to do your job right, you're \nfucking worthless as a human being.", 
                    "author": "magicstix0r"
                }, 
                {
                    "date": "2015-02-11T16:22:15.596Z", 
                    "text": "+OgreSamanosuke When I watched the video it seemed like he said just that...", 
                    "author": "D\u00e9Ji Vu"
                }, 
                {
                    "date": "2015-02-11T19:29:12.000Z", 
                    "text": "+OgreSamanosuke he may have gotten a fact or two wrong sure, but so do \nnewspapers, and then people write in and pointit out and then they correct \nit, or they don't in some cases even. So what I'm saying is its pretty \ntough to constantly deliver informative and entertaining(which newspapers \naren't nearly as much as this is) and constantly be accurate about every \nfact. So I'll say it again, if you can do better, make your own channel. \nBut you won't because that requires a lot more than making a comment.", 
                    "author": "Argonaut22j"
                }, 
                {
                    "date": "2015-02-11T06:39:22.679Z", 
                    "text": "+Argonaut22j This continues to be the dumbest counter to criticism. It \ndoesn't matter if magicstix0r didn't or can't make a video, that doesn't \nmake this video ANY LESS WRONG.\n\nFor example, Hank said \"by adding more chips your computer can be 4x's \nfaster.\" This is outright incorrect. Parrallel processing has diminishing \nreturns. Going from a Dual core to a quad core CPU is not a gain of 2x's \nspeed, it's more like 1.82x; and going from a quad core to an octo core \nwould be a gain for 1.215x. Not to mention the OS and programs in question \nneed to even be capable of multithreading to utilize more than one core.", 
                    "author": "OgreSamanosuke"
                }
            ], 
            "num_replies": 23
        }, 
        "z12ccpcyfxerel2bm04cjzibtw3gwhcjs5c": {
            "top_comment": {
                "date": "2014-11-25T23:55:32.854Z", 
                "text": "7:05 ok. that blew my mind. So... 8.5 cm/ph.. so why doesnt it take an hour \nfor it turn on the lamp. just curious. don't know nothing about this \nstuff. \ufeff", 
                "author": "Phish N' Chimps"
            }, 
            "comments": [
                {
                    "date": "2015-01-17T15:22:08.149Z", 
                    "text": "+theabdu500\nI don't get what you mean. Energy doesn't \"move through the electrons\", the \nelectrons are actually moving.\n\nBecause they are moving, they have kinetic energy (1/2 * mass *  \nvelocity^2), and when they impact with the lamp's atoms - usually tungsten \n- they lose some of that energy to the tungsten atoms.\n\nThe tungsten atoms then vibrate due to the impact (remember that atoms are \nfixed in place, they can't move).\n\nThis vibration is the same thing as temperature, so the temperature of the \ntungsten increases, and due to thermal radiation, they emmit visible light.\n\nWhy tungsten? Because tungsten can withstand extremely high temperatures \nwithout melting.\n\nAnd by \"extremely high temperatures\", I mean \"half of the Sun's surface \ntemperature\".\n\nSo, yeah, energy doesn't \"move through\" electrons, it's the movement of \nelectrons that transfers that energy.\n\nAlso, if we were talking about DC, the electrons would be moving from the \nswitch to the lamp. Not just one electron, but all electrons would move, \nsomewhat resembling a train.\n\nTo make it a little bit easier, imagine that there is a guy, miles away \nfrom your home, somehow moving an electron a few centimeters. That electron \nis inside a 500km wire to connects to your house.\n\nBecause that electron is connected to all electrons in that super long \nwire, every single electron in the wire would also move. The electron the \nguy moved never reaches your home, yet, because all electrons in the wire \nmove like a train, the energy the guy used to move that single electron \neffectively gets to your home.\n\nOf course, in real life it's more complicated than that, but the principles \nare the same.", 
                    "author": "Kagehiko"
                }, 
                {
                    "date": "2015-01-17T11:53:00.692Z", 
                    "text": "because there are electrons already next to your lamp, so the energy would \nmove through the electrons and not one electron moving from the switch to \nthe lamp.", 
                    "author": "theabdu500"
                }, 
                {
                    "date": "2015-01-16T19:33:04.818Z", 
                    "text": "Atoms are made of protons, neutrons and electrons. The electrons are \nalready there, in the atoms that make your lamp.", 
                    "author": "Kagehiko"
                }, 
                {
                    "date": "2015-01-16T09:28:14.969Z", 
                    "text": "+Kagehiko so when you buy a lamp, it is pre-charged?  does it loose its \ncharge if not used for a long time? ", 
                    "author": "Phish N' Chimps"
                }, 
                {
                    "date": "2015-01-08T18:59:29.541Z", 
                    "text": "Because electrons work a litle bit like a train. If you move a wagon, you \nmove all the other wagons, because they are all connected.\nElectrons are already in your lamp, you don't need to wait for them to get \nthere, you just need other electrons (the ones coming from your wall plug) \nto push/pull the electrons in your lamp.\n\nAlso, it's cm/h, the \" / \" is read as \"per\" ;)", 
                    "author": "Kagehiko"
                }
            ], 
            "num_replies": 5
        }, 
        "z130fzsqot2pexykm230cjvbbyygwfnkf": {
            "top_comment": {
                "date": "2014-07-13T12:18:22.961Z", 
                "text": "You're either a 1 or a 0\nALIVE OR DEAD.\ufeff", 
                "author": "IIGrayfoxII"
            }, 
            "comments": [
                {
                    "date": "2014-07-15T21:16:18.878Z", 
                    "text": "You literally just explained the quantum computer.", 
                    "author": "Luis Najera"
                }, 
                {
                    "date": "2014-07-13T22:43:47.830Z", 
                    "text": "Say that to Schr\u00f6dinger's cat", 
                    "author": "Viktor Mellgren"
                }, 
                {
                    "date": "2014-07-13T18:45:31.549Z", 
                    "text": "What about 0.5 jk", 
                    "author": "Christopher Marshall"
                }
            ], 
            "num_replies": 3
        }, 
        "z12lezjoctadf3sv1221ghpqlvmhsnhuh": {
            "top_comment": {
                "date": "2015-02-13T04:30:27.166Z", 
                "text": "Just saying, the Core i7-5960X has 2.6 billion transistors... while that's \nnot 5 billion, we should be seeing that with the release of the Broadwell \narchitecture. \ufeff", 
                "author": "World Known"
            }, 
            "comments": [
                {
                    "date": "2015-04-26T21:58:53.763Z", 
                    "text": "+World Known The Kintex Ultrascale has 100 Billion transistors.", 
                    "author": "Peter Bayley"
                }, 
                {
                    "date": "2015-04-08T01:29:45.341Z", 
                    "text": "The number of transistors on a chip isn't currently what's limiting speed. \nThe current issue is the amount of transistors we can run at the same time \nin a given area. Modern processors have extra circuits built in to do \nspecific functions that we don't use as often due to the amount of \ntransistors we can put on them (dark silicon). Another issue is the \nprocessors ability to send signals across itself, and to other components \n(see the replies to Cherno Alpha's post below[or above if it has moved]). \n Although we are approaching a hard limit to the size we can make \nindividual transistors.", 
                    "author": "Douglas Fox"
                }, 
                {
                    "date": "2015-03-30T21:44:58.082Z", 
                    "text": "+Daniel Mast\u00eda At the same time, the Titan X has 8 billion transistors, as \ndoes the new rumoured Knight's Landing Xeon Phi cards from Intel. There \nisn't a huge demand for more than what we have. ", 
                    "author": "World Known"
                }, 
                {
                    "date": "2015-03-30T17:04:15.172Z", 
                    "text": "+Daniel Mast\u00eda i think that's pretty much correct, i mean what would your \naverage person want with a xeon or a haswell-E processor?", 
                    "author": "TheEpicMusic161"
                }, 
                {
                    "date": "2015-03-30T15:35:24.345Z", 
                    "text": "+World Known Yep, that's right, and there are chips with even more than 5 \nbillion transistors today. I think the \"problem\" is that it's come up to a \npoint were consumer chips just don't need to follow Moore's Law, CPUs are \nplenty powerful for most people, so there isn't such a demand for faster \nones. Or maybe I'm completely wrong, who knows.", 
                    "author": "Daniel Mast\u00eda"
                }, 
                {
                    "date": "2015-03-19T13:43:05.469Z", 
                    "text": "+willgtl there are actually mobile chips that are 14 nm that released very \nrecently they're in the latest macbook (the super thin one with only one \nport) and the ASUS UX305 and i think a few others", 
                    "author": "TheEpicMusic161"
                }, 
                {
                    "date": "2015-03-05T01:46:32.000Z", 
                    "text": "Here's a more correct way of saying what he was trying to say. Transistor \ntech hasn't surpassed 14nm yet and it should've already (Most mainstream \nprocessors are actually 22-20nm). You can cram as many transistors on a \nchip that you want, but the more you have, the bigger the die will need to \nbe. Take the Ivy Bridge HE-4, it has 8.75m transistors/mm2 on a 160mm die \n(1.4b transistor count). The Haswell-E5 HCC processor is only 8.6m \ntransistors/mm2 on a massive 662mm2 die (5.69b transistor count). It's \nspeculated we'll get down to 5nm process in 2020 (Simply the so-called \n\"road map\" of CMOS technology) but going by the past trend, we should be \npast that by 2020. Even getting to 10nm process isn't easy. We still don't \nhave the lithography techniques for fabricating such tiny transistors. \nUnfortunately we don't even know if conventional CMOS technology can go \nthat small. And as said in this video, 10nm is getting to the point where \nwe have to consider quantum mechanics.\n\nIt's just a big ass chip. Anyone can make a bigger chip, but the bigger the \nchip, the greater the chance of manufacturing defects and the greater the \nheat dissipation. The hotter the chip, the greater the gate delay. So \nbigger chip does not mean faster chip. It means hotter chip that's harder \nto keep cool and hence actually slower (Relatively). On top of that, \nbecause it's so large and harder to cool, it'll have a shorter life.\n\nSun announced their new SPARC M7 processor will have 14b transistors. It'll \nbe on the 20nm process, but that's still gonna mean a big die. However, \nlast year Intel also announced the new Core M processors that will actually \nuse the 14nm process. Better processors are still coming, but in only a \ncouple years we're gonna hit a roadblock where we can't go smaller without \nmoving onto a new semiconductor. My hope is we'll have quantum computers by \n2025 (More than just D-Wave's quantum annealing processors).", 
                    "author": "willgtl"
                }, 
                {
                    "date": "2015-03-03T13:02:00.453Z", 
                    "text": "The  Haswell E3-12xx v3 and E5-16xx/26xx v3 Xeons have 5.56 billion \ntransistors. Some of those models were released one year before this video \nwas created.\nMost of the information in this video is either hopelessly outdated or \nsimply wrong.", 
                    "author": "Istvan Kovasznai"
                }
            ], 
            "num_replies": 8
        }, 
        "z12gwxeabku0iblk222awthoxn3jtbbvf": {
            "top_comment": {
                "date": "2014-07-13T12:01:53.949Z", 
                "text": "Well like 99% of your phone is the battery so we need to fix the battery \nbefore we do anything else...\ufeff", 
                "author": "caleb trollston"
            }, 
            "comments": [
                {
                    "date": "2014-07-15T06:24:58.512Z", 
                    "text": "+Nicole Dizon How convenient (y)", 
                    "author": "OreoMuncher"
                }, 
                {
                    "date": "2014-07-15T04:52:21.738Z", 
                    "text": "They just made a video on graphene.", 
                    "author": "Nicole Dizon"
                }, 
                {
                    "date": "2014-07-14T05:58:28.000Z", 
                    "text": "+GKMcWhite . oddly enough, there aren't many youtube videos on graphene. So \nyeah, would appreciate it if they were to dedicate an episode to talk about \nit.", 
                    "author": "OreoMuncher"
                }, 
                {
                    "date": "2014-07-14T01:17:48.542Z", 
                    "text": "+OreoMuncher We all agree that scishow just fucking finally has to do the \nepisode on graphene right?", 
                    "author": "GKMcWhite"
                }, 
                {
                    "date": "2014-07-13T23:03:46.690Z", 
                    "text": "+Boby Gandhi There's a prototype demo (which I'd give you the video link to \nif it weren't a pain to do so on my tablet) of a smartphone with a \nsupercap \"battery\". It looks ugly and huge for now, because prototype, but \nit charged the phone in what equates to 0 to full in under one minute. It's \ndamn impressive. Just, as OreoMuncher said, it's not yet cheap enough to be \ncommercial.", 
                    "author": "IceMetalPunk"
                }, 
                {
                    "date": "2014-07-13T20:03:45.006Z", 
                    "text": "+Boby Gandhi Money, the only reason. It's not economically viable to \nimplement this stuff on a mass scale.Yet.", 
                    "author": "OreoMuncher"
                }, 
                {
                    "date": "2014-07-13T16:23:30.875Z", 
                    "text": "+OreoMuncher why is this stuff not in my phone yet?", 
                    "author": "Boby Gandhi"
                }, 
                {
                    "date": "2014-07-13T13:48:05.667Z", 
                    "text": "+caleb trollston You haven't heard of Graphene super capacitors? \nhttp://www.technologyreview.com/view/521651/graphene-supercapacitors-ready-for-electric-vehicle-energy-storage-say-korean-engineers/ \nThere ya go. ", 
                    "author": "OreoMuncher"
                }, 
                {
                    "date": "2014-07-13T13:45:16.801Z", 
                    "text": "+OreoMuncher what about graphene?", 
                    "author": "caleb trollston"
                }, 
                {
                    "date": "2014-07-13T13:44:14.771Z", 
                    "text": "*Draws Rainbow in mid air* \"Graphene\"", 
                    "author": "OreoMuncher"
                }
            ], 
            "num_replies": 10
        }, 
        "z13fsvvg2vfwypeu123ztrazinv0eted2": {
            "top_comment": {
                "date": "2014-07-13T21:40:14.305Z", 
                "text": "HP has (as a prototype) a computer that can calculate 160 petabytes in one \none-billionth of a second! need proof? look up the video HP has on youtube \nabout it. it's called \"The Machine\"\ufeff", 
                "author": "CaptainCat 15"
            }, 
            "comments": [
                {
                    "date": "2014-08-19T22:35:46.952Z", 
                    "text": "+CaptainCat 15 Its a 1024 terabytes (commenting in old videos ifun !! :P)", 
                    "author": "Taprus the 3rd"
                }, 
                {
                    "date": "2014-07-14T01:39:34.925Z", 
                    "text": "+Suiseiseki Desu anything, in this case because \"The Machine\" is everything \nin one. it's a processor, it's the ram, and it's the hard drive", 
                    "author": "CaptainCat 15"
                }, 
                {
                    "date": "2014-07-13T23:56:18.471Z", 
                    "text": "Performing which operations on data are classified as 'handling' it? ", 
                    "author": "Suiseiseki Desu"
                }, 
                {
                    "date": "2014-07-13T23:20:38.041Z", 
                    "text": "And a petabyte is 1,000 terabytes I believe. Someone correct me if that \nnumber is wrong ", 
                    "author": "CaptainCat 15"
                }, 
                {
                    "date": "2014-07-13T23:19:46.319Z", 
                    "text": "It jus means that the computer can handle a crap-ton of information in one \none-billionth of a second ", 
                    "author": "CaptainCat 15"
                }, 
                {
                    "date": "2014-07-13T22:08:13.241Z", 
                    "text": "What exactly do you mean by 'calculate 160 petabytes'? This phrase just \ndoesn't have much meaning to me.", 
                    "author": "Suiseiseki Desu"
                }
            ], 
            "num_replies": 6
        }, 
        "z134wvgqrqzautroq04cfx2aovv0efvqatc0k": {
            "top_comment": {
                "date": "2014-07-13T14:58:14.153Z", 
                "text": "How about a trinary computer - left, off, right?\ufeff", 
                "author": "iamihop"
            }, 
            "comments": [
                {
                    "date": "2014-07-15T20:23:41.582Z", 
                    "text": "+Ryan Mann Hmm, that makes sense, although I'm still a little unsure why \nthat means multiple transistors might be needed to equate to one digital \nbit. Is it just that a single bit wouldn't transfer sufficient voltage by \nitself? If that's the case, how do computers handle that problem? Is it \nconsistent?\n\nIn theory, though, would it be possible to  break the signal down by <-2.5 \n= -1, -2.5 to 2.5 = 0, >2.5 = 1.", 
                    "author": "iamihop"
                }, 
                {
                    "date": "2014-07-15T17:12:52.192Z", 
                    "text": "I think this will help: Unlike what Hank said, one transistor on its own is \nnot usually enough to store one bit of data - you might actually need 4 \ntransistors to store a single bit (0 or 1) of information in a computer \nprocessor's temporary memory.\nA binary, digital system is an \"abstraction\" of the non-binary, analog \nreality: Transistors can be made to be \"really on\" or \"really off\", but \nalso everywhere in between. Computers are purposely designed so that the \ntransistors operate in the two extreme states so that data and computation \nerrors are less common and easier to correct. Assume your computer's power \nsupply provides 5 volts to your processor chip. Thus, any bit of \ninformation whose voltage is from 2.5 to 5V would be automatically \ncorrected to 5V (a digital \"1\"), and anything below 2.5V would be corrected \nto 0V or \"ground\" (a digital \"0\").\nI hope this helps.", 
                    "author": "Ryan Mann"
                }, 
                {
                    "date": "2014-07-15T14:40:37.000Z", 
                    "text": "+anagennao  Perhaps I should have said \"alternate-able.\" I didn't mean that \nthe current would constantly be alternating the way it does in AC.\nSo, having actually worked on/thought about such a system (which I \nobviously have not), do you think it could be feasible?", 
                    "author": "iamihop"
                }, 
                {
                    "date": "2014-07-15T03:01:44.169Z", 
                    "text": "+iamihop I like your thinking... I started work on developing a trinary \nsystem (+, neutral, -) about two decades ago when I was in an electronics \nprogram.  As far as using alternating current, I don't think it would work \nwith the way the standard transistor functions.  I may not be recalling \nthis entirely correctly because it's been awhile since I've last worked \nwith this information, but a transistor is either positively doped (NPN) or \nnegatively doped (PNP).  They need either a voltage or ground input signal \nto allow current flow.  An alternating input would just be switching the \ntransistor on and off at the hertz of the AC input.", 
                    "author": "anagennao"
                }, 
                {
                    "date": "2014-07-15T02:32:19.000Z", 
                    "text": "+Vulcapyro nazrin-cchi y u everywhere in utube", 
                    "author": "BattousaiHBr"
                }, 
                {
                    "date": "2014-07-14T22:15:06.479Z", 
                    "text": "+Vulcapyro There is an intrinsic benefit: each component can store more \ninformation. I don't see how that is informationally equivalent. One trit \nstores information that would take two bits to store.\n\nThat was my premise for comparing the efficiency: that a trinary transistor \nwould take up the same space as a binary transistor. If the required \nmechanism is the same: the flow of electrons across a gap, it seems like a \nreasonable premise to me. If the transistors were the same size, the \ntrinary CPU would require less space to hold or process the same amount of \ninformation.\n\nSure, \"a more efficient transistor is more efficient\" is circular, but I'm \npresenting a possible way to make that more efficient transistor, and \nnobody has demonstrated to me that it's implausible to use alternating \ncurrent.\n\nI'm not devoted to this idea - it just struck me as a possibility. So far, \nthough, the only criticism it's gotten is that it doesn't fit with the way \ncomputers are currently set up, which is the whole point. We're going to \nmax out binary, silicon-based CPUs, and then binary CPUs in general. We'll \nhave to fundamentally change things, anyway. Trinary may be an intermediate \nbefore quantum computing, which seems to be having serious problems.", 
                    "author": "iamihop"
                }, 
                {
                    "date": "2014-07-14T21:58:07.388Z", 
                    "text": "+iamihop\nNo no, you didn't get what I said. A trinary computer and a binary computer \nare informationally equivalent; there is no intrinsic benefit to having \nthree states over two. The benefit you're suggesting is that a transistor \ncapable of representing three states would be able to carry more \ninformation per transistor than a binary one and therefore be more \nefficient or compact in information, but that's only true if such a \ntransistor is more efficient or compact in the first place. You cannot just \nassume they would take up the same amount of physical space or whatever. \nIt's circular.", 
                    "author": "Vulcapyro"
                }, 
                {
                    "date": "2014-07-14T17:58:00.415Z", 
                    "text": "+Vulcapyro  I'm not sure how you would represent four states with \nelectricity. Three can be done by alternating the current. It would be \ncomputationally equivalent to binary *now*, but the whole point is that you \nwould design a computer around a trinary cpu.\n\n+yumri4 That's interesting, but it's just three binary values stored in one \ncell. I'm thinking one truly trinary value per transistor.\nWhere is the bottleneck at the moment?", 
                    "author": "iamihop"
                }, 
                {
                    "date": "2014-07-14T10:12:25.000Z", 
                    "text": "+iamihop TLC flash already is here btw it just isnt used in CPUs due to it \nshort life span and static SRAM in small amounts like 64KB + 64KB blocks \nfor Level 1 cache on a CPU is used as its speed is fast ussualy slower than \nthe core clock though a decade ago it wasnt so and would be one way to \nspeed up the modern day CPUs by just upgrading how fast the on die cache is \ngoing. very small jump in speed yes but still a jump in speed. Then with \nDDR4 it will not have as many problems with local system speed being slower \nthan CPU speed which is a BIG ISSUE right now with most CPUs.\nIf we focus to much of the CPU and not on the RAM nor the hard drive then \nwe will just have many bottlenecks with a super fast CPU but nothing to do \nfor hundreds of cycles if not throsands of cycles.", 
                    "author": "yumri4"
                }, 
                {
                    "date": "2014-07-14T10:01:42.339Z", 
                    "text": "+iamihop Such a transistor would only \"pack more information into a smaller \nspace\" if it actually *did* that. Simply having three states is \ncomputationally equivalent to binary. It makes no difference unless the \ntechnology just happens to be better than any technology using a binary \nsystem anyways. You might as well ask \"but what if it could hold four \nstates?!\"", 
                    "author": "Vulcapyro"
                }, 
                {
                    "date": "2014-07-14T07:50:37.486Z", 
                    "text": "....really", 
                    "author": "The One"
                }, 
                {
                    "date": "2014-07-14T06:12:31.045Z", 
                    "text": "+James Heyne  While that was an off-the-cuff joke at first, the more I \nthink about it, the more plausible it seems. Yes, things don't work that \nway *now*. Using binary transistors is much simpler, but a trinary \ntransistor - a transistor that could store (1, 0, or -1) - could pack more \ninformation into a smaller space.\n\nI just did a google search on this, and indeed some people have suggested \nthe idea (they apparently call them \"trits\"). Binary has dominated, but its \nreturns are diminishing. Eventually, it may be worth the investment in a \nnew architecture of \"trits.\"", 
                    "author": "iamihop"
                }, 
                {
                    "date": "2014-07-14T05:13:07.689Z", 
                    "text": "That's not how it works, that's now how any of this works", 
                    "author": "James Heyne"
                }
            ], 
            "num_replies": 13
        }, 
        "z12itl3xrkz5dji0g22od3iyzpjxubaog04": {
            "top_comment": {
                "date": "2014-07-13T18:11:55.000Z", 
                "text": "Graphene where art thou. Personally i'm waiting for graphene, cause they're \nactively researching the matter and it's feasible unlike lasers or quantum \ncomputing. They're too advanced. graphene is here and now.\ufeff", 
                "author": "tulp35000"
            }, 
            "comments": [
                {
                    "date": "2014-07-15T23:40:00.909Z", 
                    "text": "Don't worry. Because the science gets done, and you make a neat gun - for \nthe people who are still alive, of course.", 
                    "author": "Cow Norris"
                }, 
                {
                    "date": "2014-07-15T14:42:02.121Z", 
                    "text": "+Joseph Griffin yeh it was lol!", 
                    "author": "Gayle bertrude"
                }, 
                {
                    "date": "2014-07-15T14:31:14.029Z", 
                    "text": "+Toasted Lego probably Veritasium! I remember him making a couple of videos \nin regards to quantum computing", 
                    "author": "Joseph Griffin"
                }, 
                {
                    "date": "2014-07-15T14:26:20.967Z", 
                    "text": "+IceMetalPunk I cant give a link to the vid where i saw it, but i watched a \nvideo where this guy was explaining quantum computing. He said that it \nwould not replace ordinary computers. Although it could be better than the \nones we have now at doing some of the things you mentioned. Like \nprobability theory etc. But it would not be better than the computers we \nhave now for the everyday use. especially considering the cost.", 
                    "author": "Gayle bertrude"
                }, 
                {
                    "date": "2014-07-14T14:19:31.035Z", 
                    "text": "+IceMetalPunk  Yeah they're slower than a pocket calculator and cost 10 \nmillion usd for the cheapest one.", 
                    "author": "tulp35000"
                }, 
                {
                    "date": "2014-07-14T13:58:21.724Z", 
                    "text": "Waiting for it?  Research it!  Develop it! Experiment with it!", 
                    "author": "Shawn Stephenson"
                }, 
                {
                    "date": "2014-07-13T23:43:46.591Z", 
                    "text": "Plus, I'm pretty sure graphene holds the charge a lot longer so using it \nfor batteries would increase the capacity of batteries exponentially.", 
                    "author": "Matt Helton"
                }, 
                {
                    "date": "2014-07-14T22:52:56.000Z", 
                    "text": "Quantum computers are here and now. They already exist and are being used. \nthey're just not the miracle system the media has touted them as. But they \ndo work well for certain types of problems (combinatorics and probability \ntheory problems, specifically).", 
                    "author": "IceMetalPunk"
                }
            ], 
            "num_replies": 8
        }, 
        "z12lfp0z2szvcxydr23gf30g2nbqzh1qe04": {
            "top_comment": {
                "date": "2014-07-13T10:54:24.308Z", 
                "text": "Hmmm quantum computers. That would be cool. The whole bandwidth and \nclockspeed issues will be obsolete :)\ufeff", 
                "author": "EdEditz"
            }, 
            "comments": [
                {
                    "date": "2014-07-14T00:56:48.658Z", 
                    "text": "quantum computers are better used for simulations, Everyday use is better \noff with a computer", 
                    "author": "SirLotzz"
                }, 
                {
                    "date": "2014-07-13T14:40:45.737Z", 
                    "text": "+TheDesius They aren't just as slow. They'd probably actually be slower. It \ntakes more time to read results and to write input to and from a quantum \ncomputers than in conventional ones so they aren't actually a good idea.", 
                    "author": "Keandre Espina"
                }, 
                {
                    "date": "2014-07-13T14:07:04.608Z", 
                    "text": "The big thing about quantum computing, as far as I know, is that it can \ntest all the solutions at once. Think that you compute a function and the \ninput is a 64 bit integer. Because each bit is both on and off at the same \ntime, it is assumed that the quantum processor would compute the function \nfor all possible 64 bit inputs at the same time and you would have all the \nanswers after that. I do not know how would you query specific results \nafter that, but if they can do that, this would be an amazing tool for \noptimization problems, where you have to minimize a function or find out \nwhich parameters work best for an engineering problem. This would be an \namazing achievement for us.", 
                    "author": "OoJxShadow"
                }, 
                {
                    "date": "2014-07-13T13:32:38.000Z", 
                    "text": "Quantum computing actually won't ever likely be a replacement to classical \ncomputers, at least not any time soon. They don't necessarily process \nthings any faster. They're only better for specific algorithms, like Shor's \nalgorithm. ", 
                    "author": "Amelia Hartman"
                }, 
                {
                    "date": "2014-07-13T13:09:56.435Z", 
                    "text": "+Emanuele Zanetti Ah okay, thanks. I thought they would be much faster but \nI see I was wrong :)", 
                    "author": "EdEditz"
                }, 
                {
                    "date": "2014-07-13T13:08:53.558Z", 
                    "text": "+TheDesius Oh right. I didn't know that. I thought it would be the answer \nto all speed problems. Alas. Thanks for the info though :)", 
                    "author": "EdEditz"
                }, 
                {
                    "date": "2014-07-13T13:01:17.581Z", 
                    "text": "+EdEditz actually if a program isn't optimized for quantum computation it \nwill run slower on a quantum PC than on a \"normal\" PC. *if* someone \ndeveloped software specifically thought for execution on a quantum computer \nthen it *might* have some benefits (though it would imply more time to be \ndeveloped and new hardware, so that brings downsides too), but as far as I \nknow quantum computing is useful just for resolving *really* hard problems \nthat normal PCs handle poorly, due to the fact that they only use two \nstates, faster. ", 
                    "author": "Emanuele Zanetti (zanna)"
                }, 
                {
                    "date": "2014-07-13T12:00:19.768Z", 
                    "text": "nope\nquantum computers are good at solving problems but just as slow as normal \ncomputers when youbrun programs or games on them.", 
                    "author": "TheDesius"
                }
            ], 
            "num_replies": 8
        }, 
        "z13fyhzodpfpdxeta225wrz5tpmcs1z4504": {
            "top_comment": {
                "date": "2014-07-13T14:30:02.420Z", 
                "text": "That binary number is actually 194 Hank, not 67.\n\n1   2   4   8   16  32  64 128\n0   1   0   0    0   0    1   1   =  (1x2) + (1x64) + (1x128) = 194\ufeff", 
                "author": "Foxster50"
            }, 
            "comments": [
                {
                    "date": "2014-07-15T04:38:47.514Z", 
                    "text": "he's actually correct. It's 67. The digit to the left has the least value \nas it is with the decimal system.", 
                    "author": "Robert Loren Ursua"
                }, 
                {
                    "date": "2014-07-13T16:46:57.967Z", 
                    "text": "128 64 32 16 8 4 2 1\n  0    1   0   0  0 0 1 1 = 64 + 2 + 1 = 67\n\nschooled enough? ", 
                    "author": "Sir. Caloy"
                }, 
                {
                    "date": "2014-07-13T15:06:23.683Z", 
                    "text": "Binary goes the other direction (just like all base systems). 10 in binary \nis 2.\nFor example, in base ten, 1000 is much larger than 0001. Same dealio.", 
                    "author": "iamihop"
                }
            ], 
            "num_replies": 3
        }, 
        "z13lxzgrgqvlttyfh224cnvpgmv1chggn04": {
            "top_comment": {
                "date": "2014-07-13T19:21:16.517Z", 
                "text": "You made a small mistake at 5:10:\n\"The Transistor can only manage one BIT of data at a time\"\ufeff", 
                "author": "Robotic Brain"
            }, 
            "comments": [
                {
                    "date": "2014-07-13T23:32:32.656Z", 
                    "text": "+IceMetalPunk I didn't say HANK made a mistake, I said THEY made one ;)", 
                    "author": "Robotic Brain"
                }, 
                {
                    "date": "2014-07-13T23:16:33.856Z", 
                    "text": "He said it right (the 8-bit chip would handle one byte), but the graphics \nguy wrote the wrong thing.", 
                    "author": "IceMetalPunk"
                }
            ], 
            "num_replies": 2
        }, 
        "z122tlg5vz3vhx2mv23vgv0royfvuf3ku": {
            "top_comment": {
                "date": "2014-07-13T18:04:44.174Z", 
                "text": "Why aren't computers already fast enough?\ufeff", 
                "author": "Majoofi"
            }, 
            "comments": [
                {
                    "date": "2014-07-14T12:03:27.017Z", 
                    "text": "+Rafaelinux or run Crysis", 
                    "author": "Harvy666"
                }, 
                {
                    "date": "2014-07-14T10:08:39.038Z", 
                    "text": "Because as we wish to understand more about the world around us our \ncalculations need to become far more precise and complex. In order to \nprocess them quickly enough, we need faster computers.", 
                    "author": "bigglessy"
                }, 
                {
                    "date": "2014-07-14T05:46:44.857Z", 
                    "text": "Try to track any feature in a 4k video clip with today's softwares.\nOr render any of your mate's CAD buildings with proper lighting and shadows?\nDid it take a couple of hours?\nThere, that's why you need faster processing.", 
                    "author": "Rafaelinux"
                }, 
                {
                    "date": "2014-07-13T23:41:49.614Z", 
                    "text": "Why a 2001 computer is slow for today's standards?", 
                    "author": "Grman Rodriguez"
                }
            ], 
            "num_replies": 4
        }, 
        "z12udlmifkbjwl35n04ccxxptzq4zhj5vk00k": {
            "top_comment": {
                "date": "2014-07-13T15:07:23.690Z", 
                "text": "I AGREE WITH HANK ... a photon computer would be awesome!! can you imagine \nthe light shows that computer would do?? it would be VERY pretty :)\ufeff", 
                "author": "Lord Zephyros"
            }, 
            "comments": [
                {
                    "date": "2014-07-13T16:19:18.931Z", 
                    "text": "+Lord Zephyros  If they have any design sense, they would make it glow with \nall different colors, right? :)", 
                    "author": "iamihop"
                }, 
                {
                    "date": "2014-07-13T15:44:23.622Z", 
                    "text": "I know ... but can I dream? lol", 
                    "author": "Lord Zephyros"
                }, 
                {
                    "date": "2014-07-13T15:12:41.730Z", 
                    "text": "You wouldn't see the light unless something isn't working properly. First, \nthey'll use very small, targeted streams of light, and second they'll be \nfired over extremely tiny distances.", 
                    "author": "iamihop"
                }
            ], 
            "num_replies": 3
        }, 
        "z12qyniwtsr3j3ooy04cc3qahw2esroglv00k": {
            "top_comment": {
                "date": "2015-01-02T08:59:23.018Z", 
                "text": "I have 2 cpus :) costed a lot and not worth it\ufeff", 
                "author": "ZeroToHero"
            }, 
            "comments": [
                {
                    "date": "2015-03-31T03:15:48.313Z", 
                    "text": "+John Egbert not that cool or even much...", 
                    "author": "the official \u201csandidge02\u201d .sandidge02"
                }, 
                {
                    "date": "2015-01-26T23:06:38.539Z", 
                    "text": "You have a server motherboard? cool", 
                    "author": "John Egbert"
                }, 
                {
                    "date": "2015-01-26T23:00:40.214Z", 
                    "text": "2 cpus -_-", 
                    "author": "ZeroToHero"
                }, 
                {
                    "date": "2015-01-26T22:53:27.079Z", 
                    "text": "You have 2 cpus or 2 cores?", 
                    "author": "John Egbert"
                }
            ], 
            "num_replies": 4
        }, 
        "z13pwlurbrfazbrce22nffgqsviigfbh504": {
            "top_comment": {
                "date": "2014-08-08T07:26:06.427Z", 
                "text": "+scishow Well, a popular saying goes: there are no stupid questions. So \nhere's my shot. If electrons move that slow, how do I get my lamp to light \nup at the instant I push the switch? Is a cable like a hose thats under \nconstant 'pressure' and the switch just opens the tab, or am I going in the \nwrong direction and made myself just look like an idiot for the whole \ninternet to see?\ufeff", 
                "author": "CSH3"
            }, 
            "comments": [
                {
                    "date": "2014-11-15T00:01:06.264Z", 
                    "text": "Electricity is measured in Amps and Volts, measured by an ammeter and a \nvoltmeter. Amps is increased by electrons being pushed through the wire, as \nif it was a garden hose. The wider the \"hose\" is the less resistance there \nis, meaning that the electrons can be pushed through faster. Volts are the \namount of electrons being pushed through the hose, similar to the hoses \nwater pressure.", 
                    "author": "Reuben Young"
                }, 
                {
                    "date": "2014-10-04T22:37:49.240Z", 
                    "text": "Because the \"signal\" isn't an individual electron moving, it's more like an \nelectron \"shoving\" another (some guy made an ocean wave analogy about it)", 
                    "author": "Nicholas Cardenas"
                }
            ], 
            "num_replies": 2
        }, 
        "z132hrwr1wv0trada233zxujbonrjdhjx04": {
            "top_comment": {
                "date": "2014-07-13T12:45:42.701Z", 
                "text": "quantum computing most likely the next thing, base 4 instead of base 2 \nmath, sooo much faster\ufeff", 
                "author": "Magnus H\u00e5land"
            }, 
            "comments": [
                {
                    "date": "2014-07-18T06:40:47.636Z", 
                    "text": "Quantum computers are only faster at some types of things. Exponential \nproblems that require greater than polynomial computation or easy \nparallelized things are good for Quantum computers. Multiplying two numbers \nwould be far far slower on a normal quantum computer. The other problem is \nthat we can't directly read the results from quantum computation, which \nmeans the results have to be reconverted to a readable form. Therefore, \nsomething like multiplying numbers would be far smarter to do on a binary \ncomputer. Quantum computers are the future for many industrial \napplications, but not for the everyday consumer.", 
                    "author": "Bored and Hairless"
                }, 
                {
                    "date": "2014-07-15T23:48:55.048Z", 
                    "text": "Please don't comment if you have no idea what you're on about.", 
                    "author": "Cow Norris"
                }, 
                {
                    "date": "2014-07-15T21:45:54.582Z", 
                    "text": "+Vulcapyro\nbase 4 would actually be slower because the simplest data transmitter would \nbe a lot more complex and you could not fit as many on a chip.", 
                    "author": "linas3001"
                }, 
                {
                    "date": "2014-07-15T04:29:11.828Z", 
                    "text": "+Vulcapyro\nAgain, not entirely. Think about how base 16 (hexadecimal) can store as \nmany possible combinations in 2 characters as binary stores in 8. So it \nwould allow you to store more data in a smaller area. Wouldn't make \nanything faster or more efficient, but it would make things more storage \ndense.", 
                    "author": "IceMetalPunk"
                }, 
                {
                    "date": "2014-07-15T04:18:17.669Z", 
                    "text": "+Magnus H\u00e5land That isn't the case. You do not get \"tons of more data per \nbit\". A bit is a bit, no matter how it's represented. Even if quantum \ncomputers *were* to use base 4 arithmetic it would not be any different \nfrom base 2 and would be totally useless of a prospect. But it doesn't, \nthankfully!", 
                    "author": "Vulcapyro"
                }, 
                {
                    "date": "2014-07-15T04:08:45.764Z", 
                    "text": "+Magnus H\u00e5land\nNo...just, no. That's not how quantum computing works. When people say \n\"it's in both states\", that is not a third state. The states are 0 and 1, \nnot 0, 1, 00, 11, 01, and 10. There's just a PROBABILITY distribution of \nany one particle being in a spin up (1) or spin down (0) state. That's a \ntotally different thing from base 4 arithmetic.", 
                    "author": "IceMetalPunk"
                }, 
                {
                    "date": "2014-07-15T04:05:40.150Z", 
                    "text": "I say base 4 because if the technology is perfected each quit pair can be \nin 4 superposition, hence 4 different values (0-3) which in turn makes it \nbase 4 math. As far as the advantages go, if it works properly you'll have \ntons more data per bit, the challenge is of course to read these bits as \nfast as a conventional transistor works", 
                    "author": "Magnus H\u00e5land"
                }, 
                {
                    "date": "2014-07-15T03:50:36.898Z", 
                    "text": "+Magnus H\u00e5land\nYou don't even seem to know what quantum computing *is*, given you keep \nsaying \"base 4\".\n\nAnd name one theoretical advantage to using base 4 arithmetic over base 2 \nfor computing.", 
                    "author": "Vulcapyro"
                }, 
                {
                    "date": "2014-07-15T03:11:08.783Z", 
                    "text": "There are very many theoretical advantages to base 4 over base 2, and yes, \nright now quantum computing isn't that good to anything other then specific \ntasks, but give it time...", 
                    "author": "Magnus H\u00e5land"
                }, 
                {
                    "date": "2014-07-14T22:07:49.000Z", 
                    "text": "+EnderOnIce\nLike I told someone else in another thread, that only makes sense if the \nfour-state \"transistor\" is already equally efficient and compact as \ntransistors on modern computers. We can't just assume that 4>2 therefore it \nwould be better.\n\nThere's no theoretical advantage to base 4 arithmetic over base 2, either, \nit would have to be purely practical.", 
                    "author": "Vulcapyro"
                }, 
                {
                    "date": "2014-07-14T20:15:19.686Z", 
                    "text": "Not to mention quantum computing doesn't make most computing any faster, \nonly very specific algorithmic multi-tasking would see a difference. \nGeneral processes would be actually slower if done with quantum computing.", 
                    "author": "Fleegsta"
                }, 
                {
                    "date": "2014-07-14T20:12:09.993Z", 
                    "text": "+Vulcapyro Would it be possible to build a different type of transistor \n(one that would have more than 2 positions) and thereby compress \ninformation? Wouldn't working in base 4 with a transistor that had 4 \npositions mean you could say the same message in fewer bits? Please excuse \nmy ignorance\u2014this isn't my field.", 
                    "author": "EnderOnIce"
                }, 
                {
                    "date": "2014-07-14T20:10:03.766Z", 
                    "text": "Would it be possible to make a different type of transistor that had \ndegrees of on and off instead of just 1 and 0? Could you use base 4 that \nway and, by so doing, be able to compress the record of information by a \nbit (no pun intended)?", 
                    "author": "EnderOnIce"
                }, 
                {
                    "date": "2014-07-14T09:56:11.990Z", 
                    "text": "Quantum computing does not work in base 4. What. And doing so would make *literally \nno difference*.", 
                    "author": "Vulcapyro"
                }, 
                {
                    "date": "2014-07-14T04:20:02.168Z", 
                    "text": "They are the ultimate foreseeable end, but they are most likely not the \nnext computational type to come. The next is most likely photocomputing \nfollowed by DNA and molecular", 
                    "author": "NoxSicarius1"
                }
            ], 
            "num_replies": 15
        }, 
        "z12dy50zwzvlyloav04cfd04iw22gtrqtfg": {
            "top_comment": {
                "date": "2014-07-13T14:50:46.995Z", 
                "text": "Hmmm long time since I did maths with binary but I am sure (like decimals) \na 0 at the start is redundant, so 01000011 == 1000011\ufeff", 
                "author": "John Smith"
            }, 
            "comments": [
                {
                    "date": "2014-07-13T15:16:24.523Z", 
                    "text": "+John Smith   Haha, really? Are you in the US? Oh, Google. Well, my poiint \nstill stands (that second \"l\" in \"still,\" for example). It's just \nconvention.", 
                    "author": "iamihop"
                }, 
                {
                    "date": "2014-07-13T15:12:13.458Z", 
                    "text": "Actually that was Chrome's auto correct telling me math was not spelt right \n(still is...).", 
                    "author": "John Smith"
                }, 
                {
                    "date": "2014-07-13T15:00:28.507Z", 
                    "text": "Yes, but so is the \"s\" at the end of \"maths.\" It's convention, especially \nwhen one is explaining bytes.", 
                    "author": "iamihop"
                }
            ], 
            "num_replies": 3
        }, 
        "z12pixrwrvy1v3gwl04cd1rgatqdynaifa4": {
            "top_comment": {
                "date": "2014-07-13T13:26:18.626Z", 
                "text": "Why can't the chips simply be made larger?\n\nThere probably is a reason but I don't know it.\ufeff", 
                "author": "Tomislav R"
            }, 
            "comments": [
                {
                    "date": "2014-07-14T01:26:32.261Z", 
                    "text": "Heat, cost and time for the signal to get from one end of the chip to the \nother.", 
                    "author": "Michael Kenner"
                }, 
                {
                    "date": "2014-07-14T00:53:15.684Z", 
                    "text": "The size of the chips inhibits the clock speeds. Larger scales means larger \ndistances for information to travel, thus the cons are bigger than the \npros. More transistors with size vs. faster computation type of thing.", 
                    "author": "chaos101011"
                }
            ], 
            "num_replies": 2
        }, 
        "z13zsvrbnz21j1ik522ytdxx5yjodd5p404": {
            "top_comment": {
                "date": "2014-08-17T18:00:32.389Z", 
                "text": "I call BS on harder to make software for parallel computing. I think the \ncurrent software was design for a single chip.\ufeff", 
                "author": "Cesar Avelar"
            }, 
            "comments": [
                {
                    "date": "2014-11-02T22:15:37.000Z", 
                    "text": "From what I read, it is really hard to make for example a h.264 encoder \nthat is massively multi-tasking while keeping the same video quality as in \na single threaded encoder.\nAs far as I understand it, that is because h.264 video in itself is very \nlinear and all frames are depending on key-frames before or after them. You \ncannot easily break up the encoding into a lot of threads without \nsacrificing benefits of that forward-backward dependency.\nAnd I guess that problem applies not only in the case of h.264 encoding.", 
                    "author": "highks"
                }, 
                {
                    "date": "2014-10-04T22:36:03.819Z", 
                    "text": "Not /really/. I mean, yes, there is the problem of what you just stated, \nbut a lot of things can only be done linearly for somewhat obvious reasons.", 
                    "author": "Nicholas Cardenas"
                }
            ], 
            "num_replies": 2
        }, 
        "z131v5ch0omggf1ls23cvfbgwuyijraw404": {
            "top_comment": {
                "date": "2014-07-15T12:24:54.000Z", 
                "text": "How can we manufacture those chips?!\nIts something I have always asked myself: how can there be 1 000 000 000 \ntransistors on about maybe 2 cubic centimeter?\nWhat kind of machines/materials are used to shape the silicon as fine as a \nvirus?\ufeff", 
                "author": "kjell159"
            }, 
            "comments": [
                {
                    "date": "2014-09-02T10:02:28.472Z", 
                    "text": "thats pretty interesting, always finding old techniques being re-purposed \nfor newer tech. saw someone recently using a roller used to flatten dough \nas a cotton compress. new forms of ghetto rigging daily lol", 
                    "author": "Maoh Lynx"
                }, 
                {
                    "date": "2014-09-02T05:19:33.569Z", 
                    "text": "Yup, the process is called Photolithograhy (light-stone-write in latin), it \nuses similar chemicals from the old photo processing. A negative image is \nburned onto a silicon dioxide wafer using photoresist and UV light and then \netched away in the spots that are not covered (like a photo being processed \nin a dark room) with certain ions (the one i'm most familiar with is an \nArgon + ion etch).", 
                    "author": "Cfigginslz"
                }, 
                {
                    "date": "2014-07-16T08:47:42.692Z", 
                    "text": "+Priyanka Gupta\nwhen speaking about nanometer is kinda self explanatory, not many tools can \nengrave something that small. carve atoms with a knife :P", 
                    "author": "Maoh Lynx"
                }, 
                {
                    "date": "2014-07-16T08:38:19.106Z", 
                    "text": "+Maoh Leusin\nWell, most people think of a physical sharp tool that engraves the base \nmaterial when it comes to 3D printers. Although there are many different \nkinds of 3D printers. I didn't want +kjell159 to get the wrong idea that \nwafers are engraved. A series of chemical reactions, UV light, vapor \ndeposition etc. are used to etch and build the silicon wafer that makes the \nprocessor.", 
                    "author": "Priyanka Gupta"
                }, 
                {
                    "date": "2014-07-16T08:29:44.907Z", 
                    "text": "+Priyanka Gupta\n same way a 3d printer works, its etched on. start with a base material and \nuse a cad program to have it machined", 
                    "author": "Maoh Lynx"
                }, 
                {
                    "date": "2014-07-16T08:25:52.479Z", 
                    "text": "+Maoh Leusin\nActually no, a single silicon wafer is doped and etched to make \ntransistors. You can't build it up like a plastic model.", 
                    "author": "Priyanka Gupta"
                }, 
                {
                    "date": "2014-07-15T12:26:12.872Z", 
                    "text": "+Maoh Leusin Thanks for the answer. I never thaught about that myself! :)", 
                    "author": "kjell159"
                }, 
                {
                    "date": "2014-07-15T07:11:47.432Z", 
                    "text": "same way a 3d printer works", 
                    "author": "Maoh Lynx"
                }
            ], 
            "num_replies": 8
        }, 
        "z12bupmgpu2xt1t2e22vfdqyclqey5puq": {
            "top_comment": {
                "date": "2014-07-13T15:14:12.499Z", 
                "text": "Transistors are not on off. They are capable of being arranged such that \nthey are basically on off, but as someone who has been taught how to use a \ntransistor in a circuit, I can tell you that they are not nearly that \nsimple.\ufeff", 
                "author": "bloodspatteredguitar"
            }, 
            "comments": [
                {
                    "date": "2014-07-16T14:18:12.516Z", 
                    "text": "I'm half way through a degree in Electronic Engineering. I know how a \ntransistor works.\nWith that last bit, are you trying to say that because particles can have \neither positive or negative charges then electricity can only be either on \nor off? Because that's nonsense.", 
                    "author": "bloodspatteredguitar"
                }, 
                {
                    "date": "2014-07-16T14:09:41.017Z", 
                    "text": "or can look at it like this, what are the components of electricity. \npositive, negative and neutral. electricity itself only has a positive and \nnegative to go off of. its a base 2 function. what else is a base 2 \nfunction, 1/0, off/on, open/closed. any way you want to frame it. you can \nadd as many transistors as you want it will always be a base 2 function. 2 \nfunction. a switch is only a base 2 function because of electricity.", 
                    "author": "Maoh Lynx"
                }, 
                {
                    "date": "2014-07-16T14:03:34.590Z", 
                    "text": "Its like you're saying you're just looking at a macro view and not the \nmicro. macro is made up of the micro. look at how a single transistor works \nnot all billion together.", 
                    "author": "Maoh Lynx"
                }, 
                {
                    "date": "2014-07-16T13:54:49.862Z", 
                    "text": "I'm saying that you're attempting to sounds knowledgeable about something \nyou clearly have 0 experience with. Transistors are switches, they are all \nlogic gates, together they form a relay. Trying to get you to look at the \nfundamentals but you're stuck on a simplified function that is made up of \nthe primitives or fundamental of circuits..", 
                    "author": "Maoh Lynx"
                }, 
                {
                    "date": "2014-07-16T13:47:10.592Z", 
                    "text": "I'm not sure what you've just tried to tell me. I find that writing in full \nsentences is a good aid to communication.\n\nA transistor, at least of the kind used in silicon chips, works by a field \nattracting or repelling charge carriers from a channel of doped \nsemiconductor, thereby changing its conductive properties. On a very simple \nlevel, no field corresponds to disconnecting a switch and a strong field \ncorresponds to connecting a switch. The transistor can be used in a \nconfiguration where these are the only situations you need to be aware of. \nHowever, the transistor's properties change continuously as a function of \nthat field, and many applications make use of this. \n\nI repeat what I have been trying to say from the beginning: transistors can \nbe used as switches. They are not, fundamentally speaking, switches. ", 
                    "author": "bloodspatteredguitar"
                }, 
                {
                    "date": "2014-07-16T13:03:21.216Z", 
                    "text": "if that is to hard to understand suggest learning about charges of a atom. \nits in the name is \"transist\". fell like I'm talking to a kid..", 
                    "author": "Maoh Lynx"
                }, 
                {
                    "date": "2014-07-16T12:58:07.686Z", 
                    "text": "should try to understand primitive function before jumping to simplified.", 
                    "author": "Maoh Lynx"
                }, 
                {
                    "date": "2014-07-16T12:55:51.129Z", 
                    "text": "do you not understand what a switch is? all transistors are switches...", 
                    "author": "Maoh Lynx"
                }, 
                {
                    "date": "2014-07-16T12:28:52.483Z", 
                    "text": "Show me where in wikipedia /mosfet you can see that function. I have \nnothing against simplification, provided that it admits to being a \nsimplification.", 
                    "author": "bloodspatteredguitar"
                }, 
                {
                    "date": "2014-07-15T13:33:12.786Z", 
                    "text": "\"Transistors are not on off\", they literally are either off/on, 0/1, \nopen/closed etc. no mater how you want to frame it. that's the function.", 
                    "author": "Maoh Lynx"
                }, 
                {
                    "date": "2014-07-15T09:57:13.449Z", 
                    "text": "I don't need to relearn. I said they can be used that way (obviously), but \nthat is not nearly the end of their complexity nor their possible uses.", 
                    "author": "bloodspatteredguitar"
                }, 
                {
                    "date": "2014-07-15T07:07:34.735Z", 
                    "text": "yea they are pretty much that straight forward. suggest looking into logic \ngates if you'd like to relearn.", 
                    "author": "Maoh Lynx"
                }
            ], 
            "num_replies": 12
        }, 
        "z120dl2hvzuph1o1r22oy1q5roazwbnrr04": {
            "top_comment": {
                "date": "2015-01-05T12:20:10.222Z", 
                "text": "Question: what is the most common element in earth? I mean, biggest amount \nof atoms... iron? Oxygen?\ufeff", 
                "author": "Kritikh Skeyh"
            }, 
            "comments": [
                {
                    "date": "2015-04-10T21:02:51.148Z", 
                    "text": "+Kritikh Skeyh Hydrogen is several times more common that oxygen. But it's \na bitch to isolate.", 
                    "author": "John Benton"
                }, 
                {
                    "date": "2015-03-27T13:01:12.654Z", 
                    "text": "+DrKingSchultz That's abundance in the solar system.", 
                    "author": "IamGrimalkin"
                }, 
                {
                    "date": "2015-03-27T08:16:43.726Z", 
                    "text": "+Kritikh Skeyh I'm pretty sure it's Hydrogen. It is a really small atom, \nbut you asked for the amount and Hydrogen is in almost every organic \ncompound.\n(here is a graph that shows the distribution of elements on earth: \nhttp://en.wikipedia.org/wiki/Abundance_of_the_chemical_elements#/media/File:SolarSystemAbundances.png \n)", 
                    "author": "DrKingSchultz"
                }, 
                {
                    "date": "2015-03-20T13:48:53.265Z", 
                    "text": "+John Egbert 1-4% of the atmosphere is water though, which is a compound of \nhydrogen.", 
                    "author": "IamGrimalkin"
                }, 
                {
                    "date": "2015-02-10T12:01:50.000Z", 
                    "text": "+Kritikh Skeyh depends on whether you're looking at abundance by weight or \nabundance by \"number of atoms\"\n\niron has an atomic weight of about 55.8, where oxygen has an atomic weight \nof about 16, this makes each iron atom just over 3 times as heavy as any \noxygen atom, so while iron accounts for a larger percentage of the mass of \nearth, oxygen is a rather likely to account for the largest percentage of \natoms on earth\n(the reason oxygen takes up such a large percentage of the mass, \nincidentally, is due to the fact that rock, and therefore a substantial \nportion of the earth's mantle, is made up mainly of silicon oxides combined \nwith other metal oxides, granite for example contains mainly SiO2 and Al2O3 \nwith trace amounts of K2O, Na2O, CaO, FeO, Fe2O3, MgO, TiO2, P2O5 and MnO)", 
                    "author": "Sirius Black"
                }, 
                {
                    "date": "2015-02-05T21:38:03.645Z", 
                    "text": "My bad... 70% is nitrogen.", 
                    "author": "jan danyy"
                }, 
                {
                    "date": "2015-01-26T22:52:12.421Z", 
                    "text": "+jan danyy\n70% of the atmosphere is NOT hydrogen! hydrogen is too light for the \nearth's gravity to keep it close, the same goes for helium", 
                    "author": "John Egbert"
                }, 
                {
                    "date": "2015-01-07T22:40:42.926Z", 
                    "text": "NO NO...\nI just foud out this.\nhttp://en.wikipedia.org/wiki/Abundance_of_the_chemical_elements#Abundance_of_elements_in_the_Earth\n\n\nThe mass of the Earth is approximately 5.98\u00d71024 kg. It is composed mostly \nof iron (32.1%), oxygen (30.1%), silicon (15.1%), magnesium (13.9%), sulfur \n(2.9%), nickel (1.8%), calcium (1.5%), and aluminium (1.4%); with the \nremaining 1.2% consisting of trace amounts of other elements\n\nSo Iron cames first, Oxygen second, Silicon third...", 
                    "author": "Kritikh Skeyh"
                }, 
                {
                    "date": "2015-01-07T22:34:46.363Z", 
                    "text": "Ok thanx!", 
                    "author": "Kritikh Skeyh"
                }, 
                {
                    "date": "2015-01-07T22:25:54.030Z", 
                    "text": "On earth it is oxygen. It makes up about 47% of the mass of the earth.", 
                    "author": "jan danyy"
                }, 
                {
                    "date": "2015-01-07T22:12:00.735Z", 
                    "text": "I know. about universe. My question is about earth only. Atmosphere is a \nlittle percent of the mass of the earth.\nSo the result to my question probably will be determined by the solid part.\n\nSo. Which element has the biggest percent in the MASS of the EARTH. This is \nmy question.", 
                    "author": "Kritikh Skeyh"
                }, 
                {
                    "date": "2015-01-07T22:04:04.244Z", 
                    "text": "The answer to your question is very simple. The most common element in the \nuniverse and on earth is hydrogen. It has one proton and one electron so it \ncan be found anywhere. More than 70% of earth's atmosphere is hydrogen, not \nincluding land.", 
                    "author": "jan danyy"
                }, 
                {
                    "date": "2015-01-07T14:01:43.089Z", 
                    "text": "yes you are right. It is in the atmosphere.\nSo this does not answer the question. What about the whole earth?\nI think it is Iron, because of the core. But I am not sure...", 
                    "author": "Kritikh Skeyh"
                }, 
                {
                    "date": "2015-01-07T12:08:54.150Z", 
                    "text": "i think only in atmosphere", 
                    "author": "Googleing"
                }, 
                {
                    "date": "2015-01-06T15:13:54.378Z", 
                    "text": "so\nnumber of oxygen atoms / earth atoms = 0.21\n\nthis is what you mean?", 
                    "author": "Kritikh Skeyh"
                }, 
                {
                    "date": "2015-01-06T15:11:15.867Z", 
                    "text": "i think its 21%mol", 
                    "author": "Googleing"
                }, 
                {
                    "date": "2015-01-06T14:55:38.009Z", 
                    "text": "Of course it is smaller. But what percent of earth's mass is oxygen. This \nis what i am asking...", 
                    "author": "Kritikh Skeyh"
                }, 
                {
                    "date": "2015-01-06T14:49:48.000Z", 
                    "text": "+Kritikh Skeyh i think oxygen mass is smaller than earth's globe one", 
                    "author": "Googleing"
                }, 
                {
                    "date": "2015-01-05T19:41:04.372Z", 
                    "text": "ok.. So Oxygen mass / earth mass = ?", 
                    "author": "Kritikh Skeyh"
                }, 
                {
                    "date": "2015-01-05T19:02:25.449Z", 
                    "text": "oxygen", 
                    "author": "Something Random Inc."
                }
            ], 
            "num_replies": 20
        }, 
        "z13yx1gj4obsx31q304cdpchxn2lzt3io10": {
            "top_comment": {
                "date": "2014-07-14T19:29:14.683Z", 
                "text": "I thought electrons moved at a few hundred or thousand meters per second.\n8.5cm/hr is VERY slow.\ufeff", 
                "author": "TOMBOI50"
            }, 
            "comments": [
                {
                    "date": "2014-08-22T02:59:15.448Z", 
                    "text": "+Stuff and Things and Stuff and Things Mmmhh... I don't really see the \nanalogy, but thanks for your reply...\n\nAnyway, for what I understand, a transistor is on or off, depending if an \nelectric signal is applied to a specific port of it... right? it is not the \nelectrons themselves... if this is so, it wouldn't matter how fast the \nelectrons are moving, but how fast the electricity reaches them...\n\nMore or less like the speed at which an appliance turns on... it doesn't \nmatter how fast the electrons move... right?\n\nDunno, I'm a bit confused, didn't know this difference in speed", 
                    "author": "Franco Pellegrini"
                }, 
                {
                    "date": "2014-08-22T02:44:31.275Z", 
                    "text": "+Franco Pellegrini Hmm... well, I suppose a reasonable analogy would be \nrubber bands.\n\nThink of stretching out a new rubber band & letting it go. It snaps back \nvery quickly, right? The information of you letting go of the rubber band \ntravels across it rapidly.\n\nNow, do the same with an old rubber band, and it doesn't snap back nearly \nas quickly, right? It takes that information a lot longer to pass through \nthe rubber band.\n\nElectrons are kinda like an old rubber band.", 
                    "author": "Clayton \u00ad"
                }, 
                {
                    "date": "2014-08-22T02:40:31.648Z", 
                    "text": "+Stuff and Things and Stuff and Things So, the signal that goes through \ntransistors should be this wave, and not the actual electrons, right ?\n\nIf that's so, what does it matter if electrons are fast or slow?", 
                    "author": "Franco Pellegrini"
                }, 
                {
                    "date": "2014-08-20T07:21:34.462Z", 
                    "text": "There is 2 speeds of electrons, you could categorize it as the fill speed \nand push speed.", 
                    "author": "Stoogie"
                }, 
                {
                    "date": "2014-08-13T18:49:44.081Z", 
                    "text": "+TOMBOI50 Electricity is transferred by waves going through the electrons. \nWe kind of lied to you when we said current is a flow of electrons, rather \nit is a flow of electrical potential.\n\nThink of it like this, waves in the ocean can travel very fast at times, \nbut the actual water molecules don't actually move that much. They just \nbump into either causing the wave to propagate. The same is true for \nelectrons.", 
                    "author": "Clayton \u00ad"
                }, 
                {
                    "date": "2014-08-13T18:45:53.147Z", 
                    "text": "+odisy64 Holy crap that's fast. ", 
                    "author": "TOMBOI50"
                }, 
                {
                    "date": "2014-08-13T18:45:21.687Z", 
                    "text": "+Clayton Carson No I was thinking of electrons because how the hell can \nelectricity be transferred so far and so quickly.\nIn a wire when you turn the power on to an appliance it turns on almost \ninstantly even if there are meters of wire for it to get through.", 
                    "author": "TOMBOI50"
                }, 
                {
                    "date": "2014-08-12T22:02:59.049Z", 
                    "text": "No, what you're thinking of is photons: quanta of light.  A photon moves at \n299,792,458 meters per second (usually written as 3x10^8 m/s) in a vacuum. \n That is the fastest any matter or energy can move in our universe.", 
                    "author": "Clayton \u00ad"
                }, 
                {
                    "date": "2014-07-15T06:43:08.482Z", 
                    "text": "electrons travel at about 98% of speed of light when moving through a \nsubstance.", 
                    "author": "odisy64"
                }
            ], 
            "num_replies": 9
        }
    }, 
    "video_length": "PT9M19S", 
    "captions": [
        {
            "text": "Behold! The transistor, a tiny switch about\nthe size of a virus that can control the flow", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "of a small electrical current. It&#39;s one of\nthe most important inventions ever because", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "when it&#39;s on, it&#39;s on and when it&#39;s off, it&#39;s\noff. Sounds simple. Probably too simple. But", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "this &quot;either/or&quot; situation is incredibly useful\nbecause it is a binary system. On or off,", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "yes or no, one or zero. But with enough transistors\nworking together we can create limitless combinations", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "of &quot;ons&quot; and &quot;offs&quot;, &quot;ones&quot; and &quot;zeros&quot; to\nmake a code that can store and process just", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "about any kind of information you can imagine.", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "That&#39;s how your computer computes, and it&#39;s\nhow you&#39;re watching me right now. It&#39;s all", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "because those tiny transistors can be organized,\nor integrated into integrated circuits also", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "known as microchips or microprocessors, which\ncan orchestrate the operation of millions", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "of transistors at once. And until pretty recently,\nthe only limitation to how fast and smart", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "our computers could get was how many transistors\nwe could pack onto a microchip.", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "Back in 1965, Gordon Moore, co-founder of\nthe Intel Corporation, predicted that the", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "number of transistors that could fit on a\nmicrochip would double every two years. So", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "essentially every two years computers would\nbecome twice as powerful. This is known in", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "the tech industry as Moore&#39;s Law, and for\nforty years it was pretty accurate; we went", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "from chips with about 2,300 transistors in\n1972, to chips with about 300 million transistors", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "by 2006.", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "But over the last ten years we&#39;ve fallen behind\nthe exponential growth that Moore predicted.", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "The processors coming off assembly lines now\nhave about a billion transistors, which is", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "a really big number, but if we were keeping\nup with Moore&#39;s Law, we&#39;d be up to four or", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "five billion by now.", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "So why is the trend slowing down? How can\nwe get more transistors onto a chip? Are there", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "entirely different technologies we could be\nusing instead, ones that pose no limitations?", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "And how do billions of little on/off switches\nturn into movies and music and YouTube videos", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "about science that display on a glowing, magical\nbox? Spoilers: it&#39;s not magic; it&#39;s science.", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "[SciShow intro music]", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "To understand the device that you&#39;re using\nright now as well as the challenges computer", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "science is facing, and what the future of\ncomputing might look like, you have to start", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "small with that transistor. A transistor is\nessentially a little gate that can be opened", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "or shut with electricity to control the flow\nof electrons between two channels made of", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "silicon, which are separated by a little gap.\nThey&#39;re made of silicon because silicon is", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "a natural semiconductor. It can be modified\nto conduct electricity really well in some", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "conditions or not at all in other conditions.\nIn its pure state, silicon forms really nice,", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "regular crystals. Each atom has four electrons\nin its outer shell that are bonded with the", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "silicon atoms around it. This arrangement\nmakes it an excellent insulator. It doesn&#39;t", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "conduct electricity very well because all\nof its electrons are spoken for. But you can", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "make that crystalline silicon conduct electricity\nreally well if you dope it. You know, doping,", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "when you inject one substance into another\nsubstance to give it powerful properties,", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "like what Lance Armstrong did to win the the\nTour De France seven times, only instead of", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "super-powered tiger blood or whatever, the\nsilicon is doped with another element like", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "phosphorous, which has five electrons in its\nouter shell; or boron, which has three.", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "If you inject these in to pure crystal silicon,\nsuddenly you have extra unbonded electrons", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "that can move around, and jump across the\ngap between the two strips of silicon. But", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "they&#39;re not gonna do that without a little\nkick. When you apply a positive electrical", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "charge to a transistor, that positive charge\nwill attract those electrons, which are negative,", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "out of both silicon strips, drawing them in\nto the gap between them. When enough electrons", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "are gathered, they turn in to a current. Remove\nthe positive charge, and the electrons zip", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "back in to their places leaving the gap empty.\nThus the transistor has two modes: on and", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "off, one and zero.", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "All the information your computer is using\nright now is represented by sequences of open", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "and shut transistors. So, how does a bunch\nof ones and zeroes turn in to me talking to", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "you on your screen right now? Let&#39;s just imagine\neight transistors hooked up together. I say", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "8 because one byte of information is made\nout of 8 bits, that&#39;s 8 on or off switches,", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "that&#39;s the basic unit of a single piece of\ninformation inside your computer.", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "Now the total number of possible on/off configurations\nfor those 8 transistors is 256. That means", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "256 combinations of ones and zeroes in that\n8 bit sequence. So let&#39;s say our 8 transistor", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "microchip is given this byte of data, that&#39;s\nthe number 67 in binary by the way. Okay,", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "so what now?", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "The cool thing about binary data is that the\nsame string of ones and zeroes can mean totally", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "different things depending on where it&#39;s sent.", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "Different parts of your computer use different\ndecoding keys to read the binary code. So", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "if our teeny tiny little 8 transistor microchip\nkicks that byte over to our graphics card,", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "our graphics card will interpret it as one\nof 256 colors. Whichever one is coded as number", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "67. But if that same byte is sent over to\nour sound card, it might interpret it as one", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "of 256 different spots mapped on to a sound\nwave. Each spot has its own sound and our", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "byte will code for a spot number 67, so your\nspeaker will put out that sound.", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "If it&#39;s sent over to the part of your computer\nthat converts data into written language,", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "called the UTF-8 code, it turns it into the\nletter C. Uppercase C actually, not lowercase", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "c which is a different byte. So our eight\ntransistor processor already has a lot of", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "options; the problem is that it can only manage\none byte of data at a time, and even if it&#39;s", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "flying through bytes at a rate of a few million\nper second, which your computer is doing right", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "now, that&#39;s still a serious data checkpoint,\nso we need more transistors, and then more,", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "and more, and more, and more!", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "And for the past 50 years, the biggest obstacle\nto cramming more and more transistors onto", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "a single chip, and therefore increasing our\nprocessing power, has come down to one thing", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "- how small we can make that gap between the\ntwo silicon channels.", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "In the early days of computing, those gaps\nwere so big that you could see them with the", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "naked eye. Today, a state-of-the-art microchip\nhas gaps that are only 32 nanometers across.", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "To give you a sense of perspective, a single\nred blood cell is 125 times larger than that.", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "32 nanometers is the width of only a few hundred\natoms.", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "So, there&#39;s a limit to how low we can go.\nMaybe we can shave that gap down to 22 or", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "16 or even 10 nanometers using current available\ntechnology, but then you start running into", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "a lot of problems.", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "The first big problem is that when you&#39;re\ndealing with components that are so small", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "that just a few stray atoms can ruin a chip,\nit&#39;s no longer possible to make chips that", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "are reliable or affordable.", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "The second big problem is heat. That many\ntransistors churning through millions of bytes", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "of data per second in such a small space generates\na lot of heat. I mean, we&#39;re starting to test", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "chips that get so hot that they melt through\nthe motherboard, and then sometimes through", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "the floor.", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "And the third big problem is quantum mechanics.\nOh, quantum mechanics, you enchanting, treacherous", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "minx. When you start dealing with distances\nthat are that small, you start to face the", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "very real dilemma of electrons just jumping\nacross the gap for no reason, in a phenomenon", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "known as quantum tunneling. If that starts\nhappening, your data is gonna start getting", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "corrupted while it moves around inside your\ncomputer.", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "So, how can we keep making our computers even\nfaster when atoms aren&#39;t getting any smaller.", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "Well, it might be time to abandon silicon.", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "Graphene, for example, is a more highly conductive\nmaterial that would let electrons travel across", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "it faster. We just can&#39;t figure out how to\nmanufacture it yet.", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "Another option is to abandon electrons because,\nand get ready to have your mind blown, electrons", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "are incredibly slow. Like, the electrons moving\nthrough the wire that connects your lamp to", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "the wall outlet, they&#39;re moving at about 8\nand a half centimeters per hour. And that&#39;s", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "fast enough when electrons only have to travel\n32 nanometers, but other stuff can go a lot", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "faster. Like light.", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "Optical computers would move around photons\ninstead of electrons to represent the flow", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "of data. And photons are literally as fast\nas anything can possibly be, so you can&#39;t", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "ask for better than that. But, of course,\nthere are some major problems with optical", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "computing, like the fact that photons ARE\nso fast that it makes them hard to pin down", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "for long enough to be used for data. And the\nfact that lasers, which are probably what", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "optical computing would involve, are huge\npower hogs and would be incredibly expensive", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "to keep running.", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "Probably the simplest solution to faster computing\nisn&#39;t to switch to fancy new materials or", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "harness the power of light, but to just start\nusing more chips. If you&#39;ve got four chips", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "processing a program in parallel, the computer\nwould be four times faster, right?", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "Welllll, yeah, I mean es, but microchips are\nsuper expensive, and it&#39;s also hard to design", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "software that makes use of multiple processors.\nWe like our flows of data to be linear because", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "that&#39;s how we tend to process information\nand it&#39;s kind of a hard habit to break.", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "And then there are some really exotic options,\nlike thermal computing which uses variations", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "in heat to represent bits of data, or quantum\ncomputing which deals in particles that are", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "in more than one state at the same time, thereby\ntotally doing away with the whole on-off,", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "either-or system.", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "So, wherever computers go next, there are\ngonna need to be some big changes if we want", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "our technology to keep getting smaller, and\nsmarter, and faster.", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "Personally, I&#39;m holding out hope for the lasers,\nlaser computer- I want one of those.", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "Thanks for watching the SciShow Infusion,\nespecially to our Subbable subscribers. To", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "learn how you can support us in exploring\nthe world, whether it&#39;s inside your computer", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "or outside in the universe, just go to subbable.com/scishow.", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "And speaking of that whole universe, check\nout our new channel, SciShow Space where we", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "talk about that, including the latest in space\nnews, and as always don&#39;t forget to go to", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "youtube.com/scishow and subscribe, so that\nyou can always keep getting more of this,", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "because I know you like it.", 
            "dur": 0, 
            "start": 0
        }, 
        {
            "text": "[SciShow outro music]", 
            "dur": 0, 
            "start": 0
        }
    ], 
    "title": "Moore's Law and The Secret World Of Ones And Zeroes", 
    "publish_date": "2014-07-13T00:53:07.000Z", 
    "topics": [
        "/m/09t92", 
        "/m/0yq3q1b"
    ], 
    "vide_defintion": "hd", 
    "number_views": 656618, 
    "categories": [
        22
    ]
}